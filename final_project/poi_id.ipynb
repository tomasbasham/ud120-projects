{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Fraud from Public Enron Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2000, Enron Corporation was an American energy, commodities, and services company based in Houston, Texas. It was founded in 1985 as a merger between Houston Natural Gas and InterNorth, both relatively small regional companies. Before its bankruptcy on December 2, 2001, Enron employed approximately 20,000 staff and was a major electricity, natural gas, communications and pulp and paper company, with claimed revenues of nearly $101 billion during 2000. Fortune named Enron \"America's Most Innovative Company\" for six consecutive years.\n",
    "\n",
    "At the end of 2001, it was revealed that Enron's reported financial condition was sustained by institutionalised, systematic, and creatively planned accounting fraud, known since as the Enron scandal. Enron has since become a well-known example of willful corporate fraud and corruption. The scandal also brought into question the accounting practices and activities of many corporations in the United States and was a factor in the enactment of the Sarbanes–Oxley Act of 2002. The scandal also affected the greater business world by causing the dissolution of the Arthur Andersen accounting firm, which had been Enron's main auditor for years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists from Enron emails and financial data publicly available for research. The Enron Email dataset was collected and prepared by the CALO Project (A Cognitive Assistant that Learns and Organizes), details are described in https://www.cs.cmu.edu/~./enron/. The financial data was published in Payments to Insiders report by FindLaw and available at www.findlaw.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to implement and optimise a predictive model using the financial and email data provided by the Enron dataset capable of identifying persons on interest (POIs). Specifically the project intends to demonstrate working with a real world dataset, performing such tasks as cleaning and preparing the data; feature selection and engineering; possible dimensionality reduction; supervised classification and hyperparameter tuning; and validation.\n",
    "\n",
    "To help guide the implementation of this project and address some key points I have attempted to follow the [rubric](https://review.udacity.com/#!/rubrics/27/view) created by the Udacity team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tools used in this experiment are under very active development and it can be difficult to know which versions will successfully run this notebook. In light of this I've printed the versions I have used and that I expect to reproduce the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy: 1.0.0\n",
      "sklearn: 0.19.1\n",
      "numpy: 1.14.0\n",
      "matplotlib: 2.1.2\n",
      "pandas: 0.22.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../tools/')\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: %s' % scipy.__version__)\n",
    "\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: %s' % sklearn.__version__)\n",
    "\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: %s' % numpy.__version__)\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: %s' % matplotlib.__version__)\n",
    "\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: %s' % pandas.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Enron dataset is a collection of key/value pairs associating persons included in the dataset (the keys) with a collection of labelled features (the values). The labelled features for each person are represented by a dictionary and include the following data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Financial features (all units in US dollars):\n",
    "  - `bonus`\n",
    "  - `deferral_payments`\n",
    "  - `deferred_income`\n",
    "  - `director_fees`\n",
    "  - `exercised_stock_options`\n",
    "  - `expenses`\n",
    "  - `loan_advances`\n",
    "  - `long_term_incentive`\n",
    "  - `other`\n",
    "  - `restricted_stock`\n",
    "  - `restricted_stock_deferred`\n",
    "  - `salary`\n",
    "  - `total_payments`\n",
    "  - `total_stock_value`\n",
    "- Email features (most units are integers with exception to `email_address` which is a string)\n",
    "  - `email_address`\n",
    "  - `from_messages`\n",
    "  - `from_poi_to_this_person`\n",
    "  - `from_this_person_to_poi`\n",
    "  - `shared_receipt_with_poi`\n",
    "  - `to_messages`\n",
    "- Labels (boolean, represented as an integer)\n",
    "  - `poi`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to examine the data that we have to work with. It is very often the case that a dataset will contain errors, and it is imperitive that these errors are resolved before making any further analysis of the data at hand. If the errors are not resolved then the final predictive model may not generalise well to any new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When examining the data we are trying to answer the following:\n",
    "- Are there any errors in the data?\n",
    "- Are there any outliers in the data?\n",
    "- Are there any missing values in the data?\n",
    "- Does the data represent a realistic range of values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by reading the data from the provided `pkl` file. This extension expresses that the data is stored in a Pickle file, used to srialise and deserialise Python data objects into a sequence of raw bytes that may be more efficienty stored on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the dictionary containing the dataset.\n",
    "with open('final_project_dataset.pkl', 'r') as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "# Sanity check\n",
    "assert type(data_dict) is dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the lack of error we may conclude we have a dictionary. Dictionaries are a primative data structure in python; but whilst they provide a simple interface through which data may be manipulated they are not flexible enough to perform many statistical operations. Instead this data can be loaded into a Pandas DataFrame: A two-dimensional size-mutable, tabular data structure with labeled axes (rows and columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>email_address</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>201955</td>\n",
       "      <td>2902</td>\n",
       "      <td>2869717</td>\n",
       "      <td>4484442</td>\n",
       "      <td>1729541</td>\n",
       "      <td>4175000</td>\n",
       "      <td>126027</td>\n",
       "      <td>1407</td>\n",
       "      <td>-126027</td>\n",
       "      <td>1729541</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2195</td>\n",
       "      <td>152</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3081055</td>\n",
       "      <td>304805</td>\n",
       "      <td>phillip.allen@enron.com</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADUM JAMES P</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178980</td>\n",
       "      <td>182466</td>\n",
       "      <td>257817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257817</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BANNANTINE JAMES M</th>\n",
       "      <td>477</td>\n",
       "      <td>566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>916197</td>\n",
       "      <td>4046157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1757552</td>\n",
       "      <td>465</td>\n",
       "      <td>-560222</td>\n",
       "      <td>5243487</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>864523</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>james.bannantine@enron.com</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>267102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1295738</td>\n",
       "      <td>5634343</td>\n",
       "      <td>6680544</td>\n",
       "      <td>1200000</td>\n",
       "      <td>3942714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10623258</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2660303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1386055</td>\n",
       "      <td>1586055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAY FRANKLIN R</th>\n",
       "      <td>239671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260455</td>\n",
       "      <td>827696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400000</td>\n",
       "      <td>145796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-82782</td>\n",
       "      <td>63014</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-201641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>frank.bay@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    salary to_messages deferral_payments total_payments  \\\n",
       "ALLEN PHILLIP K     201955        2902           2869717        4484442   \n",
       "BADUM JAMES P          NaN         NaN            178980         182466   \n",
       "BANNANTINE JAMES M     477         566               NaN         916197   \n",
       "BAXTER JOHN C       267102         NaN           1295738        5634343   \n",
       "BAY FRANKLIN R      239671         NaN            260455         827696   \n",
       "\n",
       "                   exercised_stock_options    bonus restricted_stock  \\\n",
       "ALLEN PHILLIP K                    1729541  4175000           126027   \n",
       "BADUM JAMES P                       257817      NaN              NaN   \n",
       "BANNANTINE JAMES M                 4046157      NaN          1757552   \n",
       "BAXTER JOHN C                      6680544  1200000          3942714   \n",
       "BAY FRANKLIN R                         NaN   400000           145796   \n",
       "\n",
       "                   shared_receipt_with_poi restricted_stock_deferred  \\\n",
       "ALLEN PHILLIP K                       1407                   -126027   \n",
       "BADUM JAMES P                          NaN                       NaN   \n",
       "BANNANTINE JAMES M                     465                   -560222   \n",
       "BAXTER JOHN C                          NaN                       NaN   \n",
       "BAY FRANKLIN R                         NaN                    -82782   \n",
       "\n",
       "                   total_stock_value           ...           loan_advances  \\\n",
       "ALLEN PHILLIP K              1729541           ...                     NaN   \n",
       "BADUM JAMES P                 257817           ...                     NaN   \n",
       "BANNANTINE JAMES M           5243487           ...                     NaN   \n",
       "BAXTER JOHN C               10623258           ...                     NaN   \n",
       "BAY FRANKLIN R                 63014           ...                     NaN   \n",
       "\n",
       "                   from_messages    other from_this_person_to_poi    poi  \\\n",
       "ALLEN PHILLIP K             2195      152                      65  False   \n",
       "BADUM JAMES P                NaN      NaN                     NaN  False   \n",
       "BANNANTINE JAMES M            29   864523                       0  False   \n",
       "BAXTER JOHN C                NaN  2660303                     NaN  False   \n",
       "BAY FRANKLIN R               NaN       69                     NaN  False   \n",
       "\n",
       "                    director_fees deferred_income long_term_incentive  \\\n",
       "ALLEN PHILLIP K               NaN        -3081055              304805   \n",
       "BADUM JAMES P                 NaN             NaN                 NaN   \n",
       "BANNANTINE JAMES M            NaN           -5104                 NaN   \n",
       "BAXTER JOHN C                 NaN        -1386055             1586055   \n",
       "BAY FRANKLIN R                NaN         -201641                 NaN   \n",
       "\n",
       "                                 email_address from_poi_to_this_person  \n",
       "ALLEN PHILLIP K        phillip.allen@enron.com                      47  \n",
       "BADUM JAMES P                              NaN                     NaN  \n",
       "BANNANTINE JAMES M  james.bannantine@enron.com                      39  \n",
       "BAXTER JOHN C                              NaN                     NaN  \n",
       "BAY FRANKLIN R             frank.bay@enron.com                     NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use 2 decimal place output instead of scientific notation. It is far easier to read and compare.\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# Transpose the data so the names are used as indices.\n",
    "enron_data = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "enron_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're in luck! The data could be read into a Pandas DataFrame. This will make it far easier to explore in the following sections and allows for any changes made to be re-exported as a simple dictionary.\n",
    "\n",
    "The indexes are the names of Enron employees. There are several familiar names in the expanded list closely linked to the Enron scandal, including Kennth Lay, Jeffry Skilling, Andrew Fastow, and Cliff Baxter. There are also many unknown names in the list that are hopefully equally useful in describing the patterns we'll later discover in the data.\n",
    "\n",
    "Additionally there is an entry for \"The Travel Agency in the Park\" that is noted in the footnotes of the original FindLaw document that states paymets were made to this company by Enron and that this business was co-owned by the sister of Enron’s former Chairman. From an accounting perspective this information is very relavent but I suspect this will impede our predictive model. Therefore this entry is a good canditate to be removed in later sections.\n",
    "\n",
    "The columns describe the features available in the dataset. They are expressive enough that we may understand what each value represents but unfortunately they do not indicate their unit of measurement. Luckily we're told how each value is represented so this will not be an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first things of note is there seems to be a lot of missing data scattered throughout the dataset. This is indicated by the `NaN` string. Python will not be able to interpret this as missing data and may present issues when plotting features and performing any data manipulation. Instead we can tell Pandas to replace missing values by specifiying our missing value marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE 754).\n",
    "# This means that Not a Number is not equivalent to infinity.\n",
    "enron_data = enron_data.replace('NaN', np.nan)\n",
    "\n",
    "type(enron_data.loc['ALLEN PHILLIP K'].director_fees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that Pandas is aware of missing data and we have some sensible data to work with lets print out a few statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 21 columns):\n",
      "salary                       95 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "deferral_payments            39 non-null float64\n",
      "total_payments               125 non-null float64\n",
      "exercised_stock_options      102 non-null float64\n",
      "bonus                        82 non-null float64\n",
      "restricted_stock             110 non-null float64\n",
      "shared_receipt_with_poi      86 non-null float64\n",
      "restricted_stock_deferred    18 non-null float64\n",
      "total_stock_value            126 non-null float64\n",
      "expenses                     95 non-null float64\n",
      "loan_advances                4 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "other                        93 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "poi                          146 non-null bool\n",
      "director_fees                17 non-null float64\n",
      "deferred_income              49 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "email_address                111 non-null object\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "dtypes: bool(1), float64(19), object(1)\n",
      "memory usage: 29.1+ KB\n",
      "\n",
      "Number of data points:       3066\n",
      "Number of missing values:    1358\n",
      "Number of POIs:              18\n"
     ]
    }
   ],
   "source": [
    "# Print information about the data frame.\n",
    "enron_data.info()\n",
    "print()\n",
    "\n",
    "# Justify the output of statistics.\n",
    "print_stat = lambda t, stat: print('{}:'.format(t).ljust(28), stat)\n",
    "\n",
    "# Print a few statistics not included in the above.\n",
    "print_stat('Number of data points', enron_data.shape[0] * enron_data.shape[1])\n",
    "print_stat('Number of missing values', enron_data.isna().sum().sum())\n",
    "print_stat('Number of POIs', len(enron_data[enron_data['poi'] == True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have lots of integers, and a single column of strings and booleans. The boolean column, `poi` indicates whether the persion is a “Person Of Interest”. This is the column we’ll be trying to predict using the other data. Additionally the above shows the following:\n",
    "\n",
    "- There are 146 examples each containing 21 values,\n",
    "- Of the 21 values there are 19 numerical features, 1 text feature (\"email\") and 1 binary classification (\"poi\"),\n",
    "- There are 3066 data points, of which 1358 are missing,\n",
    "- 18 of the 146 examples are persons of interest.\n",
    "\n",
    "A significant proportion (44.3%) of the data is missing. From the table we can see this is particularly prevalent in the features `deferral_payments`, `deferred_income` `director_fees`, `loan_advances` and `restricted_stock_deferred`. At this time I will not remove any of these features just in case they are still useful when attempting to derive patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the summary statistics we can print some aggregate statistics over each features in the dataset. This allows us to see some typical statistical values that may unearth some useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>expenses</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>125.00</td>\n",
       "      <td>102.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>110.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>126.00</td>\n",
       "      <td>95.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>93.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>86.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562194.29</td>\n",
       "      <td>2073.86</td>\n",
       "      <td>1642674.15</td>\n",
       "      <td>5081526.49</td>\n",
       "      <td>5987053.77</td>\n",
       "      <td>2374234.61</td>\n",
       "      <td>2321741.14</td>\n",
       "      <td>1176.47</td>\n",
       "      <td>166410.56</td>\n",
       "      <td>6773957.45</td>\n",
       "      <td>108728.92</td>\n",
       "      <td>41962500.00</td>\n",
       "      <td>608.79</td>\n",
       "      <td>919064.97</td>\n",
       "      <td>41.23</td>\n",
       "      <td>166804.88</td>\n",
       "      <td>-1140475.14</td>\n",
       "      <td>1470361.45</td>\n",
       "      <td>64.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2716369.15</td>\n",
       "      <td>2582.70</td>\n",
       "      <td>5161929.97</td>\n",
       "      <td>29061716.40</td>\n",
       "      <td>31062006.57</td>\n",
       "      <td>10713327.97</td>\n",
       "      <td>12518278.18</td>\n",
       "      <td>1178.32</td>\n",
       "      <td>4201494.31</td>\n",
       "      <td>38957772.73</td>\n",
       "      <td>533534.81</td>\n",
       "      <td>47083208.70</td>\n",
       "      <td>1841.03</td>\n",
       "      <td>4589252.91</td>\n",
       "      <td>100.07</td>\n",
       "      <td>319891.41</td>\n",
       "      <td>4025406.38</td>\n",
       "      <td>5942759.32</td>\n",
       "      <td>86.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>477.00</td>\n",
       "      <td>57.00</td>\n",
       "      <td>-102500.00</td>\n",
       "      <td>148.00</td>\n",
       "      <td>3285.00</td>\n",
       "      <td>70000.00</td>\n",
       "      <td>-2604490.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-7576788.00</td>\n",
       "      <td>-44093.00</td>\n",
       "      <td>148.00</td>\n",
       "      <td>400000.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3285.00</td>\n",
       "      <td>-27992891.00</td>\n",
       "      <td>69223.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>211816.00</td>\n",
       "      <td>541.25</td>\n",
       "      <td>81573.00</td>\n",
       "      <td>394475.00</td>\n",
       "      <td>527886.25</td>\n",
       "      <td>431250.00</td>\n",
       "      <td>254018.00</td>\n",
       "      <td>249.75</td>\n",
       "      <td>-389621.75</td>\n",
       "      <td>494510.25</td>\n",
       "      <td>22614.00</td>\n",
       "      <td>1600000.00</td>\n",
       "      <td>22.75</td>\n",
       "      <td>1215.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>98784.00</td>\n",
       "      <td>-694862.00</td>\n",
       "      <td>281250.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>259996.00</td>\n",
       "      <td>1211.00</td>\n",
       "      <td>227449.00</td>\n",
       "      <td>1101393.00</td>\n",
       "      <td>1310813.50</td>\n",
       "      <td>769375.00</td>\n",
       "      <td>451740.00</td>\n",
       "      <td>740.50</td>\n",
       "      <td>-146975.00</td>\n",
       "      <td>1102872.50</td>\n",
       "      <td>46950.00</td>\n",
       "      <td>41762500.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>52382.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>108579.00</td>\n",
       "      <td>-159792.00</td>\n",
       "      <td>442035.00</td>\n",
       "      <td>35.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>312117.00</td>\n",
       "      <td>2634.75</td>\n",
       "      <td>1002671.50</td>\n",
       "      <td>2093263.00</td>\n",
       "      <td>2547724.00</td>\n",
       "      <td>1200000.00</td>\n",
       "      <td>1002369.75</td>\n",
       "      <td>1888.25</td>\n",
       "      <td>-75009.75</td>\n",
       "      <td>2949846.75</td>\n",
       "      <td>79952.50</td>\n",
       "      <td>82125000.00</td>\n",
       "      <td>145.50</td>\n",
       "      <td>362096.00</td>\n",
       "      <td>24.75</td>\n",
       "      <td>113784.00</td>\n",
       "      <td>-38346.00</td>\n",
       "      <td>938672.00</td>\n",
       "      <td>72.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26704229.00</td>\n",
       "      <td>15149.00</td>\n",
       "      <td>32083396.00</td>\n",
       "      <td>309886585.00</td>\n",
       "      <td>311764000.00</td>\n",
       "      <td>97343619.00</td>\n",
       "      <td>130322299.00</td>\n",
       "      <td>5521.00</td>\n",
       "      <td>15456290.00</td>\n",
       "      <td>434509511.00</td>\n",
       "      <td>5235198.00</td>\n",
       "      <td>83925000.00</td>\n",
       "      <td>14368.00</td>\n",
       "      <td>42667589.00</td>\n",
       "      <td>609.00</td>\n",
       "      <td>1398517.00</td>\n",
       "      <td>-833.00</td>\n",
       "      <td>48521928.00</td>\n",
       "      <td>528.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           salary  to_messages  deferral_payments  total_payments  \\\n",
       "count       95.00        86.00              39.00          125.00   \n",
       "mean    562194.29      2073.86         1642674.15      5081526.49   \n",
       "std    2716369.15      2582.70         5161929.97     29061716.40   \n",
       "min        477.00        57.00         -102500.00          148.00   \n",
       "25%     211816.00       541.25           81573.00       394475.00   \n",
       "50%     259996.00      1211.00          227449.00      1101393.00   \n",
       "75%     312117.00      2634.75         1002671.50      2093263.00   \n",
       "max   26704229.00     15149.00        32083396.00    309886585.00   \n",
       "\n",
       "       exercised_stock_options       bonus  restricted_stock  \\\n",
       "count                   102.00       82.00            110.00   \n",
       "mean                5987053.77  2374234.61        2321741.14   \n",
       "std                31062006.57 10713327.97       12518278.18   \n",
       "min                    3285.00    70000.00       -2604490.00   \n",
       "25%                  527886.25   431250.00         254018.00   \n",
       "50%                 1310813.50   769375.00         451740.00   \n",
       "75%                 2547724.00  1200000.00        1002369.75   \n",
       "max               311764000.00 97343619.00      130322299.00   \n",
       "\n",
       "       shared_receipt_with_poi  restricted_stock_deferred  total_stock_value  \\\n",
       "count                    86.00                      18.00             126.00   \n",
       "mean                   1176.47                  166410.56         6773957.45   \n",
       "std                    1178.32                 4201494.31        38957772.73   \n",
       "min                       2.00                -7576788.00          -44093.00   \n",
       "25%                     249.75                 -389621.75          494510.25   \n",
       "50%                     740.50                 -146975.00         1102872.50   \n",
       "75%                    1888.25                  -75009.75         2949846.75   \n",
       "max                    5521.00                15456290.00       434509511.00   \n",
       "\n",
       "        expenses  loan_advances  from_messages       other  \\\n",
       "count      95.00           4.00          86.00       93.00   \n",
       "mean   108728.92    41962500.00         608.79   919064.97   \n",
       "std    533534.81    47083208.70        1841.03  4589252.91   \n",
       "min       148.00      400000.00          12.00        2.00   \n",
       "25%     22614.00     1600000.00          22.75     1215.00   \n",
       "50%     46950.00    41762500.00          41.00    52382.00   \n",
       "75%     79952.50    82125000.00         145.50   362096.00   \n",
       "max   5235198.00    83925000.00       14368.00 42667589.00   \n",
       "\n",
       "       from_this_person_to_poi  director_fees  deferred_income  \\\n",
       "count                    86.00          17.00            49.00   \n",
       "mean                     41.23      166804.88      -1140475.14   \n",
       "std                     100.07      319891.41       4025406.38   \n",
       "min                       0.00        3285.00     -27992891.00   \n",
       "25%                       1.00       98784.00       -694862.00   \n",
       "50%                       8.00      108579.00       -159792.00   \n",
       "75%                      24.75      113784.00        -38346.00   \n",
       "max                     609.00     1398517.00          -833.00   \n",
       "\n",
       "       long_term_incentive  from_poi_to_this_person  \n",
       "count                66.00                    86.00  \n",
       "mean            1470361.45                    64.90  \n",
       "std             5942759.32                    86.98  \n",
       "min               69223.00                     0.00  \n",
       "25%              281250.00                    10.00  \n",
       "50%              442035.00                    35.00  \n",
       "75%              938672.00                    72.25  \n",
       "max            48521928.00                   528.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without a statistical background, further analysis is not particularly easy unless we know that our data should fall in a particular range. It's usually better to visualize the data in some way. Visualization makes outliers and errors immediately stand out, whereas they might go unnoticed in a large table of numbers. We'll investigate this further in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets begin analysing the dataset by first ensuring the values are in fact accurate according to the financial records available from the FindLaw report. There are two features in particular that should total the values of other features. These features are `total_payments` and `total_stock_value`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the features relating to payment we're able to find any examples where the `total_payments` feature is not equal to the sum of all the other payment features: `salary`, `bonus`, `long_term_incentive`, `deferred_income`, `deferral_payments`, `loan_advances`, `other`, `expenses`, `director_fees`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inaccurate_examples(features):\n",
    "    '''\n",
    "    Return a function that checkes for data inconsistencies.\n",
    "    '''\n",
    "    def sum_features(data):\n",
    "        '''\n",
    "        Sum along the columns of all passed features, excluding the last,\n",
    "        and compare the value to the last feature.\n",
    "        '''\n",
    "        return data[data[features[:-1]].sum(axis='columns').ne(data[features[-1]], fill_value=0)][features]\n",
    "    return sum_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>-102500.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>3285.00</td>\n",
       "      <td>102500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>137864.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>137864.00</td>\n",
       "      <td>15456290.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  salary  bonus  long_term_incentive  deferred_income  \\\n",
       "BELFER ROBERT        nan    nan                  nan              nan   \n",
       "BHATNAGAR SANJAY     nan    nan                  nan              nan   \n",
       "\n",
       "                  deferral_payments  loan_advances     other  expenses  \\\n",
       "BELFER ROBERT            -102500.00            nan       nan       nan   \n",
       "BHATNAGAR SANJAY                nan            nan 137864.00       nan   \n",
       "\n",
       "                  director_fees  total_payments  \n",
       "BELFER ROBERT           3285.00       102500.00  \n",
       "BHATNAGAR SANJAY      137864.00     15456290.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the order specified in the FindLaw report.\n",
    "payment_features = ['salary', 'bonus', 'long_term_incentive', 'deferred_income', 'deferral_payments',\n",
    "                   'loan_advances', 'other', 'expenses', 'director_fees', 'total_payments']\n",
    "\n",
    "inaccurate_payment_examples = inaccurate_examples(payment_features)\n",
    "inaccurate_payment_examples(enron_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we're able to find any examples where the `total_stock_values` feature is not equal to the sum of all the other stock features: `exercised_stock_options`, `restricted_stock`, `restricted_stock_deferred`, `total_stock_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>3285.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>44093.00</td>\n",
       "      <td>-44093.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>2604490.00</td>\n",
       "      <td>-2604490.00</td>\n",
       "      <td>15456290.00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  exercised_stock_options  restricted_stock  \\\n",
       "BELFER ROBERT                     3285.00               nan   \n",
       "BHATNAGAR SANJAY               2604490.00       -2604490.00   \n",
       "\n",
       "                  restricted_stock_deferred  total_stock_value  \n",
       "BELFER ROBERT                      44093.00          -44093.00  \n",
       "BHATNAGAR SANJAY                15456290.00                nan  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the order specified in the FindLaw report.\n",
    "stock_value_features = ['exercised_stock_options', 'restricted_stock', 'restricted_stock_deferred',\n",
    "                        'total_stock_value']\n",
    "\n",
    "inaccurate_stock_value_examples = inaccurate_examples(stock_value_features)\n",
    "inaccurate_stock_value_examples(enron_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both cases the same two names are reported to be inaccurate. This is likely the result of an input error so we'll have to correct this.\n",
    "\n",
    "In the original report, `-102,500` is listed as Robert Belfer’s deferred income, not deferral payments whilst `3,285` is listed as his expenses, and director fees listed as `102,500`, making total payments equal to `3,285`. Furthermore there is no listing for Robert Belger's exercied stock options whilst his restricted stock and restricted stock deferred are listed as `44093` and `-44093` respectively. Looks like everything shifted one column to the right. We’ll have to move it one to the left to fix it. The opposite happened to Sanjay Bhatnagar, so we’ll have to move his columns to the right to fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Robert Belfer...\n",
    "enron_data.loc[('BELFER ROBERT','deferred_income')] = -102500\n",
    "enron_data.loc[('BELFER ROBERT','deferral_payments')] = np.nan\n",
    "enron_data.loc[('BELFER ROBERT','expenses')] = 3285\n",
    "enron_data.loc[('BELFER ROBERT','director_fees')] = 102500\n",
    "enron_data.loc[('BELFER ROBERT','total_payments')] = 3285\n",
    "enron_data.loc[('BELFER ROBERT','exercised_stock_options')] = np.nan\n",
    "enron_data.loc[('BELFER ROBERT','restricted_stock')] = 44093\n",
    "enron_data.loc[('BELFER ROBERT','restricted_stock_deferred')] = -44093\n",
    "enron_data.loc[('BELFER ROBERT','total_stock_value')] = np.nan\n",
    "\n",
    "# ... and then Snajay Bhatnagar.\n",
    "enron_data.loc[('BHATNAGAR SANJAY','total_payments')] = 137864\n",
    "enron_data.loc[('BHATNAGAR SANJAY','restricted_stock_deferred')] = -2604490\n",
    "enron_data.loc[('BHATNAGAR SANJAY','total_stock_value')] = 15456290\n",
    "enron_data.loc[('BHATNAGAR SANJAY','expenses')] = 137864\n",
    "enron_data.loc[('BHATNAGAR SANJAY','exercised_stock_options')] = 15456290\n",
    "enron_data.loc[('BHATNAGAR SANJAY','other')] = np.nan\n",
    "enron_data.loc[('BHATNAGAR SANJAY','restricted_stock')] = 2604490\n",
    "enron_data.loc[('BHATNAGAR SANJAY','director_fees')] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check that we have fixed the issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistencies: 0\n"
     ]
    }
   ],
   "source": [
    "inconsistencies = len(inaccurate_payment_examples(enron_data)) + \\\n",
    "    len(inaccurate_stock_value_examples(enron_data))\n",
    "\n",
    "print('Number of inconsistencies:', inconsistencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incomplete Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in a previous section this dataset is plagued with missing values. Using the same Pandas DataFrame we can print out a list of all the features in the dataset alongside the number of values missing for that feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># missing values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_advances</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_fees</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_address</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           # missing values\n",
       "salary                                   51\n",
       "to_messages                              60\n",
       "deferral_payments                       108\n",
       "total_payments                           21\n",
       "exercised_stock_options                  45\n",
       "bonus                                    64\n",
       "restricted_stock                         35\n",
       "shared_receipt_with_poi                  60\n",
       "restricted_stock_deferred               128\n",
       "total_stock_value                        20\n",
       "expenses                                 49\n",
       "loan_advances                           142\n",
       "from_messages                            60\n",
       "other                                    54\n",
       "from_this_person_to_poi                  60\n",
       "poi                                       0\n",
       "director_fees                           130\n",
       "deferred_income                          96\n",
       "long_term_incentive                      80\n",
       "email_address                            35\n",
       "from_poi_to_this_person                  60"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data = enron_data.isna().sum().to_frame(name='# missing values')\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can see that every example in the dataset is labelled indicating whether it represents a person of interest. However no other features can be considerd complete. This will have the effect of causing difficulty for our predictive model to discover patterns from this data. The feature of largest concern is `loan_advances` which has only 4 values present in the entire dataset (~3%). Lets visualise the extent of the missing values in the form of a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family [u'sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAGkCAYAAACiis2fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3XuYXFWVsPE3JBiIBAVtGBSQW2YxyAeC3EQUgUHFEVFHVFSEgFcEYWBEkFEYHUZQUQG5DXcUQRAdwcELAspwVUEUURYggnKPA0ogAibk+2OfSlc6naTp6u6z03l/z5On+5yurlpVnVN11tlrrz1h7ty5SJIkSZLqtEzbAUiSJEmSFs6kTZIkSZIqZtImSZIkSRUzaZMkSZKkipm0SZIkSVLFJrUdAMCMGTNHtIXlSitN4dFHZ43kXY4o4+uN8Q1fzbGB8fXK+HpjfMNXc2xgfL0yvt4Y3/DVHBuMfHx9fVMnLOxn43KkbdKkiW2HsEjG1xvjG76aYwPj65Xx9cb4hq/m2MD4emV8vTG+4as5Nhjb+MZl0iZJkiRJ44VJmyRJkiRVzKRNkiRJkipm0iZJkiRJFTNpkyRJkqSKmbRJkiRJUsVM2iRJkiSpYiZtkiRJklSxSW0HIEmSJGlwex11xYje3xmHbD/k25588lfYYoutePzxx7nnnrvZffc9h/24//qvH+Xww49k6tSpQ/6d8847j7/9DXba6Y3Dftzh2nffD7Dvvgew/vobjPljD8aRNkmSJEkL+M1vfs1LX7ohN998Ixtv/LKe7usLXzjuWSVsALvttlsrCVuNHGmTJEmSNM8JJxzLT396Hffffz8f/OBe3Hffvdx44894zWt2YPr098932yOPPILJkydzzz138+CDD/KJT3yK733vu9x66y1ssMGGHHbYEQC87W07c9ppX2Xy5Ml86lOH8PDDD/PMM3PYc8/3scMOr+Wkk47nmmuuYuLEiWy++Vbsu+8BHH/88TzzzETe9a7d2XffD7DBBhvyi1/8nJkzH+fQQz/JxhtvwpNPPsmRRx7BH/5wNy95ydo88MD9HHTQx+cbIbvuumu49NJL+MxnjgLgppt+zvnnn8vnPvclvvCFz/Lb3/6Gp556iu2224G99/7gAq/Hjju+issu+18ArrzyR1x77dUcdtgRPPLIIxx22Cd46KGHAPjoRw9ko41exi9+cSPHHnsMABMmwAknnMqUKc/t6W9i0iZJUovaLH2SpMF85CP7s912O/CDH1zKfvsdyH77fYCTTjpjobefOfMxjjvuZK6++id8/OMHctJJp7P22uvwvve9lzvuSKZNi3m3veGGa3nhC/v4/OePBeDxxx/nscf+wlVXXcnXv34REyZMYObMmYM+zpw5czj11HO47rqrOeOMUzn22BP51rcuZOrUqZx99vncddedTJ/+7gV+b/PNt+Tzn/9P/vrXv7L88stzxRWXscMOOwLwgQ/sw4orPo85c+aw//4f5s4772C99aYN6XU68sgjefvb383GG7+MBx98kIMO2pdzz/0m5533NQ488GA22uhlzJo1i+c85zlDur9FWWzSFhFnAG8EHs7MDQf87F+BzwN9mfmniJgAHAu8AZgF7JmZN/UcpSRJkqQxc/vtybRpf88999zNWmuts8jbvvKVr2bChAmss856rLzyyqy77noArL32OjzwwAPzJW3rrLMeJ5xwLCeeeByvfOWr2HjjTZg9ezbPec5kjjrqM2y99TZsvfWrBn2cbbfdDoCIf+DBB+8H4JZbbmbXXXebd9+dx+42adIkttxya6655ipe85oduPbaq9lnn48CcMUVl3Hxxd9mzpw5/N///Ym7775ryEnbtddey2233T5v+4knnmDWrCf4f/9vY44//ku89rU7se2227HKKqsO6f4WZSgjbWcBXwHO6d4ZEWsAOwJ/6Nq9EzCt+bclcFLzVZIkSVLl7rgjOfLIf2fGjId43vOez5NPPgnAnnu+i1NOOYPJk5db4HeWXXZZAJZZZpl533e258yZPd9t11zzJZx++le57rpr5jU6mT79/Zx66tnceONP+dGPfshFF13AccedvMDjdEaslllmInPmzAFg7ty5Q3peO+ywI9/61oWsuOLz+Id/2IApU57L/fffx3nnfY1TTz2HFVdckSOPPIKnn356kN+eMO+77p8/88wzg74mu+++J1tvvQ3XXXc1H/zgdL785RN5yUvWGlKcC7PYRiSZeRXwyCA/+hJwMND9Su0CnJOZczPzeuD5EbFaTxFKkiRJGhPTpgVnnfV11ljjJXztaxfy8pdvzjHHHM9ZZ3190ITt2frTn2YwefJyvO51b2C33Xbn9ttvY9asWTzxxOO84hXbsP/+B3HHHbcv/o4aG230Mq644jIAfv/7u/jd7+4c9HabbPJybr/9Ni6++Ntsv/1rgTIyttxyy7PCCivwyCP/x/XXXzvo76688srcfffveeaZZ7jqqivn7d9mm2246KIL5m3fcUcCcN9997Luuuvxnvfsyfrr/wP33HP3kJ/PwgxrTltEvAm4LzN/GRHdP3ox8Meu7XubfQ8s6v5WWmkKkyZNHE4oC9XX9+y604w14+uN8Q1fzbGB8fXK+HpTe3xD0dZzqP21M77eGF9veonvkmN2GcFIBjcwvkceeYQXvGAlVl31edx//x/ZYouNF/q7yy23LCuuuDx9fVN56qnnMmnSxHn31/2ziROX4QUveC633norBx+8P8ssswyTJk3iiCOOYPnlJ3DQQQfx1FNPAXDYYZ+Ydx8rrDCZvr6pPOc5k3j+86c09/U3Jk5chr6+qbz//dM55JBD2Guvd7HBBhuw/vrrs8Yaqw76mu+ww/Z8+9vf5stfPobll1+evr6Xs9FGG7Lnnu9kjTXWYLPNXs7Uqcst8HgHH/wxDj30QFZbbTWmTZvGrFmz6OubymGHHcanP/1p9trrXcyZM4fNNtuMrbf+NCef/E1uuOEGlllmGdZbbz123vl1Pc9rmzCUIcWIWAv4bmZuGBFTgCuB12bmXyLibmCzZk7b/wCfzcyrm9+7HDg4M29c1P3PmDFzaOOaQ9TXN5UZMwafwFgD4+uN8Q1fzbGB8fXK+HrTVnzjoRGJf9veGF9vjK83Ncc3lNjmzJnD7NmzmTx5Mvfddy/77/9hzjvvW/OVabYZ37O8vwkL+9lwRtrWBdYGOqNsqwM3RcQWlJG1Nbpuuzpw/zAeQ5IkSZIW6amnnmS//T7E7NmzgbkcdNAhY5KwjbVnnbRl5i3AKp3tASNtFwP7RsT5lAYkf8nMRZZGSpIkSdJwTJnyXE4//atthzHqFtuIJCLOA64r38a9EbH3Im5+KXAXcCdwKrDPiEQpSZIkSUupxY60ZeZui/n5Wl3fzwU+0ntYkiRJkiQYwkibJEmSJKk9Jm2SJEmSVDGTNkmSJEmqmEmbJEmSJFXMpE2SJEmSKmbSJkmSJEkVM2mTJEmSpIqZtEmSJElSxUzaJEmSJKliJm2SJEmSVDGTNkmSJEmqmEmbJEmSJFVsUtsBSJIkSQPtddQVI3p/Zxyy/YjenzSWHGmTJEmSpIqZtEmSJElSxUzaJEmSJKlizmmTpMo5r0OSpKWbI22SJEmSVDGTNkmSJEmqmEmbJEmSJFXMpE2SJEmSKmbSJkmSJEkVM2mTJEmSpIqZtEmSJElSxUzaJEmSJKliJm2SJEmSVDGTNkmSJEmq2KTF3SAizgDeCDycmRs2+z4P7Aw8DfwOmJ6Zf25+diiwNzAH+Ghm/mCUYpckSZKkcW8oI21nAa8fsO8yYMPM3Ai4HTgUICI2AN4JvLT5nRMjYuKIRStJkiRJS5nFJm2ZeRXwyIB9P8zM2c3m9cDqzfe7AOdn5lOZ+XvgTmCLEYxXkiRJkpYqiy2PHIK9gG8037+YksR13NvsW6SVVprCpEkjOyDX1zd1RO9vpBlfb4xv+GqODYxvLLT5HGp//WqPbyjaeg61v3bG15va4xsK3/sWrub4ao4Nxi6+npK2iDgMmA2c2+yaMMjN5i7ufh59dFYvYSygr28qM2bMHNH7HEnG1xvjG76aYwPjGyttPYfaX7/a4xuqNp5D7a+d8fWm9viGyve+wdUcX82xwcjHt6gEcNhJW0TsQWlQskNmdhKze4E1um62OnD/cB9DkiRJkpZ2w0raIuL1wMeBbTOze5jsYuDrEfFF4EXANOCnPUcpSZIkSUupobT8Pw94DfDCiLgXOJzSLXIycFlEAFyfmR/KzFsj4gLgN5SyyY9k5pzRCl6SJEmSxrvFJm2Zudsgu09fxO2PBI7sJShJkiRJUjGUddokSZIkSS0xaZMkSZKkipm0SZIkSVLFTNokSZIkqWImbZIkSZJUMZM2SZIkSaqYSZskSZIkVcykTZIkSZIqZtImSZIkSRUzaZMkSZKkipm0SZIkSVLFTNokSZIkqWImbZIkSZJUMZM2SZIkSaqYSZskSZIkVcykTZIkSZIqNqntADR29jrqihG9vzMO2X5E70+SJEnSghxpkyRJkqSKmbRJkiRJUsVM2iRJkiSpYiZtkiRJklQxkzZJkiRJqphJmyRJkiRVzKRNkiRJkipm0iZJkiRJFTNpkyRJkqSKmbRJkiRJUsVM2iRJkiSpYpMWd4OIOAN4I/BwZm7Y7FsZ+AawFnA38PbMfDQiJgDHAm8AZgF7ZuZNoxO6JEmSJI1/QxlpOwt4/YB9hwCXZ+Y04PJmG2AnYFrz7wPASSMTpiRJkiQtnRabtGXmVcAjA3bvApzdfH828Oau/edk5tzMvB54fkSsNlLBSpIkSdLSZrHlkQuxamY+AJCZD0TEKs3+FwN/7Lrdvc2+BxZ1ZyutNIVJkyYOM5TB9fVNHdH7G2m1xzcUbT6H2l+/muOrOTYwvrHgsbtwtcc3FG09h9pfO+PrTe3xDYXvfQtXc3w1xwZjF99wk7aFmTDIvrmL+6VHH501okH09U1lxoyZI3qfI6n2+IaqredQ++tXc3w1xwbGN1Y8dgdXe3xD1cZzqP21M77e1B7fUPneN7ia46s5Nhj5+BaVAA63e+RDnbLH5uvDzf57gTW6brc6cP8wH0OSJEmSlnrDTdouBvZovt8D+E7X/vdGxISI2Ar4S6eMUpIkSZL07A2l5f95wGuAF0bEvcDhwFHABRGxN/AHYNfm5pdS2v3fSWn5P30UYpYkSZKkpcZik7bM3G0hP9phkNvOBT7Sa1CSJEmSpGK45ZGSJEmSpDEw0t0jJUmSpHFvr6OuGNH7O+OQ7Uf0/jS+ONImSZIkSRUzaZMkSZKkipm0SZIkSVLFTNokSZIkqWImbZIkSZJUMZM2SZIkSaqYSZskSZIkVcykTZIkSZIqZtImSZIkSRUzaZMkSZKkipm0SZIkSVLFTNokSZIkqWImbZIkSZJUMZM2SZIkSaqYSZskSZIkVcykTZIkSZIqZtImSZIkSRUzaZMkSZKkipm0SZIkSVLFTNokSZIkqWImbZIkSZJUMZM2SZIkSaqYSZskSZIkVcykTZIkSZIqZtImSZIkSRWb1MsvR8S/AO8D5gK3ANOB1YDzgZWBm4DdM/PpHuOUJEmSpKXSsEfaIuLFwEeBzTJzQ2Ai8E7gaOBLmTkNeBTYeyQClSRJkqSlUa/lkZOA5SNiEjAFeADYHvhm8/OzgTf3+BiSJEmStNQadnlkZt4XEV8A/gD8FfghcCPw58yc3dzsXuDFi7uvlVaawqRJE4cbyqD6+qaO6P2NtNrjG4o2n0Ptr1/N8dUcGxjfWPDYXbja4xuKtp5D7a+d8fWm9viGovbnMNLx7XzQd0b0/i45ZpcRvb+hWtr+bgsz7KQtIlYCdgHWBv4MXAjsNMhN5y7uvh59dNZwwxhUX99UZsyYOaL3OZJqj2+o2noOtb9+NcdXc2xgfGPFY3dwtcc3VG08h9pfO+PrTe3xDVXtz8H4FlT7/72Rjm9RCWAv5ZH/CPw+M2dk5t+AbwFbA89vyiUBVgfu7+ExJEmSJGmp1kv3yD8AW0XEFEp55A7Az4ErgbdROkjuAYzs2KwkSZIkLUWGPdKWmTdQGo7cRGn3vwzwX8DHgQMj4k7gBcDpIxCnJEmSJC2VelqnLTMPBw4fsPsuYIte7leSJEmSVPTa8l+SJEmSNIpM2iRJkiSpYiZtkiRJklQxkzZJkiRJqphJmyRJkiRVzKRNkiRJkipm0iZJkiRJFTNpkyRJkqSKmbRJkiRJUsVM2iRJkiSpYiZtkiRJklQxkzZJkiRJqphJmyRJkiRVzKRNkiRJkipm0iZJkiRJFTNpkyRJkqSKmbRJkiRJUsVM2iRJkiSpYiZtkiRJklQxkzZJkiRJqphJmyRJkiRVzKRNkiRJkipm0iZJkiRJFTNpkyRJkqSKTWo7AEm92+uoK0b0/s44ZPsRvT9JkiQNnyNtkiRJklQxkzZJkiRJqphJmyRJkiRVrKc5bRHxfOA0YENgLrAXkMA3gLWAu4G3Z+ajPUUpSZIkSUupXkfajgW+n5nrAxsDvwUOAS7PzGnA5c22JEmSJGkYhp20RcSKwKuB0wEy8+nM/DOwC3B2c7OzgTf3GqQkSZIkLa16KY9cB5gBnBkRGwM3AvsDq2bmAwCZ+UBErLK4O1pppSlMmjSxh1AW1Nc3dUTvbyh2Pug7I3p/lxyzy4je30hr4zWu4bGHovb4Fmdp+9t67C4djz0Utcc3FCP5HMbTseF7S288Nkaf8dXzuDUeu70kbZOATYH9MvOGiDiWYZZCPvrorB7CWFBf31RmzJg5ovfZhtqfQ1vx1f73rT2+ofBv25van4N/38HVHt9Q1fwc/L/XG1+/3tT+HIxvQUvb/71FJai9zGm7F7g3M29otr9JSeIeiojVAJqvD/fwGJIkSZK0VBt20paZDwJ/jIhodu0A/Aa4GNij2bcHMLLji5IkSZK0FOmp5T+wH3BuRDwHuAuYTkkEL4iIvYE/ALv2+BiSJEmStNTqKWnLzJuBzQb50Q693K8kSZIkqeh1nTZJkiRJ0igyaZMkSZKkipm0SZIkSVLFTNokSZIkqWImbZIkSZJUsV5b/kuSJLVir6OuGNH7O+OQ7Uf0/iRppDjSJkmSJEkVM2mTJEmSpIqZtEmSJElSxUzaJEmSJKliS1QjEiccS5IkSVraONImSZIkSRUzaZMkSZKkipm0SZIkSVLFlqg5bZIkPVvOh5YkLekcaZMkSZKkipm0SZIkSVLFTNokSZIkqWImbZIkSZJUMZM2SZIkSaqYSZskSZIkVcyW/9IQ2TZckiRJbXCkTZIkSZIqZtImSZIkSRUzaZMkSZKkipm0SZIkSVLFTNokSZIkqWI9d4+MiInAz4H7MvONEbE2cD6wMnATsHtmPt3r40iSJEnS0mgkRtr2B37btX008KXMnAY8Cuw9Ao8hSZIkSUulnpK2iFgd+CfgtGZ7ArA98M3mJmcDb+7lMSRJkiRpadZreeSXgYOBqc32C4A/Z+bsZvte4MWLu5OVVprCpEkTewzl2evrm7r4G7XI+Op87JFS83Pwb9ub2p+Df9/e1P4cao6v5tjA+Gp97JFS+3MwvroedySNxHMYdtIWEW8EHs7MGyPiNc3uCYPcdO7i7uvRR2cNN4yezJgxs5XHHSrjG1xf39TqX5uhqPk5+LftTe3Pwb9vb2p/DjXHV3NsYHwL47E7NoxvQUvb/71FJXe9lEe+EnhTRNxNaTyyPWXk7fkR0UkGVwfu7+ExJEmSJGmpNuykLTMPzczVM3Mt4J3AFZn5buBK4G3NzfYAvtNzlJIkSZK0lBqNddo+DhwYEXdS5ridPgqPIUmSJElLhZ7XaQPIzB8DP26+vwvYYiTuV5IkSZKWdqMx0iZJkiRJGiEmbZIkSZJUMZM2SZIkSarYiMxpk6RF2euoK0b0/s44ZPsRvT9JkjR2PC949hxpkyRJkqSKmbRJkiRJUsVM2iRJkiSpYiZtkiRJklQxkzZJkiRJqphJmyRJkiRVzKRNkiRJkipm0iZJkiRJFTNpkyRJkqSKmbRJkiRJUsVM2iRJkiSpYiZtkiRJklQxkzZJkiRJqphJmyRJkiRVzKRNkiRJkipm0iZJkiRJFTNpkyRJkqSKmbRJkiRJUsVM2iRJkiSpYiZtkiRJklQxkzZJkiRJqphJmyRJkiRVzKRNkiRJkipm0iZJkiRJFZs03F+MiDWAc4C/A54B/iszj42IlYFvAGsBdwNvz8xHew9VkiRJkpY+w07agNnAQZl5U0RMBW6MiMuAPYHLM/OoiDgEOAT4eO+harzb66grRvT+zjhk+xG9P0mSJKkNwy6PzMwHMvOm5vuZwG+BFwO7AGc3NzsbeHOvQUqSJEnS0qqXkbZ5ImItYBPgBmDVzHwASmIXEass7vdXWmkKkyZNHIlQnpW+vqlj/pjPhvH1xviGr+bYwPh6NdLx7XzQd0b0/i45ZpcRvb+RtrT9fUdSzbGB8dX62COl9udgfMNXc2wwMvH1nLRFxArARcABmflYRDzr+3j00Vm9hjEsM2bMbOVxh8r4emN8w1dzbGB8vTK+3hjf8NUcGxjfwvT1Ta3+tRmK2p+D8Q1fzbHB0ONbVHLXU/fIiFiWkrCdm5nfanY/FBGrNT9fDXi4l8eQJEmSpKXZsJO2iJgAnA78NjO/2PWji4E9mu/3AEa2bkaSJEmSliK9lEe+EtgduCUibm72fQI4CrggIvYG/gDs2luIkiRJkrT0GnbSlplXAxMW8uMdhnu/kiRJkqR+Pc1pkyRJkiSNLpM2SZIkSaqYSZskSZIkVcykTZIkSZIqZtImSZIkSRUzaZMkSZKkipm0SZIkSVLFTNokSZIkqWImbZIkSZJUMZM2SZIkSaqYSZskSZIkVcykTZIkSZIqZtImSZIkSRUzaZMkSZKkipm0SZIkSVLFTNokSZIkqWImbZIkSZJUMZM2SZIkSaqYSZskSZIkVcykTZIkSZIqZtImSZIkSRUzaZMkSZKkipm0SZIkSVLFTNokSZIkqWImbZIkSZJUMZM2SZIkSaqYSZskSZIkVWzSaN1xRLweOBaYCJyWmUeN1mNJkiRJ0ng1KiNtETEROAHYCdgA2C0iNhiNx5IkSZKk8Wy0yiO3AO7MzLsy82ngfGCXUXosSZIkSRq3JsydO3fE7zQi3ga8PjPf12zvDmyZmfuO+INJkiRJ0jg2WiNtEwbZN/LZoSRJkiSNc6OVtN0LrNG1vTpw/yg9liRJkiSNW6PVPfJnwLSIWBu4D3gn8K5ReixJkiRJGrdGZaQtM2cD+wI/AH4LXJCZt47GY0mSJEnSeDYqjUgkSZIkSSNjtOa0SZIkSZJGgEmbJEmSJFXMpE2SJEmSKjZukraImNh2DJIkqX0RMTEi/qXtOCRppIybRiQR8Xvgm8CZmfmbtuPpiIh1gXsz86mIeA2wEXBOZv653cjmV3OcEbEr8P3MnBkR/wZsCvxHZt7UcmjzRMT+wJnATOA0YBPgkMz8YauBscS8fmtl5t0D9m2emT9rKSSNkIj4e+AkYNXM3DAiNgLelJn/0XJoVR+3HRHxSuDmzHwiIt5DOX6Pzcx7Wg6NiPgc8B/AX4HvAxsDB2Tm11oNrBERP87M17Qdx5ImItbPzNsiYtPBfl7LZ0fNxwbU/d4HEBGrAv8JvCgzd4qIDYBXZObpLYe2RJy3tGG01mlrw0aU9eBOi4hlgDOA8zPzsXbD4iJgs4hYDzgduBj4OvCGVqNaUM1xfjIzL4yIbYDXAV+gvBFu2W5Y89krM4+NiNcBfcB0yslgDSd/S8Lr962I2Dkz7wOIiG2BrwD/r62AIuLLmXlARFwCLHB1KzPf1EJY8ywsro624+tyKvAx4BSAzPxVRHydcrLftpqP246TgI0jYmPgYMr78znAtq1GVbw2Mw+OiLcA9wK7AlcCVSRtwDUR8RXgG8ATnZ1tn/hFxNWZuU1EzKQcwxO6v2bmim3GBxwIfAA4ZpCfzQW2H9twFqrmYwPqfu8DOIvyfndYs3075VhpPWmj8vOWiHgrcDSwCuW4HZNjd9wkbZk5k3KAnBoRrwbOA74UEd8EPpOZd7YU2jOZObv5UPtyZh4fEb9oKZZFqTnOOc3XfwJOyszvRMQRLcYzmAnN1zdQRnt/GRETFvULY2hJeP0+CPx3ROxMuaL2n7R/weCrzdcvtBrFwnXieivwd/SfKO8G3N1GQAsxJTN/GhHd+2a3FcwANR+3HbMzc25E7EIZRTg9IvZoO6jGss3XNwDnZeYjA/7Obdu6+frprn2tJx2ZuU3zdWqbcSxMZn6g+bpd27EsRs3HBtT93gfwwsy8ICIOhbLGckTMWdwvjZHaz1s+B+ycmb8dywcdN0lbM6ftnyhXSteiXCE6F3gVcCnw9y2F9reI2A3YA9i52bfsIm7flprjvC8iTgH+ETg6IiZT33zMGyPih8DawKERMRV4puWYOqp//TLzZxHxUcoIx5PAjpk5o+WYbmy+/iQinkP/e0hm5t/ai2xeED8BiIjPZOaru350SURc1VJYg/lTU349FyAi3gY80G5I89R83HbMbE6qdgde1XzW1fLefElE3EYpj9wnIvoox28VloCkg2aU6FXN5lWZ+as24+kWEcsCHwY67y8/Bk6p4f2vUfOxAXW/9wE8EREvoD++rYC/tBvSPLWftzw01gkb1PUC9OoOYBfg85m5SWZ+MTMfysxvUmrt2zIdeAVwZGb+PiLWpp7SkW41x/l24AfA65s5ditTSg5qsjdwCLB5Zs4CnkN5TWtQ7esXEZdExMURcTFwKDAFeAo4vdnXumaO5x3ACcCJwO3NaH4t+iJinc5Gc+z2tRjPQB+hlAetHxH3AQdQTgRrUPNx2/EOyjGxV2Y+CLwY+Hy7IRWZeQjlc2Oz5kR+FuVzuAoRsWpEnB4R32u2N4iIvduOq6OZU3kupcRqFeDciNiv3ajmcxLwcsr73onN9ye1GtH8qj02GjW/9wEcRJkKs25EXEMpLa3l/1+15y2Nn0fENyJit4h4a+ffaD/ouBhpa66unJWZnx7s55n50TEOqfuxfxMRHwfWbLZ/DxzVVjyLsGP369Qkbn9tM6Aup2Tm7p2NzHygmQBfzbyTzHwmIh4CNojmci/kAAAgAElEQVSI2o6rFwI/B4iINZt9t7UXznxqLT3sdgxl7k7CvMnl51FOYGrwL8CPI+KuZnstSrlpFTLzLuAfI+K5wDJNKXst5gIbAG+klNA9F1iu1YgGyMwHI+IiYFqz60/At1sMaZ6ImEI5MV2TMgfqRUAA320zri5nUe+cHSgXDbbMzCcAIuJo4Drg+Faj6rd5Zm7ctX1FRPyytWgGqPnYgOrf+8jMG5v540EpFa+iiqSxGvA/A5vjtRvSfFakXKR6bde+ucC3RvNBazu5HJbMnBMR2zF/3XoVmjk6X6BcwV07Il4GfLqiJgEdewDHDti35yD72vDS7o0mSa/lhBmY92H7DuA39NdizwVqKFP7H/onuS9HKQVLBryubegq8VsbeCAzn2y2lwdWbTO2Lst2EjaAzLy9KRuqQmZ+PyKmAes3u27LzKfajKlbRHxqwDYAC7vINsZOpJRDbk/5/JhJacq0eZtBdYuI91MSopWBdSmjCScDO7QZV+NM4Eb6547dC1xIPUlbzXN2oLwnd8czh/55ljWYExHrZubvAJoR/Wpev8qPDSLi+cB7KRfSJnW997U2kNCtScC/AXyj8zeuSM3N8cjMVioyxkXS1ri2xi5RwBHAFpRacDLz5uYEtQrNPLZ3URLK7nK0qcD/tRNV0XzQfgJYPiI6XUAnAE8D/9VaYIN7MxA1nSx3ZOZ8HRijtHGuZiSmcSH9J35QTgwupI6T559HxOn0NyZ5N+VEtQrNaMeBwEsy8/0RMS0iIjNrOXF+ouv75SijWmM+F2AhtszMTTtNlzLz0Wb+Yk0+QvkMuQEgM++IiFXaDWmedTPzHc3nCJn518oaudQ8ZwdK0ntDRHyb8tm2C/WMAkIpR7tywCh+TeXDNR8bUPopXA/cQn1zZQHeRLnYfEFEPEM5f74gM//QblhAf3O8t1JfczwiYnXKiPgrKe8vVwP7Z+a9o/m44ylpq7JLFKW70V8GdA+qaXG8aykTY1/I/O19ZwKtTojOzM8Cn42Iz2bmoW3GMgR3USZAV5e0DZSZN0VEDclQt0mZ+XRnIzOfrujk+cOUk4OPUk6srqKM0NSiM9rxima7qtGOzJyvbXhEfIFy1bQGf2tG7jsn9X3Ud3L1VHM8ANCUX9fyGfJ0Myreef3Wpa73wAOZf85OH/C2dkPql5lfjIgfA9s0u6ZnZjUnpsA1lDlZnZGrUyjlm7Wo+dgAWC4zD2w7iIXJsp7d54DPNdUan6S0sZ/YamBFpznee6mvOR6Uz92vU5Y5AXhPs2/H0XzQcZO0Vdwl6tcR8S5gYnNQfJSSKFWhOWjvof+ErzqZeWhEvBh4CV3/ZzOzhtLDjlnAzRFxOV0nLTWUQURE94fGMpSW+q12ZhzEjIh4U2ZeDBClhfOfWo4JgKam/ivA5ZQT+uxOMCtQ+2jHQFOAdRZ7q7FxHGUOzCoRcSTlhP7f2g1pAT+JiE7FwY7APsAlLcfUcTil0dcaEXEu5arznq1G1KW5QFXrnJ1uEyjvLbUdt+cAjwGfabZ3o1Qc7LrQ3xhbNR8bAF9tSji/y/znBY+0F9L8ImItStOPd1AqXA5uNaB+04EPUWdzPIC+zDyza/usiDhgtB903CRtABHxT5R5OvMmklcwb2I/yiTopyjNC35A/xtgNaKlhQKHIiKOoiycXuN8sY6LqWf0YKDutYBmU+a4XdRSLAvzIUrntBOa7T9S2ji3rnlfORn4HeW4WDsiPpiZ32s3snmqHu2IiFvov/o9kTLa0fb7MgCZeW5E3EgZSZgAvLmNNs6LcQilYcUtlLLmS4HTWo2okZmXRcRNwFaU12//zKziYkuXLWjmFAGbRgSZWUVDg2a+566U9+MJwJkRcWFm1rL4cgxoRHJlTY1IqPjYaDxN6WZ5GP3vgXOp5KJVRNxAGb26ENi1aZxShSWgid+fIuI9lPN6KBc0Rn1K0bhJ2iLiZMoV3O0oB+3bgJ+2GhTQtJE+jP7uVbVqZaHAIXoLlc4X68jMs6PCtbwAMvPf245hcZpJ0FtFxArAhMq6bB0DbJeZd8K8pOh/gFqStqpHOyhz2DpmU9a3qWKB2eZv+fvMPKHpULZjRDzQtJiuxfLAGZl5KsxrxLQ8ZXS/Vc38WOhfe2rNiHgecE8Nf+OI+CqlQcXNzH/Br4qkjXKit0lXA6ajgJuAWpK2X0TEVpl5PUBEbEkpmaxC07X5a5T17XKxvzD2DgTWq/BCRscemVlLJ+n5LAFN/PYCvgJ8qdm+ptk3qsZN0gZsnZkbRcSvMvPfI+IYRrn15lBExCUsWGP9F0oL9lM6b9YVaGWhwCGqfr5Yc8J3NnA35YrpGhGxRw0lnFFa1P8r/VebAcjMtud7ztOc6B1Os4hrRPyE8gZdQ9OAhzsJW+Mu4OG2gunWlEHeBryVykY7ImLl5tuBCfiKzWhHDSVC3R3KTqOUVlXToaxxOWWB2ceb7eUpy51svdDfGDsnUsqtf0X5v7dh8/0LIuJDmdn2siybARtkZk3znLrdTakM6pwHTKaM6NdiS+C9EdFpTLEm8NvO6HlmbtReaBARb6KMZNV6Yn8rFVxcGSgi3pOZXwPeEBELvNdl5hdbCGugI6i4iV/TrGXM/5+Np6Sts6bYrIh4EWWYsoY/8F2UcqDOEOo7gIcoIzKnUkkJGM1CgcB/M3/tdeuJLxXPF+tS81peF1LK+06jonbNA5wB/JpSWw/luDiTkoy07daIuBS4gHIBZlfgZ01JcavHSGbOjYj/zsyXU0b/anIj/UtNDFRLiVB3h7Jja+tQ1lguMzsJG5n5eNMxtAZ3A3tn5q1QFq+mdBz8DOWiadtJ26+Bv6N/JLA2T1HeXy6jHBM7AldHxHFQxWfc61t+/MU5nAVP7NdqM6AB5lDOXa6krnOX5zZfpw7ys1oucFTdxC/KWsH/Qck9vg9sDBzQJMOjZjwlbd+NsibG5ynlBXOpo7Z5k8x8ddf2JRFxVWa+OiJubS2qBbWyUOAQ1TxfrKPmtbxmZ+ZJbQexGOtm5j93bf97RNzcWjTzW45yoWXbZnsGZV2gnanjGLk+IjbPzJ+1HMd8MrOGi2aLU3uHMiht6zfNZvmaiHg5/Rcp27Z+J2GDefNQNsnMuwacbI2prgqXqcBvIuKnzH/SXMtIzLeZfzHoH7cUx6CaRmU1G+zEvib/3fyrSmae0nz7o8ycr9w1Il7ZQkiDqbqJH+Ui/cER8RZKx+ZdgSsZ5WYp4yZpy8xOc4+LIuK7lKuTNZRW9UXEms1QKhGxJqW9PpRJqlXIlhYKHIpmvtjywJqV1q1D3Wt5XRIR+1BODqrsYAX8NSK2ycyrYd4HRxUnpos7NiLi0CzLU7RlO+CDEXEPZU20ThOhVkuXukXESsA05m8S1XrpMPV3KAM4ALgwIu5vtlejVGzUICPiJOD8ZvsdwO0RMRloc07vF1p87CHLzLMX9fOIuGjAxSzNr+oT+5rnujeOp5Q3L25fG7qb+H2d0sSvlrme0H9x7w3AeZn5yFhcPFjik7ZOidJCflZDed9BlHKHeZ3ngH0i4rmUOVBVaMr5TgJWzcwNI2Ij4E01dLFaAiakQt1ree3RfP1Y175aytM6PgSc08xtA3iU/rhrtyvQZtK2U4uPvVgR8T5gf2B1SkOIrShrPbU+pzIzf0M5ZjvbtXUoIzN/FhHr09+2/raKTvz2pLRZP4AS29WU+bN/o1xMaEVm/gQgIo7OzI93/ywijgZ+0kpgz15N79E1qvrEvta57hHxCsqc2L6Yf0mgFalgjbam2dK/Z+bHqLeJ38URcRvl4vI+Udb4HPUeFUt80kZ/SctgWi9dysxLmytA69P/gdv5w365vcgWcCrlpP4UgMz8VUR8nTreAI+g4gmpUNbyAr7Y/KvKElKm9lhmbhwRKwJk5mO1/Y0XobW1lSJiGeB/MnPDtmIYgv2BzYHrM3O7JgGpoqNpM6J7BP1rQHZGKWs7Wd6c/kZCm0Qlbesz86+U+bzHDPLjxwfZN9Z2BD4+YN9Og+yrVTVzeGoSEV/NzN2B92dmzd25a53r/hxgBcr7Sfe8tseoYPH5zJzTlIFXqfncvYTSdf2xJt5ZwC6j/dhLfNJWc1lfl2mUq6TLARvV8oE7wJTM/OmA4d3WWzY3qp2QGhEXZObbY/61qOapoUStmVv3YZrOjJTk95SKrtZD6eK3aWY+1rXvm7T/4TYUrf1fbFpe/7K7BLtCT2bmkxFBREzOzNuinkkopwP/QillrrJJT1Tctr65IPlZYAPmL31tNemNiA9TRgDXjYhfdf1oKhWVz2nYXh4RLwH2iohzGHDhrKLS/yrnujcj0T+JiLMqnrf4i4i4mNJI7YnOzgqq5zqfu8dk5iu69j1BV5yjZYlP2rpFhYtrR8ThwGsoH2qXUq7yXU0FH7gD/CnKmkWdBXrfRj0dt2quW9+/+frGRd6qXSdR6q875Zq7N/ve11pEjWbU5aXA8waUOq9I13FcudZG2hqrUTrQ/ZT5P9xqKR++t2kS9d/AZRHxKHD/Yn5nrPwl61kkfWFqblt/JqWD35co5ZDTaf94gFIq9z1KQnkU/Resrs7M2rqDLkoNr2WNTqZ07FuHcsGl+3WqqfS/5rnuAJMj4r+oczmglSld4Ltjab16rssPI+KfgW+N5XvzuEnaotLFtSlxbAz8IjOnR8Sq1NHVcqCPAP8FrB8R9wG/B97TbkjzdNetn0epW//MIn9jjGRmJ7HdZyFzJ2oow9k8Mzfu2r4iIn7ZWjTzC0rC+3zmL3WeCby/lYievQtbfvwqSg0XJjPf0nx7RNP6+nmUE64aXBkRn6ecCHQ36bmpvZAWUHPb+uUz8/KImNBcsT8iIv6Xksi1pmlC9peIuJ7SWOZblBP7syPi1Mw8vs34ui2mUUUNnx/VyczjgOMi4qTM/PDCbhcRK2Xmo2MY2kA1z3WHipcDWgKq6A6kLJ0wJyL+Sn9p/Yqj+aAT5s6t8eLdsxdlUe2Nur6uQMmAX7vYXx7duH6amVtExI2UhHIm8OvMfGmbcS1M0yBlmcwcuCCuFiEibsrMTQfs+1Ul5ZE3Abtm5u+a7XWAbw6Mt00R8YrMvK7tOAbTTDB+PwtejdyrrZgGakqFpmXmj6Ks4TWxlmM4Io4FvpGZtYyOz9MkkQPNreRKMzAvxpdRLkJW1bY+Iq4BXkUpZb4CuA84KjOrKH9tSiNf0ZQudT7frqvhfRkGb1QBtN6oYrwY7HN5jB//uZTy8DnN9kRgcmZWseB2RNyYZY3PakTE8SxiykG2v8Zdq8bNSBv9XVs6i2s/Qh2La/+8KQ06lTIs/jh1jADOp4nxvTQnpp0pJzUcIBGxGfAJFjxpbv2Dt2vuxDqDzJ24ZvDfGnMfo4wo3NVsr0UpY6rJW6KsWzimC1UO0XeA/wV+RGVXIwEi4v3AByjlJOsCL6ZcPd2hzbi63AT8WzMJ/9uUBO7nLccEQGa21uHwWTii7QAW4QBKhctHKdUP21NX19cJzH/MzqGuksNaG1WMF23/rS8H/pH+pjzLUxac37q1iOZX43JAnc+GV1KmFX2j2d6VikpLI2ICpdx17cz8TESsAayWmaN6fj+ekrZLYsHFtU9tNyTIzH2ab0+OiO8DK2bmrxb1Oy25FLgeuAV4puVYBjqXknjUGFv33IlDuvbPrGgy9DWUrqCdk/hTKC3Xa9LKQpVDNGVg6WtlPkLprnoDQGbeERGrtBtSvyxrUZ0dESsD/wwc3TROmdZyaDTl6v8JvCgzd4qIDSgjM6e3HNo8nfb1Ncr+Bd0fj4i9gRUGNBNq25nADRHRWcD6zZTmM7WoslHFONJ2KdlymTmvi2pmPt5UQtSiuuWAms8LImJPYLtOuXAzBeqHbcU1iBMp56PbUy5YPQ6cQOn0O2rGU9J2GzAnMy9qPng3pYKV6JuW0jc35RnbAJtGxLEVduxZLjMPXPzNWjEjMy9uO4jBdOZOALtFxKaUv/FcSqJUS9J2DqWVb2ce4G6UidG7thbRglpZqHKIvhsRb8jMS9sOZCGeysynO69XREyi/ZOVwaxHWfpkLeA37YYyz1mUE/tOy/DbKVd2qzmxj4itKAve/gOlVfdE4InRnjsxFFGWhfkQZQTrRkpDoS9m5ufbjazIzC9GxI8p78sTgOmVNSKpvVGFevNERGzamSPbtLH/a8sxzZN1Lwf0IkrFUuc8aoVmXy22zMxNI+IXAJn5aDM/dVSNp6Ttk5l5YURsQ1mb5RhKh7wt2w2Lk4CNI2Jj4GDKycA5wLatRrWgrzZlVt+lnmHyjsMj4jRKqUF3bLV0ESIiPgm8nf7ORmdGxIVZweLkQAxoRHJlRY1IOi6JFhaqXJSImElJfiYAn4iIpyiLBo/JhONn4ScR8Qlg+YjYkVKue0nLMc3TNOR5K/A7SkL0mcz8c7tRzfPCzLwgIg4FyMzZEVFbCexXgHdSmgZsRiljb32UsrFBljUV302p1vg4JemoImmDeU1lamos022wRhUntBrR+NJ2eeQBwIUR0emWuxrwjhbjmU8z6ncgsGZmfqDpzh2Z+d2WQ4PS9fUXXfOOt6WuUvG/NXMUOx3X+xiDSrDxlLR1Pmj/CTg5M78TEUe0GE/H7MycGxG7AMdm5ukRUVPNf8fTlA/aw+i/Sl9L69zplCv0y9J/UNTU+hXgXcAm2SycHhFHUU4UakjafhERW2Xm9QARsSX1zLcDIDMPaU7uB12oMiJ2zMzLxjimqYu/VRUOAfamlA9/kHLyXFOH2t9TSg7/NNgPI+KlmXnrGMfU8UREvID+D96tKCPnVcnMOyNiYtPQ4MyIqKWpy7JNOd+bga9k5t8iosZR3lp9KDO/CHyxsyMi9geObS+kJUOUBY5/lZkbLuJmrc7rzcyfRVnWJigJ5G1Z1/qoZ1IusnTm2N1LuTjUetKWmWdGxPfoH3g5JDMfbDOmAY6jzAVcNSKOpHSK/7fRftDxlLTdFxGnUCZ9Hh0Rk4FlWo4JYGZzFfc9wKubzLzGmvUDgfUWdmLVso0z8/+1HcRi3E1ZV6wzOjSZMrLQmuhf8HtZ4L0R8Ydm+yXUU542T3dr5lxwocqjgTFN2joi4vLM3GFx+8ZaVwyfbebctT6HdzCZefJibvJVSjl7Gw4ELqYswnwN0Ef58K3JrKbs5uaI+Byl9f9zW46p4xTKe98vgauaLqY1zWmr3R4smKDtOcg+DZBlgeNfNvNj/7CQ29RQKbQ5/U3UNokIMrOWdXrXzcx3RMRuAJn516bBRmuaaSbd/th8fVFEvCgrWY4lM8+N0hW+cx7w5sz87Wg/7nhK2t4OvB74Qmb+OSJWY/7JlW15B2UUZu/MfDAi1qSi0pEutwJVtKEdxPURsUFmVpdodHmKssDxZZTEaEfg6og4Dlrrwlnzgt/P1ph/kETEcpST4xdGxEpdMaxIHbX1q0XEtsCbIuJ8BrxGtXy4DUFrJwmZeVPzGnauhGdlV8IBdqdcgNwX+BdKW/h/bjWiRjbrZXXtuiciloSOnK1qTpLfBawdEd3ztadSFhTW0KxG+dz9KV0X+WpYDgMgIr5K6eh7M/3VYHMpU2Rq8HRELE9/pcG6dE1BackxzdflKOXgv6S8N29Eaba1TUtxDWYKZY7xXEpn0FE3bpK2Zt2Lb3VtP0Adi5HOpJRFzmna+a5PaelbmzmUK7lXMv+8sdZb/lMO0j0i4veU2Dpzilpv+d/l282/jh+3FMc8FTa76UUbJVcfpMxJeBHzz4l5jDrmnXyKUhq5Ol3lVY25lK5WS4LWyumaxHwf+hsI/W9EnNwpc67EpsClTVfGqhZSb0r5zqR8zp0GbEL5P1lTl7caXUs5P3kh/SepUF7HGrtL16qq42EQm1HmfdZaMnw4ZYmdNSLiXEqb/T3bDKizDEtzIfIDmXlLs70h8K9txtYtIj5FaeZ2EeWcdEz6GIybpK1iVwGvaq7UX05Zg+IdlC5RNflvKui2uRCvbzuAxcnMs5sSpr/v31XdFXs9C5l5LHBsROyXmce3Hc9AmflN4JsR8cnM/Mxif0GDOYdyotz5+9bYWfVNwJcj4irgfOAHmTm75Zg69srMYyPidZTS0umUJM6kbRGaC2r3AK9Y1O0i4rrMXORtlmaZ+ZNm2Y5Om/WfZubDbcY0wK+Bv6OOAYQFZOZlEXETsBUl8di/oiky63cSNoDM/HVEvKzNgAbYjRb6GJi0jb4JmTmrWcPm+Mz8XETc3HZQg/g/ytXc2tZBA9gPOKPm8siIeA1wNmV+xwTKlas9MvOqNuMaR+4e6weMiO0z8wrKfNm3Dvx5Rd1Lj4yI9wDrZOanmxLsv8tRXuRzBD3d4mNX31k1M6c3zT52opTUnRgRl2Xm+1oODfpLW98AnJmZv2x7Tsw4s1zbAdQsIt5OmW7yY8r/xeMj4mPNBa0avBD4TVO+2V3BVEv55luAKzLzf5rt50fEmzOzhgv4v226hn+NUgXxHmDU54w9C3fTQh8Dk7bRNyEiXkEZWdu72TexxXgW5p2UUYWLKB++NR0ctwGnRll/6kzKOl61dXg7hrJAdAI0pbDnAS9vNarKDZYMdeskRpm5yNuNkm2BK4CdB/lZTd1LT6B/kc9PU0aOLmKUF/kcqoj4dGZ+qmt7InBOZr4bIDO3ai24JaCzKkDTlfF79M+d2AWoIWm7MSJ+CKwNHBoRUxmDttdLkVrL6mpxGLB5Z3Stabv+I6CWpO2ItgNYjMMzc960jqYfxOHUUXU1nbIkxv7N9lWUJbRq0UofA5O20XcAcCjw7cy8NSLWAa5czO+Mucx8T0SsSBnyPbNp29xJkGa2HNtpwGkREZQD+VdNp7dTM7OW13LZTsIGkJm3N1fHtWidhGgVStvhK5rt7ShXT1tLjDLz8Obr9LZiGKJWFvl8FtaMiEMz87NNV98LqWfdrC3p76wKsCblCu8tVDJvNiJeT7mo1jkmTqM03qrB3sDLgLuaipIXUN6jpbGwzIByyP+jjq7hQCnfbDuGxRjstaoiL2jKDr/U/KtRK30MqvjjjGfNQfuTiHhus30XZSHN6mRZJPUiypXcA4C3AB+LiOPantPTXJ1fv/n3J0pHoQMj4oOZ+c42Y2v8PCJOp8yHgTKyemOL8SwROglRRHyXMmH7gWZ7Nepo9kFE/A64Hvhf4KoKy3RbWeTzWZgOnNssfbId8L3MrOWDuPr5spTGAOcDH8zMtju7DTQX2IDSqfbTlG6rlvSNHEtNF+37EfED+pu7vQP4XovxABARV2fmNhExk/lHSztN1FZsKbSBfh4RX6R81s6lTEWp4rwlykLfn6W8v8x7T8nMGtYOJjPPXtTPI+KizBzxLr8mbaOsKY08HViBcsV5Y8qH7z7tRja/iNgZ2IvSnvarwBaZ+XBETKHUEbeWtDVvKm+iNHL5z665OkdHRC78N8fUh4GPUBLyCZSh/BNbjWjJslYnYWs8RH9Tl7ZtQBmReRXwhSiLpf4yM9/SbljzdBb5XCXGcJHPxRmw3s6xlDW9rqFcxNq0kiUJpmXmj7p3NHNRF/mBPJYquSi1MCdScWnuOLB72wHULDM/1pTYb0P53P2v7nK/tmTmNs3XqYu6XUSslF3rk7ZgP+CTwDcor98PKecxNTiT0t3yS5SLfdNZsi5ijEpyadI2+r4MvI6ygCvNRO1XtxvSoHYFvjSwcUZT8rJXSzF1/Br4t2ZZh4G2GOtgBtNcAf8iC7ZeB0bvqss48uOuK6ZzKeVgtZS+zgH+1nx9hpJQVtOhLOdf5HMCY7TI5xAcM2D7UUoCfAz1LEnwqYj4Z0or6RUopYdPUZoKtWqQq/TzqeRqfe2luVVrEo6jKeXhExgwEpOZv24xvOpFxNGZ+XG6yui79i0JLqcs6dGKzHyCskRHjZbPzMsjYkLTbfWIiPhfSiK3JBiV+agmbWMgM/9YpmPNM2dht21LZr53ET+7fCxjGeTxz4iIlZp1OrqHya+qsCHJwlQxpF+rzNy36WTVuaBRxRXTxmPALZSE/NTMrGLx24hYuWvzYbrWf4yIlTPzkbGPql826+1UblvgIMritwCfyswq1tHsXKWPiE8DD1IqICZQSq8XeQV/DNVemlu7zwE7V3KRZUm0IzAwQdtpkH21anXkqGmY9q/AWnTlA5lZwwW1JyNiGeCOiNgXuI9ycWOpZtI2+v4YEVsDc5srkB+lrralAETEVpQSyH8AnkPpcPlEDVdzI+J9lA5Cq1NOrrYCrqOOK/VDZRewxbsJmJmZP4qIKRExte0mOI3dKOU3+wDvi4hrKXPbWr2YQZl7MJfywb8mZSRrAvB84A+Ujn6ti4j/BD6XmX9utlcCDsrM1ks4gZUopa+/o7y/vKS5slvT8fq6zNyya/ukiLiBcsLftipLc5cgD5mwPXsR8WHK+/G6EdG9GPlUysLlS4q232cuBE6mVBjUNphwADCFcs78GUqJ5B6tRvTsjEpCbtI2+j5Emc/xYuBe6qoZ7vYVSknahcBmwHuB9VqNqN/+lDkS12fmds2con9vOSaNoIh4P/ABYGXKvMoXUz5MdmgzLoDM/A7wneb/3U6UD5ODKQ172oxrbYCIOBm4ODMvbbZ3Av6xzdgG2CkzP9HZaEro3kAdJ/fXA0c1o/nLU0rVrqF0Mq3FnIh4N6UZyVzKRYQqTrAqLs1dUvw8Ir5BabHevY5XLcuJ1OrrlIYjn2X+8r6ZbVcYLGFmZ2ZNbfTnycyfNd8+ziAdaSPi+Mzcb2yjGlxzIXKNzOy+gDAqo70mbaMsy+ry7247jqHIzDsjYmJmzqG0/a/litWTmflkRBARkzPzthhQb7oEWJIm0LbhI5T5iTcA5P9v787D7arq+4+/E0CZofwEigKSoHyoVZDppwwOIKF1AEQmURCkVUYJolEUNAxSBAUEtAhKAzLYMhghyjzLYJF5KHyqIghCy6QkzBHSP9baybk3N/eeJPfctWQ9tqgAACAASURBVHbyfT1PnsvZN+F+H8g+Z6+1voP9W0lVpELkjqrvBn5H6iD5GXKcldjI9t7NC9uXSjqyZED9LJLv21cA8uLojYVjamwJfEDSN50Gk3+XlCpUk0+RNv5OJC3absrXavG/pPtiUWCJiprMtMGywIvAVh3XapoBWaVcFvGcpBOBZ5uMDEnLSHqP7ZrenwdT+rlgiqR9SaflnZsGbVj4blryh0u6jtQgb1FSBthTkq63fRCA7St68XNj0dZjksaQOvSsQd+c4W1KxTQHL+b0zbskHQs8QWrfXIPHJC1P2o28UtKfgccLx9SHpA1s397v2ta2p+SXbcmxL+UV2682a3GlQeqlU0ca3wbuyJsZs5E0zvaVIxxTp6clHQqcTfpvtitpXlEtzgauljSJFN+eVNDoI/sas3c/PI6Kuh/afpg0TLs6eXNgD1J6aXO/1tJkpnotmAFZu1Po28jjhQGujbh+9caz6VgUlc4kadINJ3Rcm0HU4HdjuTwm65+BSbYn9kvV7YlYtPXez0kt/6dQd4H2bqRBi/sDXwRWA6rodtjRWv0wSdcCywGXFQxpID/KrcLvBZC0CymNbgr0btdlAXK9pK+TdurHkeoVpgzxZ0ZER5rGnBwDlFy07ULqqDWZ9IF7Q75WBdvH5g+zJmXzSNuXl4ypQ/XdDyUtThpi/ff0bcRUuqsvpCHfa9p+tXQgbSRpVVIt+aake/dGYLztx4oG1h596k9tv543/Errqt649IlWk2If5smieZ7sTsAhI/ZDR+oHLcRetn1S6SCGYvuR/LCyBik1wzV9EOeZT5uR04Nqii3bAbgg155sRkqh22rwPxI6HEx6ML0X2Au4xPaPyobUtaIpLvmDf/ycvl9J7v+dwGKk+/fOwrF0akP3w7OAB0mjY44gpdvXUjd2H+lBtJoRGC0ziVSftWN+vWu+Nq5YRO3ykKQDSKdrkDb7HioYD1B/vbGkLWxfk0dOzKYlNZWlU0uPAC4HbrT9G0ljgd/2+ofGoq33TpQ0kdSApDNnuKqcf0kfJTV++D3pZhgjaS/bl5aNDCR9k/Sh1ryRTJJ0vu1vFQyrD9sPSfok6WT1UWAr2y8VDqtNvmD7RGDmQk3S+HytdrWkcc5J6dz/nYDvANeR3ltOljTB9gUl48ra0P3wbbZ3lLSt7TMlnUt6WKjB0cCdku6j7+dbben/tVrR9qSO12dIOrBYNO2zN+kePpT0Pnw1qaFVLWqtN/4AcA2w9QDfa0tNZdFnA9vnkxr3Na8fYgSy02LR1nvvIqUebsGsHdwac/6PAza3/TsASWsCvyR1aCptF2A92y8DSPo2qT188UWbpHvp+9C+Amlcwn9KwvY6ZSJrnd2Z/U14jwGuhfY5hPTw8iTMPM26Cii+aGtJ98Pp+etf8qzK/6GeZilnktKD76W+E8o2eFrSrsyasbgLddWjVi2/p3yydByDqLLe2PbE/HXQmspc8jGi9ceSpjDIRmizIWT7jJGKqZOkr+SU/5MZIE7bB/Ty58eirfe2A8ZWmM7X35PNgi17iHpSXh4m1XK8nF+/kXQiWIOPlQ6gzXLt36dIJ7sXd3xrGSr4cAOajqWvDHLt4ZGPqlVGNwu27BlS/WwVbD9ISj+s1Wm5pfShwMXA0sA3yoY009NtSP+v2J6kcTsn5Nc35WuhC3k49CnAyrbfKWkdYJuKsnCqrjfuwnhGvmnUd0f4582tZlPvthI/PBZtvXc37cj5v1/SJcB5pDeXHYHfNDnPhXOcX8nxXZljGwfcKOmkHFtPdzYGY/sRmDmc/P7O1sPAO4BHSsXWEjeTOpW+iXTa25gG9LwTU5duYfZuZDOv2R6wLqAipXP/L5N0ObNOE3amjhP8VrD94/yPNzBAV7cSu+Edbpd0NGkxWW36f61s/5HUNjzMmx+ROh+eCmD7npw+XMWirak3lrS07edLxzMPRvyzw/b1I/0z50bTEbzUe24s2npvZeBBSb+h7pz/xUnzdj6QXz9FSvXbmvI5zpPzr8Z1heIYTJWth2uXF72P5AYuj3ekwC4BrErBUyxJf0sa8r2EpPWY9QG2LLBkqbj6k7RGbgvfeW2jjq6XpXP/J+TNn81I/w1Psz15iD8WuldiN7yxXv763o5rNab/VymP1/kW8BKpI/K6wIG2zy4aWHssafvWfmNb/1oqmP4kbQL8mHQ6vrqkdYG9bO9bNrKujXi9tqTzbO80QOkJQDUlJ/mU98vMPs6rp+99sWjrvYmlA+hGF7nNX7N99EjF02moHQ1JF9ouPZ6g1tbDbXEesEnH69dIRb4l52X9A6mublXg+I7r04CvlwhoDn6WZwL+CUDSB0gpV++Ccrn/DUnH2P4qHRs/HdfC/Ct2kmp788G+X/gUsA22sv0VSdsBj5EyXK4l1UCFoT2d6++b7q87kDI3anEC6XPkYgDbd0t6f9mQ5kqJ95amE3LtpSfnk5r3/Zj0vDIi4qGyx4Y66pV0i+2NRyqe+bAjqVNYjWoYBFll6+EWWbSz7jMP2i46Lys/bJ4paXvbF5aMZQh7AT+XtDXpZPdfgI+UDamPccw+XP7DA1wL86bm7qUlTwHbYLH89SPAT20/2+/UKAxuP+A0YG1JfwL+QBqJUQ3bj/b7fzpiD/jD4KaR/oG2n8hfay8t+avtU4b+bcMrFm3lLT70b6lC6bqYwdTw0NLZehhSd7yaWg/X7ilJ29i+GEDStsDThWNqXJfrJ5s5gTcCR9iuolFKnhFzAGmsyMvAONtPFQ4LSfuQNi/G5uHajWUo8DCwAKv5vbnm2GpwsaQHSemR++bOqi8P8WcCIGk0sKHtLSUtRWp4NK10XP08mlMkZ+RNyAOoZ8YikpYnzZRdg74pfgfkr/uXiWxmn4CTgb8D3kDqyv2C7WVLxZTjWiH/4xRJ+5JKdzpLn3o6MD0WbeXVsODoRlviLKIFrYdrtzdwjqTvkx70HiV9mNTg30lNIJoU3E8D/0HhIakDtEZeEngOOD2PmyhdN3suqeHI0aTh6Y1pvf5gW8jUvACOz405yIuOKcCxwFTbr0l6Edi2bGTtkEsQ9gfOs/1C6XjmYG9STfFbSOmvV5BOB2txCfBr6hzZ8X3SM9X5wIak54G3FY0ouZ30vtZsSE3o+N4Mepz5FYu20K2ad0yLxyZpVdKu0KbMOo0Zb/uxooG1hO3fA++VtDSpPrCmHdMVbHcORP2WpI8Xi2aWqlsj234OeC7PKfof269I+iCwjqSf2P5L2QjbQdIbSRsGa9B3N/yI/LXYbngXir831yovOo7rLI/Ii49aFyA1ulLSl0mbaDP/u9WwKSRpEWA321Wla/azuO2DSgcxJ7Z/J2kR268BkyTdXEFMYwAkLd40TmtI6nnmXCzaymvLh9r5Q/+WYmqojZlEOlnYMb/eNV8bVyyiFpC0q+2zJR3U7zoAto8f8A+OrGslfZLULAVgB9Lg+aKaellJY4An+nXeXLlkbP1cCGwo6W3A6aSi/HOpq+6uZheRTlBvpyMNpyVqPgWswRWStgd+1tnIKnStmWnXeXrV89OObuST022ZNYOvRmdJ+hzwC0Ywxa9LL+aU0rtyl9UngKUKx9TpZmbvDj7QtWEVi7YRIGllZnXBu7XfoNndCoQ005ymujc6cpv/ZcSCyubU8pW00J3RtH61fcWIBjawFW1P6nh9hqQDi0XTHs2b8DJFoxjcXsBBwFmkv3ujgRfyQnNG6Rx70oZKbZ03O71u+6+57f/3bJ8s6c7SQbXIqrb/sXQQA6m5JqYlDiK9B74m6SVmfbaVfk9phebUo2I35ZT//ieBtcwxfBX4DnAIs561qlj0kp6NFwH2B74IrMasEoViSo8CikVbj0naiXRTXEf6n3uypAm2LwCwfV/B8KDQVPcu1d7ytdPTknZl1gDhXYAqGlXUzPapOY1kqu0qdyRt17yghAo7b/YzXdIupIf7rfO1xQb5/aGvmyW9y/a9pQMZQM01MdVrwXtLlSRtYfuavBE0G9sl58p2ajbTjui4VtMcw4OAt9mupenXTB3dI18CDi8ZSz+do4COY9aibSojMAooFm29dwiwUXO6lrtDXQVcUDSqrOYZOi1o+dppT1Lh7AmkN+WbgUFn34Ukp5FsQ2VpJJLWtv2gpAHTHSraLa258yak+2Bv4Cjbf8jpnDGHqnubAXtI+gMphalPpkFhVdfE1E7SKFJjozG2j5S0GrCK7VsLh1a79wPXkDaBmqYQnV+LL9pyo5lTbJ835G8u537gxdJBDETSx4AjgbeS1ipVnEJ3OwqoVzMqY9HWe6P7pUM+Q0qvqkpeTH4VeAcdYwh6Pd29G7W2fu1ntf7d+iRtCvyxUDxtc3OFaSQHkcY2HDfA92raLW06b/4gv36UwmnXnWz/F6nVdfP6D8C3m9eSLrRdPO2lYh8uHcAgaq6JaYN/JZ1QbkF6QH0e+AH1pDbXalpOT7+Pvp38qqkL7OxuWTqWQbxGqhm7lr737wFz/iMj5nvAJ4B7a6z37GJ2a09mVMairfculXQ5s9LmdiallNTmHNID80dJD4G7A8VnPWW1tn7tdDKzF6AOdC0MrLo0Etufz183LxVDNyrvvNmNGuonqtVkHEhaifrmetZcE9MG77G9flPjafvPlaU212rp/FWkBe5FpIXb1qTxLLWotrtl9vP8q0aPAvfVuGDrUk+aDMairfdmAKeSUlxGAacB7y0a0cD+n+3TJY3PXemul3R96aAaNbZ+BZC0MWnBsWK/DojLkk4EQ3f+yfZDnRckVfHgJ2lJ0qnb6rY/L+ntgGz/onBoAEhaDphIShki37dH5Jb7bdDWD+URkVOHjwPeDDxJShd6APj7knFl1dbEtMT0XNM7A2ZmvERt4BBsHw4g6Qpg/WajStJh1NXputrulvnv3Tjbu5aOZQ6+AlySP886TwFr6CjdjZ58rsWirffG2f4qHTnWkg6njjb1nabnr09I+ijwOKnQsgY1t359A2nXb1H6dkCcSmoNH7pzAbOfSp4PbFAglv4mkdqtN6eBj5Fiq2LRBvwbKU1op/x6N1LMAxbph9Y5krTRd5Xt9SRtTmp0VINqa2Ja4iRgMrCypKNInxmHlg2pVVYnnfY2XiV1Mq1Czd0tcy35ipLe0NnIqiJHkdKFFyc9Z7VNnLS1iaR9gH2BsZLu6fjWMtQ5u+Zbecf+S6S0vmVJbVZrsBupDrCz9WsVD6Qdp5JndKQxjQaWtj21bHT1k7Q26cRguX6dwJalnlSwNW3vnDsgYvul3ECgFmv2qwk7XNJdxaKZezX9t6zRdNvPSBotabTtayUdUzqorOaamOrZPkfS7cCH8qWP236gZEwtcxZwq6TJpJON7ehBHdG8qj1LA3iYNJbgYvqmb9ZwmrWC7a1KBzEfevKcH4u23jkXuBQ4Gji44/q0ivKZgZnH5G/PbyTPAbXV8Hzc9onAy+TWr5LGAycWjaqvoyXtTXqIuZ20CDne9ncKx1U7kUY7LM+sdvAA04DPFYlodq/mgdVNCtOa1DXk+CVJm9m+EWY2wHmpcExzo7asg9r8Jdcr/orUcOZJ4K+FY2rUXBPTFkuSUulnAEsUjqVVbB8l6VLgffnSZ23XNAOy9iyNx/Ov0dQ3K/UqSVtVMod3NvmQ4zBm/d3rU5bQqxmVo2bMiHKCAJKurbXhgqQ7bK/f79qdttcrFVN/ku6y/W5Jnyal9H0VuL2SttzVk7Sx7VtKxzEQSeNIKUvvAK4ANgX2sH1dybgaktYFfgIsly/9Gdjd9j1z/lO9J+leBs7rr6llffUkLUXasGrawy8HnGO7ijmQOXV9rfzStqcP9vvDLJK+CewIXEj6//tx4Hzb3yoaWBgWkm6zvWHn84qku22vWzq2TpKWsv3C0L9z5EiaRtrQeJVUvlNFy/+GpAtJZQnNye5uwLq2e5oFFidtoVFdy/WcjvYpYEw+vm8sS32DqxeTtBjpQ/f7tqdLih2R7m0n6X7SCdFlwLrAgbaLz/OyfaWkO0h1RaOA8ZU1Xphqe11JywLYnppnoZX2sdIBLAhsvyBpZVKXvGeASytasH2Q9NDyMOneWC3PJ6qpg1/NdgHWs/0ygKRvA3cAsWhbMFSdpZEbqZ1OqstfPW8A7mV737KRAWlzqplheISk1YFVCsfUqUhZQizaQqO6luukAdVPAG+i76ysaUDRU4QBnEp6cLkbuEHSW0nNSEJ3trL9FUnbkVJIdgSupYIhzDmma2z/Mr9eXtLHbdeSFnYhqYNa59+3CyjcxKWp8QzzR9JOpLb615EWRidLmmD7gqKBJceR7l0DSFqLNN6mhgZCbfAwqXb35fz6jcDvi0UThttE0ibkapLOIWdpFI2or+8B/wBcDGD7bknvLxvSTD9g1gzDI0jPfRdSzwzDImUJsWgLTeOMU2xXNQQyP/Q9AmzcsdMM8IDtWmo6ALB9EqkTGACS/khHbWDefa6mQLpCi+WvHwF+avtZSSXj6TTR9uTmhe2/SJpI4VqeljRxQdJ7Sc2N/o7UBWwR4IVa0lxa4BBgI9tPwsy28FeRFualLdYs2ABs/3fOOAjdeQW4X9KVpE3SccCNkk6CaOjSVpI2tX0TaWbcJ6g3SwPbj/b7rH2tVCz91D7DcG/gJ7m2DXJZQq9/aCzaArZfl7Q/UNWirSFpR+C71LnTPKA8ELJzYTmeirpaVWiKpAdJO1X75gfTl4f4MyNl9ADXanjvbEMTF4DvA58kFeBvCHwGeFvRiNpldLNgy55h4L+TJdwm6XRSFz9I6Uy3F4ynbSbnX43rCsURhtdJpNPmW3I9/i8LxzMnj0raBJiRF0QHkGZA1qD2GYZFyhJqePAIdbhS0peZvaathk6Xh1LvTnO3oq35IGwfnNuYT83zY14Eti0dV3abpONJ6RozgC9QwYOp7YuAi2pu4tKw/TtJi9h+DZgk6ebSMbXIZZIuJ6UdAuwMXFIwnk77kAYHH0B6j7sB+NeiEbXIUNkXki7sVzcT2mG6pEnAW5pT004VnaDuTerC/RZSWcIVpFFVNWhmGK5U6QzDImUJsWgLjT3z1/06rs0AxhaIpb+ad5q7FU1JBpHn2exHGpb6eeDNpJOkGlojfwH4BmlDA9IHW00fHtU2cclezLu4d0k6llSnulThmFrD9gRJ25PqYUYBp3Wm65aSd8FPt70rUMNcpwVRDZ+/Ye59DNiSVI9VfINvELL96T4XUm1W8VnC/WYYjqKSGYalyxJi0RYAsF1Dt7k5ubTineZuxUnb4KqdZ5NbIR8saWnbz5eOZwDVNnHJdiNtsuwPfBFYjVTnEbpk+0LSzm418on4ipLeYPvV0vEsoGKzr4Vy3dq/S3rA9t2l4xnEycD6XVwrwvaDwIOl4+inaFlCLNoCMPOk4yBgddufl/R20i5M8Ydm0gfXqcBm5J1mUmFvmxTfuarcmrZ3zmMesP2SpCoWujnn/8fU2RYZ6m7iAmmH9ERSjeLhAJLGk9JywhzkOUWDzbmroZHLw8BNeSRLZ1p9nLyFkDoMXg2sbPudktYBtik9hy+3+t8EWFHSQR3fWpbUKCrMQbdlCZK+Zvvo4f75sWgLjWpPOoBxtr8K/Ky5IOlw0gDrovq94c2meXixvf/IRNRaNc+zOYF62yJD3U1cIHXU6r9A22OAa6GD7WVKxzAnks6yvRsp6+EE0klqtfG2WBUbV2Ge/QiYQNp0xvY9ks6l/By+N5A2IRel7307lVQ7FobQRR35jkAs2kLPVHfSIWkfUlHsWEmdc9mWoZ6Tq+YNT6SRBM0Q8K1JRflhCPnv2Q+peJ5NxW2Rh2ziImmc7StHOq78XvIpYEw+iWksS6pLDe21QZ5F+UdSOlWYT5L+BljNdudnXfGNyTBflrR9a7/PjuLjimxfD1wv6YzB5mlKOtn2F0YwtAVJT56fY9EWGjWedJwLXErarTi44/q0SrpaYrtJ97qC1EloWn59GOmkMgzB9oycLrcVdc6zqbktMpBm2HT88wt0pKoBxwAjvmgDbiY1HXkTaQhzYxpwz4B/IrRFs8kyBrit4/oo6mlgVT1J1wHbkJ7F7gKeknS97YMAbF9RMLww/57Oz1LNc9UOpPfEKgy2YMs2HZFAFkw9qUeNRVtoTKSykw7bzwHPAbuUjKNLqwOdxfivAmuUCaWVfg2MtV3jPJuB2iLvN+ifqEuRE/P8QPAIsLGklUkn0QAP2C6+2xzmne2TgJMknWJ7n9LxtNhyeb7TPwOTbE/sl1US2m0/Ug3+2pL+BPyBNMswLPjipC0MP0mb2r6JlMr3Ceo86WiDs4BbJU0m7bBsB/ykbEitsjmwl6RHSKdETbOFdUoGldua79a/LXLLFO1AJ2lH4LukwcGjgJMlTbDdpjmLYQCxYJtvi0paBdgJOKR0MGF49Kt1v4TUzXc06bNte2JExsKgJ5lWsWgLJ5GGAd5ie32gxpOO6tk+StKlwPvypc/avrNkTC3z4dIBDCTXiG1LarYQ5s2hwEbNrMXcKOUq0iDSEBZmRwCXAzfa/o2kscBvC8cU5l//WveLSBtWu9GuWvdohNOPpK/YPlbSyQywIdoMTrf9L734+bFoC9MlTQLeIumk/t9s/gKGrixJagYxKc8vGmP7D6WDaoMucutLuknS90nDtTvbmt9RLqS58nDhnz+6WbBlz5B2nUNYqNk+n44dedsPkU5iQostQLXu0eF3dk09+22D/q4eiUVb+BiwJbAFqeV/mAeSJgIbknbWJpFmZ51NFPIuCJoxGEd0XJtBumeKkTTogGrbP8tfSw+yvlTS5cBP8+udSSlDISyUut2tD61Xda27pCnM/vfvOdKC5FTbZ4x4UJWzPSV/PRNA0jKkUo7nR+Lnx6JtIZfr1v5d0gO27y4dT4ttB6wH3AFg+/F8M4eWs735YN+XtHvzBj7Cts5fVyItLK/Jrzcn1Y/9bIA/U8IM0pyizUjpNqeRamdDWFgV3a0PI2agWvcSnxVz8hCwIn031P4XWIs0Y263QnFVT9I7Sf9/VwBGSXoK+Izt+3v5c2PRFhovSboaWNn2OyWtA2xju/QQyLZ4Nbeub1r7LlU6oDBixlPgg9j2ZwEk/QJ4h+0n8utVgB+MdDyDGGf7q3QsIiUdTsygCgup/rv1YcHUglr39Wy/v+P1FEk32H6/pJ4uPhYApwEH2b4WQNIHSQvdTQb7Q/MrFm2h8SNgAmlHHNv3SDoXiEVbd86TdCqwvKTPAXuS/puGBV/pYu01mgVb1uyUFiVpH2BfYGy/NubLADeViSqEekhaC/gyKWVu5vOY7aKp12H45NrnWuufV5S0uu0/AkhanTRXE/qmdYbZLdUs2ABsXzcSm/WxaAuNJW3fKqnzWsxS6pLt70oaB0wl1bV903aJgcZh5BVtqQ9c11EzNgP4JKnFdGnnApcCRwMHd1yfZvvZMiGFUJXzSYPKfwy8VjiWsPD5EnCjpN+TNh/HAPvmxUecAg/uIUnfIKVIAuxKmsPXU7FoC42nJa1JfgCVtAPwxOB/JDTym9w1tq9UWvlK0mK2p5eOLfRc0ZM22/tL2g5o0lxOsz25ZEwAtp8jFbXvUjqWECr1V9unlA4iLJxsXyLp7cDapM+xB22/nL/9vXKRtcKewOGktP9RpFEOn+31D41FW2jsR8rRXVvSn0g7Bm0eKDzSbgDeJ+lvSDOobiMV9cZ/wwVfDal+d5BOsK6StKSkZZo20yGEukhaIf/jFEn7ApOBV5rvx0l0GEEbMCs9dx1J2P5J2ZDqZ/vPwAGSlgNeH6nP21i0LeQkHdTx8hJSWtVo0jyq7YHjS8TVQqNsvyjpn4CTczvnmgqOw1zqd2/Mxvbx+ev+IxPRwHIN5edJXazWBN5CSrn6UMm4QghzdDspq6U5pZ/Q8b0ZwNgRjygsdCSdRfrMuItZ6bkzgFi0DUHSRsC/kQepS3oO2NN2T0dnxaItNG3pBWwEXET6INmNdHoUujNK0sakk7V/ytfi/mq3/vfGxfn11tR1b+wH/H/gPwFs/1bSSmVDCiHMie0xAJIW70hHo7lWJqqwENqQ1Hm4dF12G50O7Gv7VwCSNiPN6F2nlz90dC//5aF+tg+3fTipY9D6tr9s+0ukI/NVy0bXKgcCXwMm275f0ljqaAYR5tEA98aXKr03XrE9s9OXpEUp3xwlhDC0m7u8FkIv3Af8bekgWmpas2ADsH0j0PMUyTgJCI3V6dvi9VVSnnPogu3rges7Xj8EHFAuojCMar83rpf0dWCJ3MF0X2BK4ZhCCHMg6W9JacxLSFqPWWmSywJLFgssLGzeBPyXpFvpW1O5TbmQWuPWPOap6dq8M6mT8/owc9TDsItFW2icRfpLOJn0F3A7ouXrkCR9z/aBkqYwwOlGvPktEAa6N2rK+T+YlJJ7L7AXcIntmBEYQr3+AdiDdGJ/HLMWbVOBrxeKKSx8DisdQIu9O3+d2O/6JqTnhJ7MWhw1Y0Zk0YQk7xC8L7+8wXY00hiCpA1s3y7pAwN9P5/AhZar+d6QNN72iUNdCyHURdL2ti8c5Pu7247N09AzklYm1WwD3Gr7yZLxLCh6de9GTVuYyfYdtk/Mv6p5KK1ZR6eg24Bf2b4+L9RuBH5TLrIwzJYEpuaF0GOSxpQOqMPuA1zbY6SDCCHMncEWbNn4EQkkLJQk7QTcCuwI7AT8Z57RG+ZfT+7dSI8MYXhcDWwJPJ9fLwFcQToqDy0maSKpy5ZI3aEWA84GNi0c1y7Ap4Axki7u+NYywDNlogohDKNRQ/+WEObZIcBGzemapBVJc2YvKBrVgqEn924s2kIYHovbbhZs2H5eUhSULxi2A9YjDbDG9uOSlhn8j4yIm4EnSMXkx3VcnwbcUySiEMJwivqV0Euj+6VDPkNk4A2Xnty7sWgLYXi8IGn9pmOQpA2AlwrHFIbHq7ZnSJoBIGmp0gEB2H4EeETSp4HHm3lPkpYgdHzXdwAABzpJREFUNTh4uGB4IYT5FydtoZcuk3Q5qQMipA6IlxSMZ0ESJ20hVGw8cL6kx/PrVUhvgKH9zsutfZeX9DlgT6Cm7ozn0TcN9zXgfGYVl4cQ2umm0gGEBZftCZK2J6X6jwJOsz25cFgLip7cu9E9MoT5JGk08F5S4xGR3vwetD29aGBh2OT5Z1uR/t9ebvvKwiHNJOku2+/ud+1u2+uWiimEMDRJywOfIc19nLmJbjtmfIZQsVL3bpy0hTCfbL8u6TjbGwP3lY4nDB9Ji5AWaVsC1SzU+nlK0ja2LwaQtC3wdOGYQghDuwT4NWnG4uuFYwkLCUnTGLjmahQww/ayIxxSGxW5d+OkLYRhIOlwUvOHn9mOm2oBkjsz7mb7udKxDETSmsA5wJtJH7qPAp+x/buigYUQBiXpDtvrl44jhDB3St27sWgLYRjknaulSPVELxE7VgsMSeeR0l+vBF5orteWwiRpaWCU7WmlYwkhDE3SF0ljYn4BvNJct/1ssaBCCEMqde9GemQIw8B2DS3gQ2/8Mv+qiqRdbZ8t6aB+1wGwfXyRwEII3XoV+A5pXlazgz4DGFssohBCN4rcu7FoC2EYSBoFfBoYY/tISasBq9i+tXBoYT7ZPrN0DHPQjB6IDYMQ2ukg4G22owY1hHYpcu/Goi2E4fGvpGLULYAjScfmPyDarreepLcDRwPvABZvrtsuuhtu+9TcKGWq7RNKxhJCmCf3Ay+WDiKEMNeK3LuxaAtheLzH9vqS7gSw/WdJbygdVBgWk4CJwAnA5sBnqWTore3XJG1Dii2E0C6vAXdJupa+dTFV1cuGEGZT5N6NRVsIw2N6PvWYASBpRaKF84JiCdtXSxpl+xHgMEm/Ii3kanCzpO8D/0HfRil3lAsphNCFn+dfIYR2KXLvxqIthOFxEjAZWEnSUcAOwKFlQwrD5OU8QP23kvYH/gSsVDimTpvkr0d0XJtBStUNIVTK9pk5I2OtWZc8vWRMIYShlbp3o+V/CMNE0trAh0ipc1fbfqBwSGEYSNoIeABYnlSvuBxwrO1fFw0skzTW9kNDXQsh1EXSB4EzgYdJnxurAbvbvqFgWCGEIZS6d+OkLYRhIGlL21cBD3Zc273izoOhS7Z/k//xeVI9W20uAPoP+Twf2KBALCGE7h0HbGXbAJLWAn5K3Lsh1K7IvRuLthCGxzclbQ98GVga+DGpODUWbS2X34wnAG+l4z3TdtH0w3yy+/fAcpI+0fGtZenochlCqNZizUMfgO3/lrRYyYBCCF0pcu/Goi2E4fEB4EvAXfn1N23/tGA8YficD/wQ+BGpY1QtBHyMlLa5dcf1acDnikQUQpgbt0k6HTgrv/40cHvBeEII3Sly78aiLYTh8TfAe4DfA6sCb83dBqNotP3+avuU0kH0Z/si4CJJG9u+pXQ8IYS5tg+wH3AAqS7mBtLMzxBC3Yrcu9GIJIRhIOm/gW/b/jdJSwDHABva3mSIPxoqJWmF/I8HAE+SuoN2zmN5tkRc/Uk6FvgW8BJwGbAucKDts4sGFkKYozwi5kzbu5aOJYTQvZL37uiR/oEhLKC2JM1q+6btl4DvAgcXjinMn9uB24DdSTVtN+fXza9abGV7KilV8jFSC+IJZUMKIQzG9mvAirlteAihJUreu5EeGcLw+BppmPYWpHlZ00jdhTYqGVSYd7bHAEjaCbjM9lRJ3yB1ajyyaHB9NcXPHwF+avtZSSXjCSF052HgJkkXAy80F20fXyyiEEI3HqbAvRsnbSEMj/fY3g94GcD2n4HYQV0wHJoXbJsB44AzgJpq3KZIehDYELha0orkv4chhPpIapoX7Az8gvQstkzHrxBChUrfu3HSFsLwmJ7znGcA5Afn18uGFIZJ0zHyo8APbV8k6bCC8fRh+2BJxwBTbb8m6UVg29JxhRDmaANJbwX+CJxcOpgQQteK3ruxaAtheJxEalSxkqSjgB2AQ8uGFIbJnySdSqpbPEbSG6koS0HSkqQuVqsDnwfeTBoH8IuScYUQ5uiHpKZBY+hbHzuKtPE3tkRQIYQhFb13o3tkCMMkDzv+EOnmvdr2A4VDCsMgL4r+EbjX9m8lrQK8y/YVhUMDQNJ/kJqmfMb2O3P30ltsv7twaCGEQUg6xfY+peMIIcydUvduLNpCCKHFJN1me0NJd9peL1+72/a6pWMLIYQQwvCoJsUnhBDCPHk1n6419ZRr0jFPLoQQQgjtFzVtIYTQUpJGMSvHfjVJ5wCbAnuUjCuEEEIIwyvSI0MIocUk3Q5sBbyXVE/5a9tPl40qhBBCCMMpTtpCCKHdfg2Mtf3L0oGEEEIIoTfipC2EEFpM0n8BawGPAC+QWw/bXqdoYCGEEEIYNnHSFkII7fbh0gGEEEIIobfipC2EEEIIIYQQKhYt/0MIIYQQQgihYrFoCyGEEEIIIYSKxaIthBBCCCGEECoWi7YQQgghhBBCqNj/AQqqTPrCej5mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa13fd65a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing_data.plot(kind='bar', figsize=(15,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high number of missing values there may be many examples not offering anything useful to our predictive model. I've chosen, somewhat arbitrarily, a threshold of 85% missing values to mean those examples we may be interested in removing from the dataset.\n",
    "\n",
    "We can retrieve these examples using the following snippet (thank you [stackoverflow](https://stackoverflow.com/a/52882784/1613695) and Wen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>...</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>email_address</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>119292.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "      <td>119292.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOCKHART EUGENE E</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THE TRAVEL AGENCY IN THE PARK</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>362096.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>362096.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHALEY DAVID A</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>98718.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>98718.00</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WROBEL BRUCE</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>139130.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>139130.00</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>False</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               salary  to_messages  deferral_payments  \\\n",
       "GRAMM WENDY L                     nan          nan                nan   \n",
       "LOCKHART EUGENE E                 nan          nan                nan   \n",
       "THE TRAVEL AGENCY IN THE PARK     nan          nan                nan   \n",
       "WHALEY DAVID A                    nan          nan                nan   \n",
       "WROBEL BRUCE                      nan          nan                nan   \n",
       "\n",
       "                               total_payments  exercised_stock_options  bonus  \\\n",
       "GRAMM WENDY L                       119292.00                      nan    nan   \n",
       "LOCKHART EUGENE E                         nan                      nan    nan   \n",
       "THE TRAVEL AGENCY IN THE PARK       362096.00                      nan    nan   \n",
       "WHALEY DAVID A                            nan                 98718.00    nan   \n",
       "WROBEL BRUCE                              nan                139130.00    nan   \n",
       "\n",
       "                               restricted_stock  shared_receipt_with_poi  \\\n",
       "GRAMM WENDY L                               nan                      nan   \n",
       "LOCKHART EUGENE E                           nan                      nan   \n",
       "THE TRAVEL AGENCY IN THE PARK               nan                      nan   \n",
       "WHALEY DAVID A                              nan                      nan   \n",
       "WROBEL BRUCE                                nan                      nan   \n",
       "\n",
       "                               restricted_stock_deferred  total_stock_value  \\\n",
       "GRAMM WENDY L                                        nan                nan   \n",
       "LOCKHART EUGENE E                                    nan                nan   \n",
       "THE TRAVEL AGENCY IN THE PARK                        nan                nan   \n",
       "WHALEY DAVID A                                       nan           98718.00   \n",
       "WROBEL BRUCE                                         nan          139130.00   \n",
       "\n",
       "                                        ...            loan_advances  \\\n",
       "GRAMM WENDY L                           ...                      nan   \n",
       "LOCKHART EUGENE E                       ...                      nan   \n",
       "THE TRAVEL AGENCY IN THE PARK           ...                      nan   \n",
       "WHALEY DAVID A                          ...                      nan   \n",
       "WROBEL BRUCE                            ...                      nan   \n",
       "\n",
       "                               from_messages     other  \\\n",
       "GRAMM WENDY L                            nan       nan   \n",
       "LOCKHART EUGENE E                        nan       nan   \n",
       "THE TRAVEL AGENCY IN THE PARK            nan 362096.00   \n",
       "WHALEY DAVID A                           nan       nan   \n",
       "WROBEL BRUCE                             nan       nan   \n",
       "\n",
       "                               from_this_person_to_poi    poi  director_fees  \\\n",
       "GRAMM WENDY L                                      nan  False      119292.00   \n",
       "LOCKHART EUGENE E                                  nan  False            nan   \n",
       "THE TRAVEL AGENCY IN THE PARK                      nan  False            nan   \n",
       "WHALEY DAVID A                                     nan  False            nan   \n",
       "WROBEL BRUCE                                       nan  False            nan   \n",
       "\n",
       "                               deferred_income  long_term_incentive  \\\n",
       "GRAMM WENDY L                              nan                  nan   \n",
       "LOCKHART EUGENE E                          nan                  nan   \n",
       "THE TRAVEL AGENCY IN THE PARK              nan                  nan   \n",
       "WHALEY DAVID A                             nan                  nan   \n",
       "WROBEL BRUCE                               nan                  nan   \n",
       "\n",
       "                               email_address from_poi_to_this_person  \n",
       "GRAMM WENDY L                            NaN                     nan  \n",
       "LOCKHART EUGENE E                        NaN                     nan  \n",
       "THE TRAVEL AGENCY IN THE PARK            NaN                     nan  \n",
       "WHALEY DAVID A                           NaN                     nan  \n",
       "WROBEL BRUCE                             NaN                     nan  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = .85\n",
    "\n",
    "# Return the rows that have a percentage of their data missing.\n",
    "#\n",
    "# `enron_data.isna().sum(1)` gives the number of missing values for each person.\n",
    "# `enron_data.shape[1]` is equivalent to `len(enron_data.columns)`\n",
    "enron_data[(enron_data.isna().sum(1) / enron_data.shape[1]) > threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These really are adding little value and none of them are persons of interest. In fact `THE TRAVEL AGENCY IN THE PARK` does not represent an individual employee and may have a negative impact on out predictive model. Lets just drop them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1 - threshold\n",
    "\n",
    "# Return the rows that have a percentage of their data present.\n",
    "#\n",
    "# `enron_data.shape[1]` is equivalent to `len(enron_data.columns)`\n",
    "enron_data = enron_data.dropna(thresh=enron_data.shape[1] * threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For various reasons, many real world datasets contain missing values, often encoded as blanks, or in the case of this dataset `np.nana` values. Such datasets however are incompatible with the estimators we'll be using in later sections which assume that all values in an array are numerical, and that all have and hold meaning. A basic strategy to use incomplete datasets is to discard entire rows and/or columns containing missing values. However, this comes at the price of losing data which may be valuable (even though incomplete) and in the case of this dataset will remove every available feature. A better strategy is to impute the missing values, i.e. to infer them from the known part of the data.\n",
    "\n",
    "There are a few statistical methods often employed to impute missing values that focus around central tendency. Each have their own qualities:\n",
    "\n",
    "- mean: The mean value is very sensitive to outliers. That is, one or two extreme values can change the mean a lot,\n",
    "- mode: Continuous data is unlikely going to have a single value that is most frequent. Therfore this is best used for catagorial data,\n",
    "- median: The mdeian is far less sensitive to outliers making it more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the features in this dataset are concerned with financial data. According to the FindLaw report, where a value appears missing (has a `-` in place of a numerical value) this is equivalent to the value being `0`. This we can imagine would be true for such features as `director_fees` and `loan_advances` since the majority of Enron employees would not be directors of the company and are unlikely to be receiving loan advances. In light of this let's fill in the `np.nan` values for financial features with a `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_features = payment_features + stock_value_features\n",
    "enron_data[financial_features] = enron_data[financial_features].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the other type of feature concerning numbers of emails being sent to and from Enron emplyees, `np.nan` values indicate that the data is unknown. For this type of feature I want to infer the values from the available data, most likely using the median value given it is less sensitive to outliers. However imputing the data this early may be a mistake; something that is dicussed further in the section on data leakage, more specifically validation leakage.\n",
    "\n",
    "Despite the risk of imputing data this early I am forced to do so anyway because the `test_classifier` method I will later use to evaluate my classifier does not allow for the validation data (after being split) to be imputed, or manipulated in any way.\n",
    "\n",
    "Because the behaviour of a person of interest is likely to differ from somebody we're not interested in I will separately impute the values for the two classes. I feel this will provide a more accurate and fair assesment of each classes distribution of email values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "email_features = ['from_messages', 'from_poi_to_this_person', 'from_this_person_to_poi',\n",
    "                  'shared_receipt_with_poi', 'to_messages']\n",
    "\n",
    "poi_email_features = enron_data.loc[enron_data.poi == True, email_features]\n",
    "non_poi_email_features = enron_data.loc[enron_data.poi == False, email_features]\n",
    "\n",
    "# Simple imputer using the median value for each feature.\n",
    "median_imputer = Imputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "enron_data.loc[enron_data.poi == True, email_features] = median_imputer.fit_transform(poi_email_features)\n",
    "enron_data.loc[enron_data.poi == False, email_features] = median_imputer.fit_transform(non_poi_email_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one exception within the email features is `email_address` which is a text value where perhaps `np.nan` values should be treated as empty strings. However since the sklearn estimators require values to be numerical I will just remove the `email_address` feature entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_data = enron_data.drop(columns=['email_address'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data leakage causes a predictive model to appear accurate on the validation data but perform poorly when trying to use the model to make further predictions on completely new data. It is a type of overfitting that can be difficult to track down.\n",
    "\n",
    "There are two main types of data leakage: Label leakage and validation leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label leakage [1] occurs when a predictive model includes data that will not be available at prediction time. This is a subtle form of cheating caused by features that give a bias towards the target label. For example if trying to predict whether an Enron employee is a person of interest we were given a feature expressing whether they had been incarcerated, `is_incarcerated`, this could possibly be an extremely useful indicator as to whether the Enron employee was in fact a person of interest.\n",
    "\n",
    "In this example an employee will be incarcerated after they are given the status person of interest. So the raw dataset shows a strong correlation between the two features. But `is_incarcerated` will frequently be changed __after__ the value for `poi` is determined.\n",
    "\n",
    "The predictive model will show that a value of `False` for `is_incarcerated` indicates that an employee is not a person of interest. Since the validation data comes from the same source as the testing data this pattern will continue and the model will perform very well. However the same model will perform poorly when used on new data not containing the `is_incarcerated` feature. It is generally recommended that to prevent this type of data leakage, any variables updated (or created) after the target label is realised should be excluded from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no single solution that universally solves label leakage. It requires knowledge about your data, case-specific inspection and common sense.\n",
    "\n",
    "However, in most cases of label leakage there exists 1 or more features having a high statistical correlation to the target label. So two tactics to keep in mind:\n",
    "\n",
    "1. To screen for possible target leakage, look for columns that are statistically correlated to your target.\n",
    "1. If you build a model and find it extremely accurate, you likely have a leakage problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check for correlated values in our dataset by computing a pairwise correlation of columns, excluding NA/null values. Specifically we're interested in features that have a high correlation to the target label, `poi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>expenses</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_advances</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_fees</th>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>-0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           salary  to_messages  deferral_payments  \\\n",
       "salary                       1.00         0.00               0.96   \n",
       "to_messages                  0.00         1.00              -0.00   \n",
       "deferral_payments            0.96        -0.00               1.00   \n",
       "total_payments               0.96         0.03               0.92   \n",
       "exercised_stock_options      0.99        -0.01               0.95   \n",
       "bonus                        0.99         0.04               0.96   \n",
       "restricted_stock             0.99         0.00               0.95   \n",
       "shared_receipt_with_poi      0.01         0.86               0.02   \n",
       "restricted_stock_deferred   -0.91         0.04              -0.88   \n",
       "total_stock_value            0.99        -0.01               0.95   \n",
       "expenses                     0.99        -0.01               0.96   \n",
       "loan_advances                0.74         0.05               0.69   \n",
       "from_messages               -0.01         0.50              -0.01   \n",
       "other                        0.96         0.00               0.95   \n",
       "from_this_person_to_poi     -0.01         0.59              -0.02   \n",
       "poi                         -0.00         0.12              -0.04   \n",
       "director_fees                0.96        -0.05               0.93   \n",
       "deferred_income             -0.97         0.00              -0.97   \n",
       "long_term_incentive          0.99        -0.00               0.95   \n",
       "from_poi_to_this_person      0.00         0.56               0.03   \n",
       "\n",
       "                           total_payments  exercised_stock_options  bonus  \\\n",
       "salary                               0.96                     0.99   0.99   \n",
       "to_messages                          0.03                    -0.01   0.04   \n",
       "deferral_payments                    0.92                     0.95   0.96   \n",
       "total_payments                       1.00                     0.96   0.96   \n",
       "exercised_stock_options              0.96                     1.00   0.98   \n",
       "bonus                                0.96                     0.98   1.00   \n",
       "restricted_stock                     0.97                     0.99   0.98   \n",
       "shared_receipt_with_poi              0.05                    -0.00   0.06   \n",
       "restricted_stock_deferred           -0.86                    -0.92  -0.90   \n",
       "total_stock_value                    0.97                     1.00   0.99   \n",
       "expenses                             0.95                     0.98   0.99   \n",
       "loan_advances                        0.90                     0.77   0.75   \n",
       "from_messages                       -0.02                    -0.03   0.01   \n",
       "other                                0.98                     0.97   0.96   \n",
       "from_this_person_to_poi             -0.00                    -0.02   0.04   \n",
       "poi                                  0.05                     0.04   0.02   \n",
       "director_fees                        0.91                     0.95   0.95   \n",
       "deferred_income                     -0.92                    -0.96  -0.97   \n",
       "long_term_incentive                  0.96                     0.98   0.99   \n",
       "from_poi_to_this_person              0.04                    -0.00   0.06   \n",
       "\n",
       "                           restricted_stock  shared_receipt_with_poi  \\\n",
       "salary                                 0.99                     0.01   \n",
       "to_messages                            0.00                     0.86   \n",
       "deferral_payments                      0.95                     0.02   \n",
       "total_payments                         0.97                     0.05   \n",
       "exercised_stock_options                0.99                    -0.00   \n",
       "bonus                                  0.98                     0.06   \n",
       "restricted_stock                       1.00                     0.00   \n",
       "shared_receipt_with_poi                0.00                     1.00   \n",
       "restricted_stock_deferred             -0.91                     0.05   \n",
       "total_stock_value                      0.99                    -0.00   \n",
       "expenses                               0.98                    -0.00   \n",
       "loan_advances                          0.78                     0.07   \n",
       "from_messages                         -0.02                     0.26   \n",
       "other                                  0.97                     0.02   \n",
       "from_this_person_to_poi               -0.01                     0.50   \n",
       "poi                                    0.01                     0.30   \n",
       "director_fees                          0.95                    -0.06   \n",
       "deferred_income                       -0.96                    -0.03   \n",
       "long_term_incentive                    0.98                     0.01   \n",
       "from_poi_to_this_person               -0.01                     0.68   \n",
       "\n",
       "                           restricted_stock_deferred  total_stock_value  \\\n",
       "salary                                         -0.91               0.99   \n",
       "to_messages                                     0.04              -0.01   \n",
       "deferral_payments                              -0.88               0.95   \n",
       "total_payments                                 -0.86               0.97   \n",
       "exercised_stock_options                        -0.92               1.00   \n",
       "bonus                                          -0.90               0.99   \n",
       "restricted_stock                               -0.91               0.99   \n",
       "shared_receipt_with_poi                         0.05              -0.00   \n",
       "restricted_stock_deferred                       1.00              -0.91   \n",
       "total_stock_value                              -0.91               1.00   \n",
       "expenses                                       -0.92               0.98   \n",
       "loan_advances                                  -0.65               0.78   \n",
       "from_messages                                   0.02              -0.02   \n",
       "other                                          -0.87               0.97   \n",
       "from_this_person_to_poi                         0.04              -0.02   \n",
       "poi                                             0.06               0.03   \n",
       "director_fees                                  -0.88               0.95   \n",
       "deferred_income                                 0.89              -0.96   \n",
       "long_term_incentive                            -0.90               0.98   \n",
       "from_poi_to_this_person                         0.04              -0.00   \n",
       "\n",
       "                           expenses  loan_advances  from_messages  other  \\\n",
       "salary                         0.99           0.74          -0.01   0.96   \n",
       "to_messages                   -0.01           0.05           0.50   0.00   \n",
       "deferral_payments              0.96           0.69          -0.01   0.95   \n",
       "total_payments                 0.95           0.90          -0.02   0.98   \n",
       "exercised_stock_options        0.98           0.77          -0.03   0.97   \n",
       "bonus                          0.99           0.75           0.01   0.96   \n",
       "restricted_stock               0.98           0.78          -0.02   0.97   \n",
       "shared_receipt_with_poi       -0.00           0.07           0.26   0.02   \n",
       "restricted_stock_deferred     -0.92          -0.65           0.02  -0.87   \n",
       "total_stock_value              0.98           0.78          -0.02   0.97   \n",
       "expenses                       1.00           0.72          -0.01   0.95   \n",
       "loan_advances                  0.72           1.00          -0.03   0.84   \n",
       "from_messages                 -0.01          -0.03           1.00  -0.04   \n",
       "other                          0.95           0.84          -0.04   1.00   \n",
       "from_this_person_to_poi       -0.01          -0.03           0.61  -0.04   \n",
       "poi                           -0.01           0.13          -0.04   0.02   \n",
       "director_fees                  0.96           0.69          -0.04   0.92   \n",
       "deferred_income               -0.96          -0.70           0.02  -0.94   \n",
       "long_term_incentive            0.98           0.75          -0.01   0.97   \n",
       "from_poi_to_this_person       -0.02           0.04           0.22   0.02   \n",
       "\n",
       "                           from_this_person_to_poi   poi  director_fees  \\\n",
       "salary                                       -0.01 -0.00           0.96   \n",
       "to_messages                                   0.59  0.12          -0.05   \n",
       "deferral_payments                            -0.02 -0.04           0.93   \n",
       "total_payments                               -0.00  0.05           0.91   \n",
       "exercised_stock_options                      -0.02  0.04           0.95   \n",
       "bonus                                         0.04  0.02           0.95   \n",
       "restricted_stock                             -0.01  0.01           0.95   \n",
       "shared_receipt_with_poi                       0.50  0.30          -0.06   \n",
       "restricted_stock_deferred                     0.04  0.06          -0.88   \n",
       "total_stock_value                            -0.02  0.03           0.95   \n",
       "expenses                                     -0.01 -0.01           0.96   \n",
       "loan_advances                                -0.03  0.13           0.69   \n",
       "from_messages                                 0.61 -0.04          -0.04   \n",
       "other                                        -0.04  0.02           0.92   \n",
       "from_this_person_to_poi                       1.00  0.13          -0.04   \n",
       "poi                                           0.13  1.00          -0.06   \n",
       "director_fees                                -0.04 -0.06           1.00   \n",
       "deferred_income                               0.02 -0.04          -0.93   \n",
       "long_term_incentive                           0.00  0.01           0.95   \n",
       "from_poi_to_this_person                       0.47  0.21          -0.06   \n",
       "\n",
       "                           deferred_income  long_term_incentive  \\\n",
       "salary                               -0.97                 0.99   \n",
       "to_messages                           0.00                -0.00   \n",
       "deferral_payments                    -0.97                 0.95   \n",
       "total_payments                       -0.92                 0.96   \n",
       "exercised_stock_options              -0.96                 0.98   \n",
       "bonus                                -0.97                 0.99   \n",
       "restricted_stock                     -0.96                 0.98   \n",
       "shared_receipt_with_poi              -0.03                 0.01   \n",
       "restricted_stock_deferred             0.89                -0.90   \n",
       "total_stock_value                    -0.96                 0.98   \n",
       "expenses                             -0.96                 0.98   \n",
       "loan_advances                        -0.70                 0.75   \n",
       "from_messages                         0.02                -0.01   \n",
       "other                                -0.94                 0.97   \n",
       "from_this_person_to_poi               0.02                 0.00   \n",
       "poi                                  -0.04                 0.01   \n",
       "director_fees                        -0.93                 0.95   \n",
       "deferred_income                       1.00                -0.97   \n",
       "long_term_incentive                  -0.97                 1.00   \n",
       "from_poi_to_this_person              -0.02                 0.01   \n",
       "\n",
       "                           from_poi_to_this_person  \n",
       "salary                                        0.00  \n",
       "to_messages                                   0.56  \n",
       "deferral_payments                             0.03  \n",
       "total_payments                                0.04  \n",
       "exercised_stock_options                      -0.00  \n",
       "bonus                                         0.06  \n",
       "restricted_stock                             -0.01  \n",
       "shared_receipt_with_poi                       0.68  \n",
       "restricted_stock_deferred                     0.04  \n",
       "total_stock_value                            -0.00  \n",
       "expenses                                     -0.02  \n",
       "loan_advances                                 0.04  \n",
       "from_messages                                 0.22  \n",
       "other                                         0.02  \n",
       "from_this_person_to_poi                       0.47  \n",
       "poi                                           0.21  \n",
       "director_fees                                -0.06  \n",
       "deferred_income                              -0.02  \n",
       "long_term_incentive                           0.01  \n",
       "from_poi_to_this_person                       1.00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps not so surprisingly the email features that include emails to/from a poi have a slightly more significant correlation than other features. However quite interestingly `loan_advances` has the highest corrlelation of the financial features to the target label at `0.13`. This is not high enough to be of any conern so I'll not be remving any features from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much different type of leak occurs when you aren't careful distinguishing training data from validation data [2]. For example, this happens if you run preprocessing (like fitting the Imputer for missing values) before calling [`sklearn.model_selection.train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Validation is meant to be a measure of how the model does on data it hasn't considered before. You can corrupt this process in subtle ways if the validation data affects the preprocessing behaviour. The end result is that your model will get very good validation scores, giving you great confidence, but perform poorly when deployed to make decisions.\n",
    "\n",
    "If your validation is based on a simple train-test split, exclude the validation data from any type of fitting, including the fitting of preprocessing steps. This is easier if you use [`sklearn.pipeline.Pipeline`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). When using cross-validation, it's even more critical that you use pipelines and do your preprocessing inside the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous sections I've cleaned data that exhibited issues with data entry and missing values. Now I would like to discover the outliers. This part of the data exploration has deliberately been left until last. The reson being that this step is destructive. That is up until now we have been correcting the data so that it is true to the source, or using sensible data where it was otherwise not available. In this section I will remove data that will not be useful to the investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conveninently the definition of an outlier can be described as a point which falls more than 1.5 times the interquartile range above the third quartile or below the first quartile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># of outliers</th>\n",
       "      <th>poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FREVERT MARK A</th>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAY KENNETH L</th>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKILLING JEFFREY K</th>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHALLEY LAWRENCE G</th>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAVORATO JOHN J</th>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAEDICKE MARK E</th>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BELDEN TIMOTHY N</th>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    # of outliers    poi\n",
       "FREVERT MARK A                 13  False\n",
       "LAY KENNETH L                  13   True\n",
       "SKILLING JEFFREY K             12   True\n",
       "TOTAL                          12  False\n",
       "WHALLEY LAWRENCE G             12  False\n",
       "LAVORATO JOHN J                10  False\n",
       "HAEDICKE MARK E                 8  False\n",
       "BELDEN TIMOTHY N                8   True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = enron_data.drop(columns=['poi']) # poi is not a feature and should not be considered\n",
    "\n",
    "first_quantile = original_data.quantile(.25)\n",
    "third_quantile = original_data.quantile(.75)\n",
    "\n",
    "median = original_data.quantile(.5)\n",
    "interquantile_range = third_quantile - first_quantile\n",
    "\n",
    "outlier_data = median + 1.5 * interquantile_range\n",
    "outliers = (original_data > outlier_data).sum(axis=1).to_frame(name='# of outliers') \\\n",
    "    .sort_values('# of outliers', ascending=False)\n",
    "\n",
    "five_percent_of_sample = int(len(enron_data) * 0.06)\n",
    "\n",
    "# Merge the outliers with the original enron data.\n",
    "outliers = outliers.merge(right=enron_data, how='inner', left_index=True, right_index=True) \\\n",
    "    .loc[:, ['# of outliers', 'poi']]\n",
    "outliers.head(five_percent_of_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set is really small, so I'm going to consider just 5% of the samples the with most number of outliers:\n",
    "\n",
    "- Mark Frevert and Lawrence \"Greg\" Whalley are lesser known employees but still top managers of Enron (the latter being President and COO of Enron) who also represent valuable examples for our predictive model.\n",
    "- Kenneth Lay (Enron chairman and CEO) and Jeffrey Skilling (former Enron president and CEO) are very well known persons from Enron and heavily involved in the scandal. They represent important examples in our dataset and falsely flagged as true outliers.\n",
    "- The example `TOTAL` is the total value of financial payments from the FindLaw dataset. This clearly is not an individual person and will unbalance the distribution across several features in the dataset. Therefore it should be removed.\n",
    "- John Lavorato, another senior Enron execuative, has little media exposure and there are no reports of him being involved in the scandal. Since his data contains many outliers that could potentially bias our predictive model I'll remove him from the dataset.\n",
    "- Timothy \"Norris\" Belden is the former head of trading in Enron Energy Services. He is considered a key player in the Enron scandal constituting a good example for our predictive model.\n",
    "\n",
    "From the avbove considered 8 examples I will exlude only 2 of them. However before doing so I will visualise some of the features, hoping they will make the outliers and errors immediately stand out. This will convince me futher that these examples should be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/ggplot/components/smoothers.py:4: FutureWarning: The pandas.lib module is deprecated and will be removed in a future version. These are private functions and can be accessed from pandas._libs.lib instead\n",
      "  from pandas.lib import Timestamp\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/matplotlib/__init__.py:800: MatplotlibDeprecationWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  mplDeprecation)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa12d2b2cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (8770639016617)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ggplot import *\n",
    "\n",
    "ggplot(enron_data, aes(x='salary', y='bonus', color='poi')) + \\\n",
    "    geom_point(size=40.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>bonus</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>expenses</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>other</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>poi</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>26704229.00</td>\n",
       "      <td>944.00</td>\n",
       "      <td>32083396.00</td>\n",
       "      <td>309886585.00</td>\n",
       "      <td>311764000.00</td>\n",
       "      <td>97343619.00</td>\n",
       "      <td>130322299.00</td>\n",
       "      <td>594.00</td>\n",
       "      <td>-7576788.00</td>\n",
       "      <td>434509511.00</td>\n",
       "      <td>5235198.00</td>\n",
       "      <td>83925000.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>42667589.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1398517.00</td>\n",
       "      <td>-27992891.00</td>\n",
       "      <td>48521928.00</td>\n",
       "      <td>26.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           salary  to_messages  deferral_payments  total_payments  \\\n",
       "TOTAL 26704229.00       944.00        32083396.00    309886585.00   \n",
       "\n",
       "       exercised_stock_options       bonus  restricted_stock  \\\n",
       "TOTAL             311764000.00 97343619.00      130322299.00   \n",
       "\n",
       "       shared_receipt_with_poi  restricted_stock_deferred  total_stock_value  \\\n",
       "TOTAL                   594.00                -7576788.00       434509511.00   \n",
       "\n",
       "        expenses  loan_advances  from_messages       other  \\\n",
       "TOTAL 5235198.00    83925000.00          41.00 42667589.00   \n",
       "\n",
       "       from_this_person_to_poi    poi  director_fees  deferred_income  \\\n",
       "TOTAL                     6.00  False     1398517.00     -27992891.00   \n",
       "\n",
       "       long_term_incentive  from_poi_to_this_person  \n",
       "TOTAL          48521928.00                    26.50  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data[enron_data['salary'] > 1e7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa12cd34610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (8770638656725)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data = enron_data.drop('TOTAL')\n",
    "\n",
    "ggplot(enron_data, aes(x='salary', y='bonus', color='poi')) + \\\n",
    "    geom_point(size=40.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may conclude that there are four more outliers in the data. However considering the top 2 earners are Jeffrey Skilling and Kenneth Lay, both persons of interest, these should remain in the dataset. Similarly we can conclude there to be a single outlier within the bonus data. We can list the highest receivers to see just who this is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAVORATO JOHN J</th>\n",
       "      <td>339288.00</td>\n",
       "      <td>8000000.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAY KENNETH L</th>\n",
       "      <td>1072321.00</td>\n",
       "      <td>7000000.00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKILLING JEFFREY K</th>\n",
       "      <td>1111258.00</td>\n",
       "      <td>5600000.00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BELDEN TIMOTHY N</th>\n",
       "      <td>213999.00</td>\n",
       "      <td>5249999.00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALLEN PHILLIP K</th>\n",
       "      <td>201955.00</td>\n",
       "      <td>4175000.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       salary      bonus    poi\n",
       "LAVORATO JOHN J     339288.00 8000000.00  False\n",
       "LAY KENNETH L      1072321.00 7000000.00   True\n",
       "SKILLING JEFFREY K 1111258.00 5600000.00   True\n",
       "BELDEN TIMOTHY N    213999.00 5249999.00   True\n",
       "ALLEN PHILLIP K     201955.00 4175000.00  False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data.sort_values(by='bonus', ascending=False).head().loc[:, ['salary', 'bonus', 'poi']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The person receiving the highest bonus is John Lavorato, somebody we have already identified above as a potential outlier. Given this name has appeared a couple times as an outlier I will remove it from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa12cb9a710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (8770638554085)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data = enron_data.drop('LAVORATO JOHN J')\n",
    "\n",
    "ggplot(enron_data, aes(x='salary', y='bonus', color='poi')) + \\\n",
    "    geom_point(size=40.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've cleaned up the dataset, lets see how many examples and features remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 139 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 20 columns):\n",
      "salary                       139 non-null float64\n",
      "to_messages                  139 non-null float64\n",
      "deferral_payments            139 non-null float64\n",
      "total_payments               139 non-null float64\n",
      "exercised_stock_options      139 non-null float64\n",
      "bonus                        139 non-null float64\n",
      "restricted_stock             139 non-null float64\n",
      "shared_receipt_with_poi      139 non-null float64\n",
      "restricted_stock_deferred    139 non-null float64\n",
      "total_stock_value            139 non-null float64\n",
      "expenses                     139 non-null float64\n",
      "loan_advances                139 non-null float64\n",
      "from_messages                139 non-null float64\n",
      "other                        139 non-null float64\n",
      "from_this_person_to_poi      139 non-null float64\n",
      "poi                          139 non-null bool\n",
      "director_fees                139 non-null float64\n",
      "deferred_income              139 non-null float64\n",
      "long_term_incentive          139 non-null float64\n",
      "from_poi_to_this_person      139 non-null float64\n",
      "dtypes: bool(1), float64(19)\n",
      "memory usage: 21.9+ KB\n"
     ]
    }
   ],
   "source": [
    "enron_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total I have:\n",
    "\n",
    "- removed 7 examples,\n",
    "- removed 1 feature,\n",
    "- corrected inconsistant data,\n",
    "- filled in missing financial data with a zero value,\n",
    "- imputed missing email data using the median value from each class.\n",
    "\n",
    "Lets write this cleaned dataset to disk to be used in the final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dictionary containing the dataset.\n",
    "with open('final_project_dataset_cleaned.pkl', 'wb') as data_file:\n",
    "    pickle.dump(enron_data.to_dict(orient='index'), data_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing to implement a predicitve model and investigating different classifers I want to discuss the evaluation metrics I'll be using to determine the suitability of each classifier. This is an important topic as without knowing what we're measuring it will not be possible to meaningfully improve and tune our predictive model.\n",
    "\n",
    "It follows that each evaluation metric favours one type of error over another, thus allowing a predictive model to be tuned and optimised for specific outcomes. For examples some metrics are more sensitive to false positives which will in the case of the Enron dataset tend to classify more employees as persons of interest than perhaps are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard accuracy is a ratio of correct classifications to the total number of classifications:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "accuracy & = \\frac{\\text{number of data points labelled correctly}}{\\text{number of data points}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is therefore an overall measure of correct classification over all classes, that assigns equal cost to false positives and false negatives.\n",
    "\n",
    "When the class distribution is heavily imbalanced (for example more non-POIs than POIs) a model can predict the value of the majority class for all predictions and achieve a high classification accuracy. In this case accuracy is just a measure of how good our predictive model is at guessing. To put this into perspective a predictive model that always predicted false when trying to identify persons of interest on our cleaned dataset would achieve an accuracy of 87%.\n",
    "\n",
    "This causes issues when in reality there are unequal costs associated with errors (false positives vs false nagatives). In the Enron dataset the cost of a false positive may be far less than the cost of a false negative where those falsely labelled as a person of interest could later be absolved from any crime.\n",
    "\n",
    "Clearly this metric would not satisfy the objectives of this investigation that requires we implement a predictive model capable of identifying persons of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is defined as the number of true positives divided by the number of true positives and false positives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "precision & = \\frac{\\text{true positives}}{\\text{true positives} + \\text{false positives}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put more simply precision (also called the positive predictive value) measures the proportion of true positives that actually belong to the positive class. It is a measure of confidence that when the predictive model classifies an example as positive that it has been correctly classified.\n",
    "\n",
    "In terms of the Enron dataset precision expresses that for every employee classified as a person of interest the probability that this employee really is a person of interest.\n",
    "\n",
    "A positive result from a predictive model with a high preceision is useful for ruling out a possible negative classification since it rarely predicts negative for the truely positive examples in the dataset. Therefore a model with 100% precision can confidently say all positively classified examples are truely positive. In this case a positive result would definitively rule out a negative classification.\n",
    "\n",
    "On the otherhand a negative result from a predictive model with a high precision does not guarentee a truely negative classification. This is becaue precision does not take into account false negatives. Therefore a model with 100% precision may not recognise some examples that should belong to the positive class.\n",
    "\n",
    "In other words precision errs on the side of negative classification as it is reluctant to \"pull the trigger\" on edge cases. Therefore it will favour classifying Enron employees as non-POIs which presents a high cost as potentially many persons of interest will go undetected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall is defined as the number of true positives divided by the number of true positives and false negatives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "recall & = \\frac{\\text{true positives}}{\\text{true positives} + \\text{false nagatives}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put more simply recall (also called the true positive rate or sensitivity) measures the proportion of true positives that are correctly classified as such. Equivalently recall is the extent to which true positives are not overlooked (so false negatives are few) and thus a highly sensitive predictive model rarely overlooks a true positive.\n",
    "\n",
    "In terms of the Enron dataset recall returns the proportion of employees who are classified as persons of interest among those who truely are persons of interest.\n",
    "\n",
    "A negative result from a predictive model with a high recall is useful for ruling out a possible positive classification since it rarely predicts positive for the truely nagative examples in the dataset. Therefore a model with 100% recall will recognise all truely positive examples. In this case a negative result would definitively rule out a positive classification.\n",
    "\n",
    "Conversely a positive result from a predictive model with a high recall does not guarentee a truely positive classification. This is because recall does not take into account false positives. Therefore a model with 100% recall will recognise not only truely positive examples but may also include many false positives.\n",
    "\n",
    "Since recall quantifies the avoiding of false negatives this evaluation metric is ideal for the Enron dataset whereby not correclty identifying an employee as a person of interest has a much greater cost than fasely identifying an innocent employee of being a person of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F-measure is a weighted average of the precision and recall, with the traditional F-measure or balanced F-score (F1 score) being the harmonic average of the precision and recall:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "F_1 & = 2 \\cdot \\left(\\frac{precision \\cdot recall}{precision + recall}\\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This measure is approximately the average of both precision and recall when they are close, and is more generally the harmonic mean, which, for the case of two numbers, coincides with the square of the geometric mean divided by the arithmetic mean. The F1 score reaches its best value at 1 (indicating perfect precision and recall) and worst at 0. In its more general form the F-measure is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "F_\\beta & = \\left(1 + \\beta^2\\right) \\cdot \\left(\\frac{precision \\cdot recall}{\\beta^2 \\cdot precision + recall}\\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a parameterised version of the F-measure allowing us to specify the preferred weights for each error type (false positives and false negatives). As discussed above we are more interested in maximising the recall since it avoids false negatives. Therefore we can use the F2 score, which weighs recall twice as high as precision (thus placing more emphasis on false negatives). Plugging in the values the F2 score is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "F_2 & = 5 \\cdot \\left(\\frac{precision \\cdot recall}{4 \\cdot precision + recall}\\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this investigation it is a requirement that our classifier achieves both a precision and recall greater than `0.3`. However it should be possible to achieve a better result given the optimal features are selected and hyperparameters given. Therefore when I later attempt to optimise my classifier I would like to lean towards maximising the F2 score. However sklearn does not seem to provide F2 as a possible [scoring function](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) so I will fallback to maximising the F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning the parameters of a predictive model and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called overfitting. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set.\n",
    "\n",
    "This is called validation: a set of techniques used to make sure a predictive model performs well in a wide range of situations, and is not just optimised for a particular dataset or set of conditions. In this section I cover 2 of the more widely used validation methods describing some of the issues and how these can be overcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split is a validation method that partitions the original dataset into a training set to train the model; a validation set for tuning the model; and a test set to evaluate it. There is no general rule dictating how many samples should be made available for each set and depends largely and how strong the patterns are in the data. However it is advides to maximise the training data as much as possible.\n",
    "\n",
    "The training set, as the name suggests, is used to train a predictive model by attempting to identify the patterns in the data that drive it to generalise on a solution. During training the model fits itself around the data it is provided, but there is no validation performed at this stage.\n",
    "\n",
    "The validation set is used strictly for model tuning. Using the model created during training, parameters may be tuned and the performance of each adjutment is recorded. Using an independant dataset attempts to prevent the model from \"cheating\" and inaccurately reporting higher performance for a particular combination of parameter values.\n",
    "\n",
    "The test set is used to make a final estimate of the error. Until this point, the most performant model has been exposed to both the training and validation sets for parameter tuning. So, it must be checked on an unseen set so that we may forecast how well it will perform in the real world.\n",
    "\n",
    "![train-test-split](train-test-split.png)\n",
    "\n",
    "We can see how the Enron dataset may be split to create a training, validation, and test set using [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Note that the dataset is shuffled to distribute the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set:    83 samples\n",
      "validation set:  28 samples\n",
      "test set:        28 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First shuffle the data.\n",
    "shuffled_data = enron_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Create a 80% split of the data.\n",
    "split_boundary = int(len(shuffled_data) * .80)\n",
    "test_set = shuffled_data[split_boundary:]\n",
    "train_validation_set = shuffled_data[:split_boundary]\n",
    "\n",
    "# Create a further split for training and validation data.\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_validation_set.drop(columns=['poi']), \n",
    "                                                      train_validation_set['poi'], \n",
    "                                                      test_size=0.25, \n",
    "                                                      random_state=42)\n",
    "\n",
    "# Justify the output of samples.\n",
    "print_samples = lambda t, samples: print('{} set:'.format(t).ljust(16), len(samples), 'samples')\n",
    "\n",
    "print_samples('training', X_train)\n",
    "print_samples('validation', X_valid)\n",
    "print_samples('test', test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above however is only viable when there is enough data to make three splits. In this example I have created a 60-20-20 split that yields only 83 samples from the Enron dataset to be used for training. This is likely not nearly enough data to identify patterns that are possibly hidden in the other 56 samples being used for validation and testing. Furthermore making such a segregation, despite the data having been shuffled, may disturb the target distribution and therefore we may find that most of the persons of interest are contained in any one of the three sets.\n",
    "\n",
    "This is one of the drawbacks of this particular validation strategy and by definition it does not maximise the number of samples available for training since it must hold back a percentage of the samples to be distributed across both the validation and test sets.\n",
    "\n",
    "On a more general note validation and test sets \"wear out\" with repeated use. That is, the more you use the same data to make decisions about hyperparameter settings or other model improvements, the less confidence you'll have that these results actually generalize to new, unseen data. Note that validation sets typically wear out more slowly than test sets.\n",
    "\n",
    "If possible, it's a good idea to collect more data to \"refresh\" the validation and test sets. This of course is not possible in respect to the Enron dataset since we already have the records of all employees at the company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a technique to validate predictive models by partitioning the original dataset into a training set to train the model, and a test set to evaluate it.\n",
    "\n",
    "In k-fold cross-validation, the original sample is randomly partitioned into `k` equal size subsamples. Of the `k` subsamples, a single subsample is retained as the validation data for testing the model, and the remaining `k-1` subsamples are used as training data. The cross-validation process is then repeated `k` times (the folds), with each of the `k` subsamples used exactly once as the validation data. The `k` results from the folds can then be averaged (or otherwise combined) to produce a single estimation.\n",
    "\n",
    "Moreover, we can use the [`StratifiedShuffleSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) cross-validation object; a merge of [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) and [`ShuffleSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html), which returns stratified randomised folds. The folds are made by preserving the percentage of samples for each class.\n",
    "\n",
    "![cross-validation](cross-validation.png)\n",
    "\n",
    "As before we can see how this may be applied to the Enron dataset using the object sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set:    125 samples\n",
      "validation set:  14 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Cross-validator with 10 splits.\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.1)\n",
    "\n",
    "# The cross-validator returns an iterator. Grab only the first item.\n",
    "X_train, X_valid = next(cv.split(enron_data.drop(columns=['poi']), enron_data['poi']))\n",
    "\n",
    "# Justify the output of samples.\n",
    "print_samples = lambda t, samples: print('{} set:'.format(t).ljust(16), len(samples), 'samples')\n",
    "\n",
    "print_samples('training', X_train)\n",
    "print_samples('validation', X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of this method is that all samples are used for both training and validation, and each sample is used for validation exactly once. This therefore maximises the number of samples used for training.\n",
    "\n",
    "For the remainder of this experiment I shall use cross validation when evaluating my models and their respective hyperparamters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drive the evaluation of each classifier I will use the function included in this project, `test_classifier`, offering a consistent means through which every classifer may be tested. Furthermore it will be the same function used to evaluate my classifer upon submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from tester import test_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This testing strategy does however come with the limitation that I am unable to manipulate the validation data before it is used to evaluate each classifier. This is something I dicussed earlier concerning validation leakage. If this were not the case I could perform imputation at the time of evaluation such that the validation set is not biased by the same data used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above function I have additionally implemented a means through which to test multiple classifiers sequentially whilst keeping the output to a minimum. Once each classifier has been tested the results are returned in a DataFrame and the results sorted (ascending F1 score by default). This is really useful to reduce the noise in this notebook, displaying only the most important information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import redirect_stdout\n",
    "\n",
    "def test_classifiers(clfs, dataset, features, sort_by='f1', verbose=False):\n",
    "    results = pd.DataFrame(columns=['accuracy', 'precision', 'recall', 'f1', 'f2'])\n",
    "    for _, (name, clf) in enumerate(clfs):\n",
    "        print('=====> Running {}\\n'.format(name))\n",
    "        if verbose:\n",
    "            results.loc[name] = test_classifier(clf, dataset, features)\n",
    "        else:\n",
    "            with redirect_stdout():\n",
    "                results.loc[name] = test_classifier(clf, dataset, features)\n",
    "    return results.sort_values(by=sort_by, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Pre-Assesment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this secton I am going to perform a prelimiary assesment of 4 \"out of the box\" classifieres using their respective default parameters. I'm going to use the results of evaulating these classifiers as a baseline from which I may improve performance, or ultimately dismiss classifiers from being further evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to begin using all of the features in the dataset because presently there are no strong indicators as to which features are driving the patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `features_list` is a list of strings, each of which is a feature name in the dataset. \n",
    "# The first feature in the list must be `poi` - the target label.\n",
    "features_list = ['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments',\n",
    "                'exercised_stock_options', 'bonus', 'restricted_stock',\n",
    "                'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value',\n",
    "                'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi',\n",
    "                'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I have to extract a dictionary from the dataframe we've been using throughout the fist half of this investingation. Importantly the data is reorientated such that the keys in the dictionary are the Enron emplyees instead of the features, which is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = enron_data.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite having implemented a method to test each classifier sequentially, in this section I will perform the evaluation each time using `test_classifier` to show the general approach that will be taken throughout the remainder of the project. This also lends to writing up a little about each classifier and detailing their features.\n",
    "\n",
    "To record the results of the pre-assesment I will create a dataframe where the columns match the evaluation metrics discussed in the last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy', 'precision', 'recall', 'f1', 'f2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Naive Bayes classifier is a fairly simple, probabalistic classifier based on applying Bayes' theorem with strong (naive) independence assumptions between features. What this means is that a Naive Bayes classifer will assume a [statistical indepencance](https://en.wikipedia.org/wiki/Independence_(probability_theory)) between features despite there being a possible strong correlation. However in spite of this apparent over-simplified assumption Naive Bayes calssifiers have been know to perform rather well in some real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.75621\tPrecision: 0.25289\tRecall: 0.36150\tF1: 0.29759\tF2: 0.33290\n",
      "\tTotal predictions: 14000\tTrue positives:  723\tFalse positives: 2136\tFalse negatives: 1277\tTrue negatives: 9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "naive_bayes = GaussianNB()\n",
    "results.loc['Naive Bayes'] = test_classifier(naive_bayes, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results shown above we can see that even before making any optimisations this classifier almost meets the requirements of this experiment (0.3 for both precision and recall). However the high number of false negatives is a concern meaning that over the many conbinations of training/validation subsets a huge number of persons of interest were not identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines (SMV) attempt to find a hyerplane, also known as the decision boundary, that divides two classes with the largest margin. That is an SVM maximises the distance to the nearest point in both classes which consequently maximises the robutness of the classification decision boundary. This is a classic optimisation problem, putting correct classification above maximising the margin. So there may be cases where the margin is reduced in order to correctly classify all examples.\n",
    "\n",
    "If a hyperplane does not exist that classifies all examples correctly the SVM will do the \"best it can\" given specific hyperparameters, therefore accomodating for outliers.\n",
    "\n",
    "For non-linear decision boundaries there are functions (kernels) that take in a low dimentional feature sapce and map it to a higher dimentional feature space. This transforms a non-linearly seperable feature space into one that can be separated. Most importantly these functions can map the results back into a low dimentional feature space.\n",
    "\n",
    "Support vectors are the points that lie along the supporting hyerplane. One key factor that plays into the complexity of the runtime for a support vector is the penaly parameter, `C`. The penalty parameter allows for a soft-margin and better generalization. The number of support vectors varies depending on the penalty we allow and how the data is distributed. The lower the penalty the fewer support vectors we get, creating a smoother decision boundary. Converserly the higher the penalty the greater the number of support vectors, having the effect of prioritising the number of correctly classified examples.\n",
    "\n",
    "Another key factor into the complexity of a support vector is how far the influence of a sinlge trainig point reaches, controlled by the kernel coefficient parameter, `gamma`. A low kernel coefficient has the effect of creating a straighter decision boundary due to training examples further from the hyperplane having a higher influence on the algorithm. On the otherhand a high kernel coefficient causes the decision boundary to become less linear because only those examples closest to the decision boundary have any influence on the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1000.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\tAccuracy: 0.73650\tPrecision: 0.23165\tRecall: 0.36450\tF1: 0.28327\tF2: 0.32699\n",
      "\tTotal predictions: 14000\tTrue positives:  729\tFalse positives: 2418\tFalse negatives: 1271\tTrue negatives: 9582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svc = LinearSVC(C=1000.0)\n",
    "results.loc['SVM'] = test_classifier(linear_svc, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many discussion forums, including the Udacity [Intro to Machine Learning](https://discussions.udacity.com/t/final-project-error/25538/6?u=tomasbashamdy3) forum, talk about how support vector machines commonly struggle on this particular dataset which may explain why I was not able to get a result when using the `sklearn.svm.SVC` classifier with an `rbf` kernel. Instead I have selected to use the `sklearn.svm.LinearSVC` classifier which is similar to `sklearn.svm.SVC` with a linear kernel, but instead is implemented in terms of `liblinear` rather than `libsvm`. Because of this it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.\n",
    "\n",
    "Unlike the other classifiers in this section I had to tune the penalty parameter, `C`, otherwise the classifier was not returing in a reasonable amount of time (if at all). This I think is likely due to the many features contained in the dataset that may possibly not be linearly separable. Using a higher penalty parameter allows the classifer to priorities correctness over smooth decision boundaries.\n",
    "\n",
    "Despite my best efforts the linear Support Vector Machine classifier has performed similarly to Naive Bayes, arguably slightly worse, with both a slightly lower number of true posites and equally slightly higher number of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest classifiers are a specific type of bootstrap aggrageted (or bagged) decision tree, an early ensemble method, that builds multiple decision trees by repeatedly resampling training data with replacement, and voting the trees for a consensus prediction. That is a Random Forest classifier is composed of a number of smaller classifiers, in this case decision trees: a non-parametric supervised learning method used for both calssification and regression.\n",
    "\n",
    "Decision trees attempt to create a model that predits the value of a target variable (represented by the leaves) by learning simple rules informed by the features within a dataset. These rules create decision boundaries (represented by the branches) that attempt to separate disimilar examples.\n",
    "\n",
    "A tree can be \"learned\" by splitting the input data into subsets based on an attribute value test. This process is repeated on each derived subset in a recursive manner called recursive partitioning. The recursion is completed when the subset at a node has all the same value of the target variable, or when splitting no longer adds value to the predictions. This process of top-down induction of decision trees is an example of a greedy algorithm, and it is by far the most common strategy for learning decision trees from data.\n",
    "\n",
    "However one of the issues with decision tree learners is that they can create over-complex trees that do not generalise well from the training data. Random decision forests correct for decision trees' habit of overfitting to their training set.\n",
    "\n",
    "An important factor that governs the performace of a random forest is the number of decision tree the compose it. I believe it is generally accepted that the greater number of decision trees the more confidence we can gain from the consensus. However more decision trees, and therefore more subsamples of the training data, result in a classifier that is much slower to train.\n",
    "\n",
    "Another interesting parameter is the [criterion](https://en.wikipedia.org/wiki/Decision_tree_learning#Metrics). This dictates the function used to measure the impurity of a decision boundary. The `sklearn.tree.DecisionTreeClassifier` used here implements 2 known functions to measure boundary impurity. The first is [information gain](https://en.wikipedia.org/wiki/Information_gain_in_decision_trees) and is intended for classification problems, similar to that of this experiment. The second function is gini impurity, intended for continuous values and therefore more appropriate for regression problems. It is interesting to note that both information gain and gini impurity are largely similar as metrics and generally the performance of a classifier will not differ using one or the other. There was a paper written comparing these two metrics where the most important remarks were:\n",
    "\n",
    "* It only matters in 2% of the cases whether you use gini impurity or entropy.\n",
    "* Entropy might be a little slower to compute (because it makes use of the logarithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\tAccuracy: 0.86829\tPrecision: 0.59443\tRecall: 0.24550\tF1: 0.34749\tF2: 0.27816\n",
      "\tTotal predictions: 14000\tTrue positives:  491\tFalse positives:  335\tFalse negatives: 1509\tTrue negatives: 11665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_jobs=-1)\n",
    "results.loc['Random Forest'] = test_classifier(random_forest, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results I am rather impressed with the fairly high precision this classifiers offers without having performed any hyperparameter tuning or other machine learning techniques. However the recall seems to have suffered even more greatly than the support vector machine classifier. This is a cause for concern since in my opinion the recall is of greater importance in this experiment than the precision. Even more concerning is the increase in false negatives. This is a really undesirable feature of this classifer and can hopefully be improved through tuning. However despite this the F1 score has improved upon both the Naive Bayes and SVM classifiers due to the significant boost in precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "\tAccuracy: 0.87029\tPrecision: 0.55549\tRecall: 0.46050\tF1: 0.50355\tF2: 0.47681\n",
      "\tTotal predictions: 14000\tTrue positives:  921\tFalse positives:  737\tFalse negatives: 1079\tTrue negatives: 11263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost = AdaBoostClassifier()\n",
    "results.loc['AdaBoost'] = test_classifier(adaboost, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By far the most performant out-of-the-box classifier, AdaBoost already scores high enough to have achieved the criteria for this experiment. Most impressively it has attained more true and false positives than any of the other classifiers. This indicates that currently this classifier errs on the side of positive classification (marking examples as persons of interest). This is a favourable tradeoff likely meaning many more persons of interest will be correctly classified as such. However I am still concerned with the number of false negatives this classifier yields. Whilst it is the lowest of all the classifiers it still remains too high to give a satisfacotry level of confidence to dismiss an individual Enron employee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the full table of results for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  precision  recall   f1   f2\n",
       "AdaBoost           0.87       0.56    0.46 0.50 0.48\n",
       "Random Forest      0.87       0.59    0.25 0.35 0.28\n",
       "Naive Bayes        0.76       0.25    0.36 0.30 0.33\n",
       "SVM                0.74       0.23    0.36 0.28 0.33"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by='f1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in this experiment is to create new features from the existing data in the Enron dataset. I'll do this in an attempt to tease out any latent information within combinations of features that may improve performance.\n",
    "\n",
    "Using my intuition and resoning about the background of the Enron scandal I have created 6 new features across the payment, stock and email data I have at hand. The payment features implemented are concerned with the fraction of financial compensation awarded as a fraction of the total payment received by each Enron employee. Needless to say that it is quite typical that employees at any organisation can be incentivised by three common types of compensation: salary, bonus and long term incentives (e.g. reward for long service). Therefore is stands to reason that perhaps those persons of interest involved in the Enron scandal were receiving large bonuses or being rewarded huge long service incentives in an attempt to hide fraudulent behaviour. More specifically I have created 3 new features:\n",
    "\n",
    "* salary as a fraction of total payment\n",
    "* bounus as a fraction of total payment\n",
    "* long term incentive as a fraction of total payment\n",
    "\n",
    "It is important to note that here I've also replaced any infinate values that may have resulted from the calculation with 0. This is quite likely to happen since many values in the financial data were given a value of 0 during the data cleaning stage of this experiment.\n",
    "\n",
    "Below I have plotted the salary as a fraction of total payment against bonus as a fraction of total payment to guage if there are any patterns to be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa12cb073d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (8770638514129)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data['fraction_salary'] = enron_data.salary / enron_data.total_payments\n",
    "enron_data['fraction_bonus'] = enron_data.bonus / enron_data.total_payments\n",
    "enron_data['fraction_long_term_incentive'] = enron_data.long_term_incentive / enron_data.total_payments\n",
    "\n",
    "# Replace any infinate or missing values.\n",
    "enron_data = enron_data.replace([np.inf, -np.inf], np.nan)\n",
    "enron_data = enron_data.fillna(0)\n",
    "\n",
    "ggplot(enron_data, aes(x='fraction_salary', y='fraction_bonus', color='poi')) + \\\n",
    "    geom_point(size=40.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively I'd expect many of the persons of interest involved in the Enron scandal to have large contributions to their total payment from either a bonus or from some other means. In the scatter plot above you can see that many of the persons of interest receive a low salary in respect to their overall total payment but tend towards receiving a higher bonus. That is with expection to a small handful of Enron employees. Suspiciously there are a few data points that indicate a bonus much larger than the total payment they received. I thought this to be an error in the data, but having gone back to the FindLaw report it is clear that the total payment repoted for some employees was significantly reduced due to deferred income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly I have plotted the salary as a fraction of total payment against long term incentive as a fraction of total payment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa12cb9a910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (8770638508481)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ggplot(enron_data, aes(x='fraction_salary', y='fraction_long_term_incentive', color='poi')) + \\\n",
    "    geom_point(size=40.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the two glaring obvious persons of interest that have long term incentives much larger than their total payment, there does not appear to be any conclusive trend in this data. However I shall keep this feature in case it proves useful to the classifiers. If I find this to not be the case this feature will likely be removed in the feature selection part of the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I'll create a new stock value feature that, not too disimilar to the new payment features, will represent exercised stock options as a fraction of the total stock value for each Enron employee. The rationale behind this new feature is that employees involved in the scandal may have been given huge amounts of stock that could be later sold.\n",
    "\n",
    "I did not have any other feature that I though appropriate to plot this against so I'll just leave this feature for the classifiers to judge it's usefulness whilst performing feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_data['fraction_exercised_stock_options'] = enron_data.exercised_stock_options / enron_data.total_stock_value\n",
    "\n",
    "# Replace any infinite or missing values.\n",
    "enron_data = enron_data.replace([np.inf, -np.inf], np.nan)\n",
    "enron_data = enron_data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, I created new email features that attempt to tease out the frequency at which persons of interest were in contact (via email) with each other as a proportion to the total number of message they either sent or received. The reason I find these features to be of interest is becuase it seems likely for this scandal to have gone unnoticed for so long that key individuals were privately sending messages to coordinate fraudulant activity. More specifically I have created 2 new features:\n",
    "\n",
    "* messages sent to a person of interest as a fraction of total messages sent\n",
    "* messaged received from a person of interest as a fraction of total messaged received\n",
    "\n",
    "I have plotted these two features against each other to find any trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa12ccb8e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (8770638643181)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data['fraction_from_poi_to_this_person'] = enron_data.from_poi_to_this_person / enron_data.to_messages\n",
    "enron_data['fraction_from_this_person_to_poi'] = enron_data.from_this_person_to_poi / enron_data.from_messages\n",
    "\n",
    "ggplot(enron_data, aes(x='fraction_from_poi_to_this_person', y='fraction_from_this_person_to_poi', color='poi')) + \\\n",
    "    geom_point(size=40.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively I would have imagined persons of interest to sit somewhere towards the top right of the graph whilst the other employees would be scattered about as they innocently get on with their jobs. However the scatter plot does not contain any discernible pattern that I can see. What is apparent from this plot is that Enron employees tended to send more email messages to persons on interest than receive them.\n",
    "\n",
    "However all is not lost as there are a few data points in this plot worth exploring. An interesting data point is the Enron employee that has not be flagged as a person of interest but has only ever sent email messages to other persons of interest. Lets find out who this is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraction_from_this_person_to_poi</th>\n",
       "      <th>from_messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HUMPHREY GENE E</th>\n",
       "      <td>1.00</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHERRICK JEFFREY B</th>\n",
       "      <td>0.72</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    fraction_from_this_person_to_poi  from_messages\n",
       "HUMPHREY GENE E                                 1.00          17.00\n",
       "SHERRICK JEFFREY B                              0.72          25.00"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data.sort_values(by='fraction_from_this_person_to_poi', ascending=False) \\\n",
    "    .loc[:, ['fraction_from_this_person_to_poi', 'from_messages']].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst I could not find much on the internet that would identify the role Gene Hunphrey had at Enron I was able to discover to whom he was sending the messages:\n",
    "\n",
    "* Kenneth Lay\n",
    "* Jeffrey Skilling\n",
    "\n",
    "Considering he only sent 17 messages it is not too hard to believe why this metric is so high.\n",
    "\n",
    "Jeffrey Sherrick in another interesting data point who sent email messages primarily to Kenneth Lay. However this is justified by the fact he was the President of Enron Global Exploration & Production Inc. and therfore part of the corporate leadership and central management at Enron.\n",
    "\n",
    "The last data point I want to explore is the employee that has clearly received the most emails from persons of interest as a fraction of the total number of emails received. Lets find out who this is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraction_from_poi_to_this_person</th>\n",
       "      <th>fraction_from_this_person_to_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DONAHUE JR JEFFREY M</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.50</td>\n",
       "      <td>865.00</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      fraction_from_poi_to_this_person  \\\n",
       "DONAHUE JR JEFFREY M                              0.22   \n",
       "\n",
       "                      fraction_from_this_person_to_poi  to_messages  \\\n",
       "DONAHUE JR JEFFREY M                              0.50       865.00   \n",
       "\n",
       "                      from_messages  \n",
       "DONAHUE JR JEFFREY M          22.00  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data.sort_values(by='fraction_from_poi_to_this_person', ascending=False) \\\n",
    "    .loc[:, ['fraction_from_poi_to_this_person', 'fraction_from_this_person_to_poi', 'to_messages', 'from_messages']].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeffrey Donahue held a number of senior corporate development roles whilst at Enron and it is evident from the above table that 50% of the messages he sent were to a person of interest (which is only 11 messages). Additionally he received 190 messages from persons of interest, making up 22% of the messages he received overall. Taking a look at his email data I can see that he both sent messages to and received messages from the following persons of interest:\n",
    "\n",
    "* David Delainey\n",
    "* Kenneth Lay\n",
    "* Jeffrey Skilling\n",
    "\n",
    "So although neither Gene Humphrey, Jeffrey Sherrick nor Jeffrey Donahue are themselves persons of interest it is fascinating to discover that they were all in contact with the same few empoyees of the company involved in the scandal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before I will extract a dictionary from the dataframe we've been using throughout this investingation, now including the new engineered features, and reorient the data. In addition I will now be using the `test_classifiers` method I implemented earlier to more comprehensively evaluate a list of classifiers sequentially, and will continue to take this approach from this point in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_features = ['fraction_salary', 'fraction_bonus', 'fraction_long_term_incentive',\n",
    "                       'fraction_exercised_stock_options', 'fraction_from_poi_to_this_person',\n",
    "                       'fraction_from_this_person_to_poi']\n",
    "\n",
    "# Append the engineered features to our list of original features.\n",
    "extended_features_list = features_list + engineered_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Running Naive Bayes\n",
      "\n",
      "=====> Running SVM\n",
      "\n",
      "=====> Running Random Forest\n",
      "\n",
      "=====> Running AdaBoost\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  precision  recall   f1   f2\n",
       "AdaBoost           0.87       0.56    0.48 0.52 0.49\n",
       "Random Forest      0.88       0.69    0.30 0.42 0.34\n",
       "Naive Bayes        0.76       0.25    0.36 0.30 0.33\n",
       "SVM                0.74       0.23    0.36 0.28 0.33"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the data from the dataframe, including the engineered features.\n",
    "my_extended_dataset = enron_data.to_dict(orient='index')\n",
    "\n",
    "# Create a list of classifiers to evaluate.\n",
    "clfs = [\n",
    "  (u'Naive Bayes', GaussianNB()),\n",
    "  (u'SVM', LinearSVC(C=1000.0)),\n",
    "  (u'Random Forest', RandomForestClassifier(n_jobs=-1)),\n",
    "  (u'AdaBoost', AdaBoostClassifier())\n",
    "]\n",
    "\n",
    "test_classifiers(clfs, my_extended_dataset, extended_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table shows that overall adding these 4 new features has not had a significant impact on the performace of each classifier, with exception to the `RandomForestClassifier` that has an imporoved F1 score of 41% (a 5% increase). This is due to both an increase in the precision and recall of this particular classifer. This I admit is a little disappointing as I had hoped some latent patterns to be discovered in these new features that would show a greater performace across all the classifiers. However I will keep all of these features until later feature selection deems them as having no significant effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total I have engineered 6 features:\n",
    "\n",
    "- fraction_salary\n",
    "- fraction_bonus\n",
    "- fraction_long_term_incentive\n",
    "- fraction_exercised_stock_options\n",
    "- fraction_from_poi_to_this_person\n",
    "- fraction_from_this_person_to_poi\n",
    "\n",
    "Lets write these engineered dataset to disk to be used in the final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the engineered dictionary containing the dataset.\n",
    "with open('final_project_dataset_engineered.pkl', 'wb') as data_file:\n",
    "    pickle.dump(my_extended_dataset, data_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, classifiers that exploit distances (i.e. [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance)) or similarities between examples are sensitive to features taking on broad ranges of values. That is classifiers that have a co-dependancy between dimentions are effected by feature scaling. For example if one feature takes on a range of values much greater than the other features in the same dataset, the distance will be goverened by this particular feature. Therefore it is best practice to normalise (or standardise) all features within a dataset such that each contributes proportionately to the final distance.\n",
    "\n",
    "Examples of classifers sensitive to feature scaling include both Support Vector Machines and K-Nearest Neighbour. Therefore it is imperitive for this experiment that, at least in the case of the `LinearSVC`, the features are appropriately scaled.\n",
    "\n",
    "Conversely graphical-model based classifiers, such as Naive Bayes, as well as Decision trees and Tree-based ensemble methods (Random Forest, AdaBoost) are invariant to feature scaling. However as part of the experimentation I will scale the data for these classifiers to investigate what differece, if any, it makes to the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling (min-max Normalisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Normalisation](https://en.wikipedia.org/wiki/Normalization_(statistics)) is a method commonly deployed in machine learning centered around rescaling that uses the extreme values within a particular distribution. More specifically it looks at the minimum and maximum values, the range of a feature, and then shrinks or stretches each value to a common range. This common range will typically be between` [0, 1]` or `[-1, 1]`. Selecting the target range depends on the nature of the data. The general formula is given as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "x^{\\prime} = \\frac{\\left(x - x_{min}\\right)}{\\left(x_{max} - x_{min}\\right)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is basically at what percentage of a range the value lies. Since the range is only determined by the minimum and maximum for each feature normalisation is invarient to extreme values. For example a series containing values `[-100, 10, 11, 12, 900]` can still be normalised within a range of `[0, 1]`. Here the normalised output would be `[0, 0.11, 0.111, 0.112, 1]`. What follows is an example of applying feature normalisation to the Enron dataset and what effect this has to the performance of each classifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Running Naive Bayes\n",
      "\n",
      "=====> Running SVM\n",
      "\n",
      "=====> Running Random Forest\n",
      "\n",
      "=====> Running AdaBoost\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  precision  recall   f1   f2\n",
       "AdaBoost           0.87       0.56    0.47 0.52 0.49\n",
       "SVM                0.83       0.42    0.42 0.42 0.42\n",
       "Random Forest      0.88       0.65    0.27 0.39 0.31\n",
       "Naive Bayes        0.67       0.24    0.57 0.33 0.45"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "columns_to_scale = enron_data.columns.drop('poi') # poi is not a feature and should not be considered\n",
    "\n",
    "# Make a copy of the extended dataset and perform scaling.\n",
    "enron_data_normalised = enron_data.copy()\n",
    "enron_data_normalised[columns_to_scale] = scaler.fit_transform(enron_data[columns_to_scale])\n",
    "\n",
    "# Extract the data from the dataframe, with the features normalised.\n",
    "my_normalised_dataset = enron_data_normalised.to_dict(orient='index')\n",
    "\n",
    "# Create a list of classifiers to evaluate.\n",
    "clfs = [\n",
    "  (u'Naive Bayes', GaussianNB()),\n",
    "  (u'SVM', LinearSVC(C=1000.0)),\n",
    "  (u'Random Forest', RandomForestClassifier(n_jobs=-1)),\n",
    "  (u'AdaBoost', AdaBoostClassifier())\n",
    "]\n",
    "\n",
    "test_classifiers(clfs, my_normalised_dataset, extended_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite unsurprisingly, normalising the features has had no (or very little) effect on the results of the AdaBoost and RandomForest classifiers, having only in the case of the AdaBoost classifier increasd recall by 1%. This I have deemed not significant enough to warrant any further investigation. Conversely normalisaing the features has surprisingly had a mixed effect on the Naive Bayes classifier, reducing the accuracy by almost 10% whilst increasing the recall by over 20%. Since all texts online have led me to believe Naive Bayes is invariant to feature scaling I am rather curious as to why this has had such a significant impact.\n",
    "\n",
    "Again unsurprisingly, as the only non graphical-model based classifer I am using to evaluate a predictive model, the performance of the support vector machine has improved vastly from having previously been the least performant, to being far more comparible to the most performant classifiers in the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Standardisation](https://en.wikipedia.org/wiki/Feature_scaling#Standardization) is another method of feature scaling and is employed by `sklearn.preprocessing.scale()` which assumes that all features are normally distributed (each feature with a different mean and standard deviation), and scales them such that each feature's Gaussian distribution is now centered around 0, and it's standard deviation is 1 (unit-variance).\n",
    "\n",
    "It achieves this by calculating the distribution mean and standard deviation for each feature, and converts each value into a z-score, defined as the number of standard deviations away from the mean:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "x^{\\prime} = \\frac{\\left(x - \\bar{x}\\right)}{\\sigma}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ideal circumstances where all features hold the normality assumption, in addition to many practical situations where the normality assumption does not hold but the distributions are somewhat close, this scheme still works pretty well. On the other hand if the data is far from normally distributed, for example, highly skewed, fat-tailed distributions like a [power-law](https://en.wikipedia.org/wiki/Power_law), this scheme will not give good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Running Naive Bayes\n",
      "\n",
      "=====> Running SVM\n",
      "\n",
      "=====> Running Random Forest\n",
      "\n",
      "=====> Running AdaBoost\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  precision  recall   f1   f2\n",
       "AdaBoost           0.87       0.56    0.48 0.52 0.49\n",
       "SVM                0.84       0.44    0.56 0.49 0.53\n",
       "Random Forest      0.88       0.66    0.29 0.40 0.32\n",
       "Naive Bayes        0.63       0.23    0.68 0.35 0.49"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "columns_to_scale = enron_data.columns.drop('poi') # poi is not a feature and should not be considered\n",
    "\n",
    "# Make a copy of the extended dataset and perform scaling.\n",
    "enron_data_standardised = enron_data.copy()\n",
    "enron_data_standardised[columns_to_scale] = scaler.fit_transform(enron_data[columns_to_scale])\n",
    "\n",
    "# Extract the data from the dataframe, with the features standardised.\n",
    "my_standardised_dataset = enron_data_standardised.to_dict(orient='index')\n",
    "\n",
    "# Create a list of classifiers to evaluate.\n",
    "clfs = [\n",
    "  (u'Naive Bayes', GaussianNB()),\n",
    "  (u'SVM', LinearSVC(C=1000.0)),\n",
    "  (u'Random Forest', RandomForestClassifier(n_jobs=-1)),\n",
    "  (u'AdaBoost', AdaBoostClassifier())\n",
    "]\n",
    "\n",
    "test_classifiers(clfs, my_standardised_dataset, extended_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show a similar trend to those obtained from normalising the data, with no discerbale difference in performance from both the AdaBoost and RandomForest classifiers and a large improvement from the support vecor machine. It is important to note however that standardising the data has somewhat further improved the performace of the support vector machine over normalisation, boosting the F1 score to almost that of the most performant classifier.\n",
    "\n",
    "As before, and just as surprisingly the Naive Bayes classifier has returned a decrease in accuracy but overall improvement in recall and therefore F2 score. At a later date I would like to dive into why scaling the data is causing this behaviour from this particular classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerations..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescaling ([MinMaxScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler)) works much better in certain cases where standarisation ([StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)) might not work well. For example, if the standard deviations are very small for features, standarisation is highly sensitive to tiny changes between standard deviations of different features, but rescaling is very robust. Also, for features with highly skewed distributions, or sparse cases where each feature has a lot of zeros that move the distribution away from a Gaussian, rescaling is a better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># standard deviations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>197600.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>2043.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>766161.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>8901866.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>4995771.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>1082916.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>2030256.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>937.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <td>277901.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>6361214.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>46381.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_advances</th>\n",
       "      <td>6915543.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>1459.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>1150429.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>73.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_fees</th>\n",
       "      <td>29479.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>615568.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>682003.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>57.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraction_salary</th>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraction_bonus</th>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraction_long_term_incentive</th>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraction_exercised_stock_options</th>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraction_from_poi_to_this_person</th>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraction_from_this_person_to_poi</th>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  # standard deviations\n",
       "salary                                        197600.56\n",
       "to_messages                                     2043.02\n",
       "deferral_payments                             766161.13\n",
       "total_payments                               8901866.63\n",
       "exercised_stock_options                      4995771.18\n",
       "bonus                                        1082916.14\n",
       "restricted_stock                             2030256.98\n",
       "shared_receipt_with_poi                          937.60\n",
       "restricted_stock_deferred                     277901.51\n",
       "total_stock_value                            6361214.05\n",
       "expenses                                       46381.80\n",
       "loan_advances                                6915543.11\n",
       "from_messages                                   1459.43\n",
       "other                                        1150429.36\n",
       "from_this_person_to_poi                           73.39\n",
       "director_fees                                  29479.77\n",
       "deferred_income                               615568.91\n",
       "long_term_incentive                           682003.43\n",
       "from_poi_to_this_person                           57.80\n",
       "fraction_salary                                    0.20\n",
       "fraction_bonus                                     0.59\n",
       "fraction_long_term_incentive                       0.56\n",
       "fraction_exercised_stock_options                   0.39\n",
       "fraction_from_poi_to_this_person                   0.03\n",
       "fraction_from_this_person_to_poi                   0.17"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data.drop(columns=['poi']).std().to_frame('# standard deviations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite there being a small handful of features with tiny standard deviations, all resulting from features engineered in the previous section, it is conclusive from the test results that standardisation has seen the largest improvments in the non graphical-model based classifiers (in this case only SVM). Moreover since standardisation also has no significant effect on both the AdaBoost and RandomForest classifiers it should not harm to apply the same scaling operation when further testing these classifers in later sections, thus making experimentation much easier and fair.\n",
    "\n",
    "However due to the surprising results from the Naive Bayes classifier it may be time to eliminate it from the list of potential candidates for final selection. Despite in both cases (normalisation and standardisation) Naive Bayes performed slightly better, according to the evaluation metrics I'm optimising for, I feel this may be coincidental and this particular classifier too unpredictable to continue evaluating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets write the standardised dataset to disk to be used in the final submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the engineered dictionary containing the dataset.\n",
    "with open('final_project_dataset_standardised.pkl', 'wb') as data_file:\n",
    "    pickle.dump(my_standardised_dataset, data_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features in our dataset have a significant influence over the performance of the predictive model we are able to create. Broadly speaking, in machine learning if you feed garbage into a classifier you should expect only garbage to come out. This becomes more important as the number of features in the dataset grows. You need not use every available feature when creating a model, therefore it is important to discover which features are contributing most to predicting the output variable. In our case this is the  likelihood an Enron employee is in fact a person of interest. This is a very difficult problem which often requires a deep understanding of the domain. However it is possible to automatically identify a subset of features from the original dataset that are the most relevant and useful through a process called feaure selection. It is this process that may mean the difference between successfully and meaningfully modeling the problem and not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout previous sections it has been accepted that the more data we have the better our trained model will be at making predictions. This is generally the case but does have a few caveats. For instance, including redundant or partially redundant features can be misleading to modeling algorithms. This is especially true of linear algorithms such as linear and logistic regression. Furthermore irrelevant attributes may contribute to overfitting. Some Decision Tree algorithms, including the Random Forest classifier used in this experiment, attempt to make splits in feature values. Less relevant features will be split on last but may contribute to small amounts of noise, only benefiting the model by chance. Overall this could have a large negative impact on model performance and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can therefore conclude that the removal of redundant features may benefit the performance of a predicitve model, lowering the prediction error that would be otherwise incurred if using the full dataset. Overall choosing to keep only the most relevant features has the following desired effects:\n",
    "\n",
    "- **Reduces Overfitting**: Less redundant data means less opportunity to make decisions based on noise.\n",
    "- **Improves Accuracy**: Less misleading data means modeling accuracy improves.\n",
    "- **Reduces Training Time**: Less data means that algorithms train faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach with Caution..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst feature selection is a vital part of the machine learning process we must be aware of the cost of performing it too ealry. In reality the choice of features may have an impact on the optimal hyperparameter values of our predictive model, and those values may also impact the choice of optimal features. Therefore we end up in a chicken and egg situation which could be solved by considering feature selection as part of the model selection process. If not, bias may be introduced into our model and result in overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition it would be a mistake to first perform feature selection on the entire dataset, then perform model selection, training and validation on the selected features. The reason for this is that the validation and testing datasets will have also been used when deciding on the selection of features thus introduing bias in the predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid this situation feature selection must be performed as part fo the iterative validation process when using such techniques as cross-validation. This means that feature selection is performed on the prepared fold right before the model is trained. More generally feature selection must be performed on a different dataset than that which is used for validation and testing. Moreover feature selection must not be performed on the test set, as this will inflate estimates of the models' performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagged Decision Trees like Random Forest and Adaboost can be used to estimate and rank the importance of features in both regression and classification problems. We can take advantage of this to get a sense of which features may be most important and perform an amount of manual feature selection. The benefit to this appraoch is that each classifier can be given its own crafted subset of features. However one drawback is that this technique can only be applied to those classifiers that support it. Therefore the Linear Support Vector Machine cannot take advantage of this method. However it is still useful nonetheless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a little more context a Bagged Decision Tree is a classifier that fits many Decision Trees on a random subset of the original dataset and then takes the mean of all their individual predctions, forming a final prediction. Due to this each Decision Tree has its own feature importances, which are also averaged to create a final set of importances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "f(x) = \\frac{\\sum_{i}importances(x_i)}{len(x)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the importances are returned from these classifiers they are no longer clearly identifiable by name. Instead only the score is returned. Therefore to see what these look like I will first define a function to print out the feature importances alongside their original names. Luckily the scores are in the same order as the features were given to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Justify the output of feature importances.\n",
    "print_importance = lambda f, importance: print('{}:'.format(f).ljust(34), importance)\n",
    "\n",
    "def print_feature_importances(clf, features_list):\n",
    "    feature_name_and_importance = zip(features_list, clf.feature_importances_)\n",
    "    for feat, importance in sorted(feature_name_and_importance, key=lambda x: x[1], reverse=True):\n",
    "        print_importance(feat, importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now retreiving the feature importances is as simple as accessing the `feature_importances_` attribute on the trained predictive model as seen below with the RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\tAccuracy: 0.87843\tPrecision: 0.66817\tRecall: 0.29600\tF1: 0.41026\tF2: 0.33311\n",
      "\tTotal predictions: 14000\tTrue positives:  592\tFalse positives:  294\tFalse negatives: 1408\tTrue negatives: 11706\n",
      "\n",
      "fraction_from_this_person_to_poi:  0.14781050413072772\n",
      "total_payments:                    0.07100500623787412\n",
      "exercised_stock_options:           0.07061972893444307\n",
      "shared_receipt_with_poi:           0.06707985571417129\n",
      "from_messages:                     0.06558367499624823\n",
      "from_poi_to_this_person:           0.06547970025557637\n",
      "fraction_from_poi_to_this_person:  0.06486769112028759\n",
      "from_this_person_to_poi:           0.06349202143390158\n",
      "expenses:                          0.0629752646942957\n",
      "fraction_bonus:                    0.05941534927524802\n",
      "other:                             0.04608726192514147\n",
      "bonus:                             0.044931051418569026\n",
      "long_term_incentive:               0.03608470395037865\n",
      "to_messages:                       0.03404968299548859\n",
      "fraction_salary:                   0.032137757428155195\n",
      "total_stock_value:                 0.03128079091822085\n",
      "salary:                            0.027153311588839622\n",
      "fraction_exercised_stock_options:  0.0060963055966194715\n",
      "fraction_long_term_incentive:      0.0038503373858134312\n",
      "deferral_payments:                 0.0\n",
      "restricted_stock:                  0.0\n",
      "restricted_stock_deferred:         0.0\n",
      "loan_advances:                     0.0\n",
      "director_fees:                     0.0\n",
      "deferred_income:                   0.0\n"
     ]
    }
   ],
   "source": [
    "random_forest_selection = RandomForestClassifier(n_jobs=-1)\n",
    "test_classifier(random_forest_selection, my_standardised_dataset, extended_features_list)\n",
    "\n",
    "# Print the feature names and importances.\n",
    "print_feature_importances(random_forest_selection, extended_features_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the output that the attribute `feature_importances_` holds a score for each of the features in the dataset representing the estimated importance of each feature. The importances are ordered such that those with the largest value are considered the most relevant to the classifer whils those towards the bottom are considered of lower relevance and could contribute noie to the predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can similarly retrieve the feature importances from the AdaBoostClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "\tAccuracy: 0.87243\tPrecision: 0.56346\tRecall: 0.47500\tF1: 0.51546\tF2: 0.49040\n",
      "\tTotal predictions: 14000\tTrue positives:  950\tFalse positives:  736\tFalse negatives: 1050\tTrue negatives: 11264\n",
      "\n",
      "from_this_person_to_poi:           0.14\n",
      "shared_receipt_with_poi:           0.1\n",
      "fraction_from_poi_to_this_person:  0.1\n",
      "fraction_from_this_person_to_poi:  0.1\n",
      "expenses:                          0.08\n",
      "fraction_salary:                   0.08\n",
      "other:                             0.06\n",
      "fraction_long_term_incentive:      0.06\n",
      "deferral_payments:                 0.04\n",
      "bonus:                             0.04\n",
      "total_stock_value:                 0.04\n",
      "salary:                            0.02\n",
      "to_messages:                       0.02\n",
      "total_payments:                    0.02\n",
      "exercised_stock_options:           0.02\n",
      "deferred_income:                   0.02\n",
      "long_term_incentive:               0.02\n",
      "from_poi_to_this_person:           0.02\n",
      "fraction_bonus:                    0.02\n",
      "restricted_stock:                  0.0\n",
      "restricted_stock_deferred:         0.0\n",
      "loan_advances:                     0.0\n",
      "from_messages:                     0.0\n",
      "director_fees:                     0.0\n",
      "fraction_exercised_stock_options:  0.0\n"
     ]
    }
   ],
   "source": [
    "adaboost_selection = AdaBoostClassifier()\n",
    "test_classifier(adaboost_selection, my_standardised_dataset, extended_features_list)\n",
    "\n",
    "# Print the feature names and importances.\n",
    "print_feature_importances(adaboost_selection, extended_features_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is rather interesting to compare the feature importances of both the RandomForestClassifer and the AdaBoostClassifier. It is clear from the results that both classifiers do not agree on the 10 most important features despite each classifier having arguably equal accuracy thus far. This could be noted as further indication that accuracy is not a great metric in this experiment. However what is clear is that both classifiers regard several of the engineered features more important than many of the original features in dataset. This would suggest that these features in fact describe a trend in the data posing a strong correlation to the output variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There would be little point to investigate further whether only using the top `n` features has any impact on the performance of the predictive model since there is likely a co-dependancy on the classifier hyperparameters which will be investingated in a later section. For now it is enough to know how wildly different the importances are for each classifier with their respective default options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate feature selection, a type of filter method, works by selecting the most relevant features as reported by some univariate statistical function. That is the selection of features is independant to any implementation of classifier. Instead when univariate feature selection is applied each feature is assigned a score indicating the strength of its relationship with the output variable. This is a powerful property of this type of feature selection because, unlike feature importances which only works with supported modeling implementations, this technique may be applied as a preprocessing step before training any model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use [`sklearn.feature_selection.SelectKBest`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest) that by default applies the [`f_classif`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif) scoring function to compute the ANOVA F-value for the provided samples. This is a good scoring function for the Enron dataset which contains a few negative values. Alternatively if we had previously normalised the features between 0 and 1 then we could use the [`chi2`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2) scoring function to compute the likelihood of correlation or association between groups of categorical features using their frequency distribution. However this only works for non-negative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Justify the output of feature scores.\n",
    "print_score = lambda f, score: print('{}:'.format(f).ljust(34), score)\n",
    "\n",
    "def print_feature_scores(clf, features_list):\n",
    "    feature_name_and_score = zip(features_list, clf.scores_)\n",
    "    for feat, score in sorted(feature_name_and_score, key=lambda x: x[1], reverse=True):\n",
    "        print_score(feat, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the scores by first separating the features from the labels using methods provided by the course material and running these through the `SelectKBest` algorithm. Note that I have, for the purpose of demonstration, set the algorithm to reduce the dataset down to the 4 most relevant features. This however will not become important until the dataset has been transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bonus:                             30.996650263046035\n",
      "fraction_from_this_person_to_poi:  24.74703911283773\n",
      "total_stock_value:                 21.715370553236223\n",
      "exercised_stock_options:           21.61831247068783\n",
      "fraction_bonus:                    20.11247267477801\n",
      "salary:                            17.652821354040245\n",
      "shared_receipt_with_poi:           15.901048190153714\n",
      "fraction_long_term_incentive:      13.280784474046534\n",
      "from_poi_to_this_person:           11.868915005764967\n",
      "deferred_income:                   10.877747814724641\n",
      "long_term_incentive:               10.438729740129324\n",
      "total_payments:                    9.17891146854367\n",
      "restricted_stock:                  8.383512828688367\n",
      "loan_advances:                     6.949372528479059\n",
      "expenses:                          5.038223197623868\n",
      "other:                             3.968449361834746\n",
      "from_this_person_to_poi:           3.5603092511206285\n",
      "fraction_salary:                   2.363441883884539\n",
      "to_messages:                       2.259290587732519\n",
      "fraction_from_poi_to_this_person:  2.1529983056261957\n",
      "director_fees:                     2.030244576563368\n",
      "restricted_stock_deferred:         0.7943522196252019\n",
      "deferral_payments:                 0.26155708920673937\n",
      "from_messages:                     0.16456684445456812\n",
      "fraction_exercised_stock_options:  0.05302510191815604\n"
     ]
    }
   ],
   "source": [
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "data = featureFormat(my_standardised_dataset, extended_features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "select_k_best = SelectKBest(k=4).fit(features, labels)\n",
    "\n",
    "# Print the feature names and scores.\n",
    "print_feature_scores(select_k_best, extended_features_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the scores that have been assigned to each feature, where the largest scores indicate the most relevant features. When the dataset is transformed through this algorithm it will return only the 4 most relevant features since the `k` parameter was set to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139, 4)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data = select_k_best.transform(features)\n",
    "transformed_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 4 features, in order of relevance, are:\n",
    "\n",
    "1. `bonus`\n",
    "1. `fraction_from_this_person_to_poi`\n",
    "1. `total_stock_value`\n",
    "1. `exercised_stock_options`\n",
    "\n",
    "Interestingly the second most relevant feature to be returned by `SelectKBest` is an engineered feature describing the messages sent to a person of interest as a fraction of total messages they have sent. Perhaps not so surprisingly however are the other features which I intuatively believe to be some of the more important drivers indicating a person of interest.\n",
    "\n",
    "Again it must be noted that the features here do not agree with the feature importances returned from the Random Forest and AdaBoost classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that using this algorithm we can select only the subset of features that are most relevant, the problem is reduced to that of optimising how many features should be selected to obtain the most performant predictive model. Choosing this value will take part of the focus of the hyperparameter tuning section of this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive feature elimination, a type of wrapper method, is a greedy optimization algorithm which aims to identify which attributes (and combination of attributes) contribute the most to predicting the target value. This is achieved by first training the predictive model on the initial set of feature and then removing the least relevant feature, indicated by the smallest feature coefficient or feature importance. The model is then retrained and the next least relevant feature removed. This process continues by considering smaller and smaller sets of features until we arrive at the desired number of remaining features.\n",
    "\n",
    "We can use [`sklearn.feature_selection.RFE`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html) to perform this task, that given a classifer capable of assiging weights/scores to each feature, will determine the least relevant feature through either the `coef_` or `feature_importances` attribute. We have observed that the classifiers used in this experiment pocess either attribute and can therefore all be used to perform recursive feature elimination.\n",
    "\n",
    "It is important to note that features must first be scaled, otherwise there is a chance that features with smaller values will have a minimal coefficient and therefore be dropped. However if the features are scaled with a preprocessing stage these same features could turn out to be quite important. Fortunatley this has already covered this in the previous section where I decided on standardising the data using the `StandardScaler`.\n",
    "\n",
    "As with univariate feature selection the problem of selecting features is reduced to that of optimising how many features should be selected to obtain the most performant model. For this I would like to use [`sklearn.feature_selection.RFECV`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV) which extends `RFE` with a cross-validation step that intends to seek out the optimal number of features given for a given metric. In this case I will optimise for the F1 score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction is a subtle form of feature selection deserving its own section of this notebook. Unlike feature selection discussed in the previous section the techniques used in dimensionality reduction derive brand new (latent) features from the existing dataset. These features are not directly measureable but describe a general trend or direction in the data that we may project our data onto while losing a minimal amount of information. Here I will discuss 2 common methods to apply dimensionality reduction and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Principal Component Analysis](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) (PCA) is a very useful unsupervised learning technique that can be used to tease out the latent features in a dataset. It achieves this by identifying and reframing the dataset by what are called its principle components (PC), the combination of attributes (directions in the feature space) that account for the most variance in the data.\n",
    "\n",
    "It is mathematical fact that projecting data points onto the direction of maximum variance we minimise the distance from a higher dimensionality data point to its new transformed value. This translates to a minimal information loss after the transformation.\n",
    "\n",
    "As a gerneral process PCA is able to algorithmically create new features from a dataset and rank the relative powers of each new feature. So if we have `n` latent features that are driving most of the variation in the data (remember this minimises the informaton loss) PCA will pick those out and rank them as the `1st, 2nd, ..., nth` principle components where the 1st PC has the most effect, and the maximum number of PCs is equal to `min(num_features, num_examples)`.\n",
    "\n",
    "More specifically PCA finds a new coordinate space, through translation and rotation only, moving the centre of the coordinate system to the centre of the data. PCA works on eigenvectors and eigenvalues of the covariance matrix, which is the equivalent of fitting those principle-component hyperplanes to the variance of the data. Why? Because eigenvectors trace the principal lines of force. In other words, PCA determines the lines of variance in the dataset which are so called its principal components with the first principal component having the maximum variance, second principal component (orthoganal to the first) having second maximum variance and so on.\n",
    "\n",
    "When used for dimensionality reduction PCA will discard the principle components ranking the loweset and therefore having the least effect. This therefore reduces any noise in the dataset that is either adding little (or no) information or could be derived from other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Linear Discriminant Analysis](http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html) (LDA) is a supervised learning technique that in addition to identifying attributes contributing the most variance in the data (the scatter in LDA terms), as PCA does, computes the linear discriminants (LD) representing the directions in the feature space that maximise the separation between classes. This ensures good class separability in the dataset.\n",
    "\n",
    "In general LDA algorithmically finds the boundaries around the clusters of classes, projecting the data points onto the direction of maximum distance between each class such that they are as separated as possible, with each cluster having a relative (close) distance to a centroid. Furthermore LDA identifies these cluster as satisfying two criteria:\n",
    "\n",
    "1.\tMaximize the distance between the centroid of each class,\n",
    "1.\tMaximize the variation within each class.\n",
    "\n",
    "When used for dimensionality reduction LDA will discard the linear discriminants that explain the least distance between classes thus reducing any potential noise generated by features that may posess some overlap.\n",
    "\n",
    "Linear Discriminant Analysis is particularly suited to datasets that have more than two classes and is the preferred linear classification technique, say over logistic regression, that is limited to only two-class classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I could also perform Principal Component Analysis to further reduce the number of features, but I think that the performance I am seeing does not necessitate the use of PCA, and the algorithms do not take very long to train even on a large number of features.\n",
    "\n",
    "This is one way that I try to combat the black box problem in machine learning. If I at least know what is going in to a model, then I can try to understand why the model returned a certain classification and it can inform my thinking to enable me to create smarter machine learning classifiers in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using [Grid Search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) as it allows for large permutations of paramters to be tuned systematically.\n",
    "\n",
    "https://github.com/scikit-learn/scikit-learn/wiki/Pipeline-et-al.-design-issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "def create_validator(dataset, features_list):\n",
    "    '''\n",
    "    Return a function that cross-validates over a dataset.\n",
    "    '''\n",
    "    def validator(estimator, param_grid):\n",
    "        '''\n",
    "        Perform recursive feature elimination over the entire dataset before\n",
    "        running the results through grid search cross-validation.\n",
    "        '''\n",
    "        # Extract features and labels from dataset for local testing.\n",
    "        data = featureFormat(dataset, features_list, sort_keys=True)\n",
    "        labels, features = targetFeatureSplit(data)\n",
    "\n",
    "        # Cross validator with 100 splits.\n",
    "        validator = StratifiedShuffleSplit(n_splits=100)\n",
    "\n",
    "        # Automatic cross-validated feature selection.\n",
    "        selector = RFECV(estimator, scoring='f1', cv=5, n_jobs=-1)\n",
    "\n",
    "        # Parameter search cross-validation.\n",
    "        grid_search = GridSearchCV(selector, param_grid, scoring='f1', cv=validator, n_jobs=-1, return_train_score=False)\n",
    "        grid_search.fit(features, labels)\n",
    "\n",
    "        return grid_search\n",
    "    return validator\n",
    "\n",
    "def create_k_best_validator(dataset, features_list):\n",
    "    '''\n",
    "    '''\n",
    "    def validator(estimator, param_grid):\n",
    "        '''\n",
    "        '''\n",
    "        # Extract features and labels from dataset for local testing.\n",
    "        data = featureFormat(dataset, features_list, sort_keys=True)\n",
    "        labels, features = targetFeatureSplit(data)\n",
    "\n",
    "        # Cross validator with 100 splits.\n",
    "        validator = StratifiedShuffleSplit(n_splits=100)\n",
    "        \n",
    "        # Pipeline with univariate feature selection step.\n",
    "        pipeline = Pipeline([\n",
    "            ('selection', SelectKBest()),\n",
    "            ('estimator', estimator)\n",
    "        ])\n",
    "        \n",
    "        # Parameter search cross-validation.\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, scoring='f1', cv=validator, n_jobs=-1, return_train_score=False)\n",
    "        grid_search.fit(features, labels)\n",
    "        \n",
    "        return grid_search\n",
    "    return validator\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary containing the dataset.\n",
    "with open('final_project_dataset_standardised.pkl', 'r') as data_file:\n",
    "    my_standardised_dataset = pickle.load(data_file)\n",
    "\n",
    "#df = pd.DataFrame.from_dict(my_standardised_dataset, orient='index')\n",
    "#df[:].isin([np.inf, -np.inf, np.nan]).any(axis=0, skipna=False)\n",
    "#np.where(df.values >= np.finfo(np.float64).max)\n",
    "\n",
    "rfe_validator = create_validator(my_standardised_dataset, extended_features_list)\n",
    "kbest_validator = create_k_best_validator(my_standardised_dataset, extended_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(  \n",
    "    estimator__n_estimators=[5, 10, 20, 50, 100, 500],\n",
    "    estimator__learning_rate=[1.0, 0.5, 0.1, 0.01],\n",
    "    estimator__algorithm=['SAMME.R', 'SAMME']\n",
    ")\n",
    "\n",
    "adaboost_validated = validator(AdaBoostClassifier(), param_grid)\n",
    "pd.DataFrame(adaboost_validated.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_estimator__C</th>\n",
       "      <th>param_estimator__loss</th>\n",
       "      <th>param_estimator__max_iter</th>\n",
       "      <th>param_estimator__multi_class</th>\n",
       "      <th>param_estimator__tol</th>\n",
       "      <th>param_selection__k</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split94_test_score</th>\n",
       "      <th>split95_test_score</th>\n",
       "      <th>split96_test_score</th>\n",
       "      <th>split97_test_score</th>\n",
       "      <th>split98_test_score</th>\n",
       "      <th>split99_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25</td>\n",
       "      <td>{u'estimator__C': 1000, u'estimator__max_iter'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.10</td>\n",
       "      <td>25</td>\n",
       "      <td>{u'estimator__C': 1000, u'estimator__max_iter'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25</td>\n",
       "      <td>{u'estimator__C': 1000, u'estimator__max_iter'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1000</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25</td>\n",
       "      <td>{u'estimator__C': 1000, u'estimator__max_iter'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1000</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.01</td>\n",
       "      <td>25</td>\n",
       "      <td>{u'estimator__C': 1000, u'estimator__max_iter'...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  mean_score_time  mean_test_score param_estimator__C  \\\n",
       "3499           0.01             0.00             0.51               1000   \n",
       "3424           0.01             0.00             0.51               1000   \n",
       "3474           0.01             0.00             0.51               1000   \n",
       "3874           0.01             0.00             0.50               1000   \n",
       "3449           0.01             0.00             0.50               1000   \n",
       "\n",
       "     param_estimator__loss param_estimator__max_iter  \\\n",
       "3499                 hinge                      1000   \n",
       "3424                 hinge                      1000   \n",
       "3474                 hinge                      1000   \n",
       "3874         squared_hinge                      1000   \n",
       "3449                 hinge                      1000   \n",
       "\n",
       "     param_estimator__multi_class param_estimator__tol param_selection__k  \\\n",
       "3499                          ovr                 0.00                 25   \n",
       "3424                          ovr                 0.10                 25   \n",
       "3474                          ovr                 0.00                 25   \n",
       "3874                          ovr                 0.00                 25   \n",
       "3449                          ovr                 0.01                 25   \n",
       "\n",
       "                                                 params       ...        \\\n",
       "3499  {u'estimator__C': 1000, u'estimator__max_iter'...       ...         \n",
       "3424  {u'estimator__C': 1000, u'estimator__max_iter'...       ...         \n",
       "3474  {u'estimator__C': 1000, u'estimator__max_iter'...       ...         \n",
       "3874  {u'estimator__C': 1000, u'estimator__max_iter'...       ...         \n",
       "3449  {u'estimator__C': 1000, u'estimator__max_iter'...       ...         \n",
       "\n",
       "      split94_test_score  split95_test_score  split96_test_score  \\\n",
       "3499                0.50                0.67                0.57   \n",
       "3424                0.50                0.67                0.80   \n",
       "3474                0.50                0.67                0.67   \n",
       "3874                0.50                0.67                0.57   \n",
       "3449                0.50                0.67                0.67   \n",
       "\n",
       "      split97_test_score  split98_test_score  split99_test_score  \\\n",
       "3499                0.00                0.67                0.50   \n",
       "3424                0.00                0.57                0.50   \n",
       "3474                0.00                0.57                0.50   \n",
       "3874                0.00                0.57                0.50   \n",
       "3449                0.00                0.67                0.50   \n",
       "\n",
       "      split9_test_score  std_fit_time  std_score_time  std_test_score  \n",
       "3499               0.00          0.00            0.00            0.29  \n",
       "3424               0.00          0.00            0.00            0.28  \n",
       "3474               0.00          0.00            0.00            0.28  \n",
       "3874               0.00          0.00            0.00            0.29  \n",
       "3449               0.00          0.00            0.00            0.29  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = dict(\n",
    "    selection__k=np.arange(1, len(extended_features_list)),\n",
    "    estimator__C=[1, 10, 50, 100, 1000],\n",
    "    estimator__loss=['hinge', 'squared_hinge'],\n",
    "    estimator__max_iter=[100, 1000],\n",
    "    estimator__multi_class=['ovr', 'crammer_singer'],\n",
    "    estimator__tol=[0.1, 0.01, 0.001, 0.0001] \n",
    ")\n",
    "\n",
    "linear_svc_validated = kbest_validator(LinearSVC(), param_grid)\n",
    "pd.DataFrame(linear_svc_validated.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(  \n",
    "    estimator__C=[1, 10, 50, 100, 1000],\n",
    "    estimator__loss=['hinge', 'squared_hinge'],\n",
    "    estimator__max_iter=[100, 1000],\n",
    "    estimator__multi_class=['ovr', 'crammer_singer'],\n",
    "    estimator__tol=[0.1, 0.01, 0.001, 0.0001] \n",
    ")\n",
    "\n",
    "linear_svc_validated = rfe_validator(LinearSVC(), param_grid)\n",
    "pd.DataFrame(linear_svc_validated.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/envs/py2env/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_estimator__min_samples_split</th>\n",
       "      <th>param_estimator__n_estimators</th>\n",
       "      <th>param_selection__k</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split94_test_score</th>\n",
       "      <th>split95_test_score</th>\n",
       "      <th>split96_test_score</th>\n",
       "      <th>split97_test_score</th>\n",
       "      <th>split98_test_score</th>\n",
       "      <th>split99_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>22</td>\n",
       "      <td>{u'estimator__min_samples_split': 4, u'selecti...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>{u'estimator__min_samples_split': 2, u'selecti...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>18</td>\n",
       "      <td>{u'estimator__min_samples_split': 2, u'selecti...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>{u'estimator__min_samples_split': 4, u'selecti...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>24</td>\n",
       "      <td>{u'estimator__min_samples_split': 2, u'selecti...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  mean_score_time  mean_test_score  \\\n",
       "196           0.51             0.13             0.41   \n",
       "99            0.51             0.13             0.41   \n",
       "67            0.41             0.14             0.40   \n",
       "112           0.16             0.13             0.40   \n",
       "73            0.40             0.14             0.40   \n",
       "\n",
       "    param_estimator__min_samples_split param_estimator__n_estimators  \\\n",
       "196                                  4                           100   \n",
       "99                                   2                           100   \n",
       "67                                   2                            75   \n",
       "112                                  4                            10   \n",
       "73                                   2                            75   \n",
       "\n",
       "    param_selection__k                                             params  \\\n",
       "196                 22  {u'estimator__min_samples_split': 4, u'selecti...   \n",
       "99                  25  {u'estimator__min_samples_split': 2, u'selecti...   \n",
       "67                  18  {u'estimator__min_samples_split': 2, u'selecti...   \n",
       "112                 13  {u'estimator__min_samples_split': 4, u'selecti...   \n",
       "73                  24  {u'estimator__min_samples_split': 2, u'selecti...   \n",
       "\n",
       "     rank_test_score  split0_test_score  split10_test_score       ...        \\\n",
       "196                1               0.67                0.50       ...         \n",
       "99                 2               0.67                0.50       ...         \n",
       "67                 3               0.67                0.50       ...         \n",
       "112                4               0.00                0.67       ...         \n",
       "73                 5               0.67                0.50       ...         \n",
       "\n",
       "     split94_test_score  split95_test_score  split96_test_score  \\\n",
       "196                0.00                0.50                0.50   \n",
       "99                 0.67                0.50                0.40   \n",
       "67                 0.67                0.50                0.50   \n",
       "112                1.00                0.67                0.50   \n",
       "73                 0.67                0.50                0.00   \n",
       "\n",
       "     split97_test_score  split98_test_score  split99_test_score  \\\n",
       "196                1.00                0.67                0.00   \n",
       "99                 1.00                0.67                0.00   \n",
       "67                 1.00                0.50                0.00   \n",
       "112                0.67                0.50                0.00   \n",
       "73                 1.00                0.67                0.00   \n",
       "\n",
       "     split9_test_score  std_fit_time  std_score_time  std_test_score  \n",
       "196               0.67          0.06            0.02            0.34  \n",
       "99                0.67          0.06            0.02            0.34  \n",
       "67                0.67          0.03            0.02            0.35  \n",
       "112               0.67          0.01            0.00            0.36  \n",
       "73                0.00          0.04            0.02            0.35  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = dict(\n",
    "    selection__k=np.arange(1, len(extended_features_list)),\n",
    "    estimator__n_estimators=[10, 50, 75, 100],\n",
    "    estimator__min_samples_split=[2, 4]\n",
    ")\n",
    "\n",
    "random_forest_validated = kbest_validator(RandomForestClassifier(n_jobs=-1), param_grid)\n",
    "pd.DataFrame(random_forest_validated.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(\n",
    "    estimator__n_estimators=[10, 50, 75, 100],\n",
    "    estimator__min_samples_split=[2, 4]\n",
    ")\n",
    "\n",
    "random_forest_validated = validator(RandomForestClassifier(n_jobs=-1), param_grid)\n",
    "#pd.DataFrame(random_forest_validated.cv_results_).sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=100, random_state=None, test_size='default',\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=RFECV(cv=5,\n",
       "   estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "  ...state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "   n_jobs=-1, scoring='f1', step=1, verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'estimator__min_samples_split': [2, 4], 'estimator__n_estimators': [10, 50, 75, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_validated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above has just completed all the hard work for me by cross-validating and cross-referencing all the hyperparameter values I specified in the parameter grid, using the F1 score as the evaluation metric. To see the most performant estimator we can read from the `best_estimator` attribute on the grid search object. Additionally I'll print the steps for transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = grid_search.best_estimator_\n",
    "clf.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I'll run the predictive model through the provided testing code to see if the results are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classifier(clf, my_dataset, features_list);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same dataset can I run this through a neural network using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@article{doi:10.1145/2020408.2020496,\n",
    "  author  = {Kaufman, S. and Rosset, S. and Perlich, C},\n",
    "  title   = {Leakage in Data Mining: Formulation, Detection, and Avoidance},\n",
    "  journal = {ACM},\n",
    "  pages   = {556-563},\n",
    "  year    = {2011},\n",
    "  doi     = {10.1145/2020408.2020496},\n",
    "  url     = {http://doi.acm.org/10.1145/2020408.2020496},\n",
    "}\n",
    "\n",
    "@article{doi:10.1093/llc/fqn019,\n",
    "  author  = {Sculley, D. and Pasanek, Bradley M.},\n",
    "  title   = {Meaning and mining: the impact of implicit assumptions in data mining for the humanities},\n",
    "  journal = {Literary and Linguistic Computing},\n",
    "  volume  = {23},\n",
    "  number  = {4},\n",
    "  pages   = {409-424},\n",
    "  year    = {2008},\n",
    "  doi     = {10.1093/llc/fqn019},\n",
    "  url     = {http://dx.doi.org/10.1093/llc/fqn019},\n",
    "  eprint  = {/oup/backfile/content_public/journal/dsh/23/4/10.1093/llc/fqn019/2/fqn019.pdf}\n",
    "}\n",
    "\n",
    "@article{doi:10.1.1.483.2183,\n",
    "  author  = {Zhang, H`},\n",
    "  title   = {The Optimality of Naive Bayes},\n",
    "  journal = {Proceedings of the Seventeenth International Florida Artificial Intelligence Research Society Conference, FLAIRS 2004},\n",
    "  volume  = {2},       \n",
    "  year    = {2004},\n",
    "  doi     = {10.1.1.483.2183}\n",
    "}\n",
    "\n",
    "https://en.wikipedia.org/wiki/Enron#Former_management_and_corporate_governance\n",
    "https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
